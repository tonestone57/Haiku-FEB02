File: src/system/kernel/DPC.cpp
  Line 118 [new]: = new(std::nothrow) FunctionDPCCallback(this);
  Line 318 [new]: new(&sNormalPriorityQueue) DPCQueue;
  Line 319 [new]: new(&sHighPriorityQueue) DPCQueue;
  Line 320 [new]: new(&sRealTimePriorityQueue) DPCQueue;
  Line 328 [panic]: panic("Failed to create default DPC queues!");

File: src/system/kernel/UserEvent.cpp
  Line 114 [new]: EventSignal* signal = new(std::nothrow) EventSignal(signalNumber,
  Line 120 [new]: TeamSignalEvent* event = new(std::nothrow) TeamSignalEvent(team, signal);
  Line 184 [new]: EventSignal* signal = new(std::nothrow) EventSignal(signalNumber,
  Line 190 [new]: ThreadSignalEvent* event = new(std::nothrow) ThreadSignalEvent(thread, signal);
  Line 257 [new]: return new(std::nothrow) CreateThreadEvent(attributes);

File: src/system/kernel/UserTimer.cpp
  Line 77 [new]: // called for new threads not added to the team yet.
  Line 147 [new]: with new parameters.
  Line 324 [new]: // schedule the new timer
  Line 431 [new]: // schedule the new timer
  Line 469 [new]: // get the new real-time offset
  Line 543 [new]: // schedule the new timer
  Line 553 [new]: Team* newTeam = Team::Get(fTeamID);
  Line 554 [new]: if (newTeam == NULL) {
  Line 558 [new]: timeLocker.SetTo(newTeam->time_lock, false);
  Line 559 [new]: fTeam = newTeam;
  Line 786 [new]: // schedule the new timer
  Line 796 [new]: Team* newTeam = Team::Get(fTeamID);
  Line 797 [new]: if (newTeam == NULL) {
  Line 801 [new]: timeLocker.SetTo(newTeam->time_lock, false);
  Line 802 [new]: fTeam = newTeam;
  Line 939 [new]: // schedule the new timer
  Line 949 [new]: Thread* newThread = Thread::Get(fThreadID);
  Line 950 [new]: if (newThread == NULL) {
  Line 954 [new]: timeLocker.SetTo(newThread->time_lock, false);
  Line 955 [new]: fThread = newThread;
  Line 1250 [new]: timer = new(std::nothrow) SystemTimeUserTimer;
  Line 1254 [new]: timer = new(std::nothrow) RealTimeUserTimer;
  Line 1258 [new]: timer = new(std::nothrow) ThreadTimeUserTimer(
  Line 1265 [new]: timer = new(std::nothrow) TeamTimeUserTimer(team->id);
  Line 1271 [new]: timer = new(std::nothrow) TeamUserTimeUserTimer(team->id);
  Line 1296 [new]: timer = new(std::nothrow) TeamTimeUserTimer(clockID);
  Line 1384 [new]: (new = old + changedBy).
  Line 1403 [new]: (new = old + changedBy).
  Line 1643 [user_memcpy]: || user_memcpy(userTime, &time, sizeof(time)) != B_OK) {
  Line 1759 [user_memcpy]: || user_memcpy(userclockID, &clockID, sizeof(clockID)) != B_OK)) {
  Line 1775 [user_memcpy]: || user_memcpy(&event, userEvent, sizeof(event)) != B_OK) {
  Line 1866 [user_memcpy]: || user_memcpy(userInfo, &info, sizeof(info)) != B_OK)) {
  Line 1904 [user_memcpy]: || user_memcpy(userOldInfo, &oldInfo, sizeof(oldInfo)) != B_OK)) {
  Line 1197 [panic]: panic("UserTimerList::AddTimer(): timer with ID %" B_PRId32
  Line 1078 [TODO]: // TODO: To avoid odd race conditions, we should check the current time of
  Line 1154 [TODO]: // TODO: Use a more efficient data structure. E.g. a sorted array.

File: src/system/kernel/arch/arm/arch_asm.S
  Line 67 [new]: struct arch_thread* newState); */
  Line 97 [user_memcpy]: /* status_t arch_cpu_user_memcpy(void *to, const void *from, size_t size, addr_t *faultHandler) */
  Line 98 [user_memcpy]: FUNCTION(_arch_cpu_user_memcpy):
  Line 102 [user_memcpy]: ldr	r4, =.L_user_memcpy_error
  Line 128 [user_memcpy]: .L_user_memcpy_error:
  Line 133 [user_memcpy]: FUNCTION_END(_arch_cpu_user_memcpy)

File: src/system/kernel/arch/arm/arch_atomic32.cpp
  Line 28 [new]: atomic_set(int32 *value, int32 newValue)
  Line 31 [new]: *value = newValue;
  Line 35 [new]: atomic_get_and_set(int32 *value, int32 newValue)
  Line 39 [new]: atomic_set(value, newValue);
  Line 44 [new]: atomic_test_and_set(int32 *value, int32 newValue, int32 testAgainst)
  Line 50 [new]: *value = newValue;
  Line 94 [new]: _user_atomic_set(int32 *value, int32 newValue)
  Line 98 [new]: atomic_set(value, newValue);
  Line 109 [new]: _user_atomic_get_and_set(int32 *value, int32 newValue)
  Line 113 [new]: int32 oldValue = atomic_get_and_set(value, newValue);
  Line 124 [new]: _user_atomic_test_and_set(int32 *value, int32 newValue, int32 testAgainst)
  Line 128 [new]: int32 oldValue = atomic_test_and_set((int32*)value, newValue, testAgainst);

File: src/system/kernel/arch/arm/arch_atomic64.cpp
  Line 25 [new]: * operations. Anything newer is capable, and does therefore not
  Line 34 [new]: atomic_set64(int64 *value, int64 newValue)
  Line 38 [new]: *value = newValue;
  Line 43 [new]: atomic_get_and_set64(int64 *value, int64 newValue)
  Line 48 [new]: *value = newValue;
  Line 54 [new]: atomic_test_and_set64(int64 *value, int64 newValue, int64 testAgainst)
  Line 60 [new]: *value = newValue;
  Line 107 [new]: _user_atomic_get_and_set64(int64 *value, int64 newValue)
  Line 111 [new]: int64 oldValue = atomic_get_and_set64(value, newValue);
  Line 123 [new]: _user_atomic_set64(int64 *value, int64 newValue)
  Line 127 [new]: atomic_set64(value, newValue);
  Line 139 [new]: _user_atomic_test_and_set64(int64 *value, int64 newValue, int64 testAgainst)
  Line 143 [new]: int64 oldValue = atomic_test_and_set64(value, newValue, testAgainst);

File: src/system/kernel/arch/arm/arch_commpage.cpp
  Line 55 [panic]: panic("register_commpage_function(): Failed to find "

File: src/system/kernel/arch/arm/arch_cpu.cpp
  Line 30 [panic]: panic("No SMP support on ARM yet!\n");

File: src/system/kernel/arch/arm/arch_debug.cpp
  Line 119 [malloc]: char* buffer = (char*)debug_malloc(kBufferSize);
  Line 468 [TODO]: // TODO: Implement!
  Line 476 [TODO]: // TODO: Implement!
  Line 484 [TODO]: // TODO: Implement!
  Line 492 [TODO]: // TODO: Implement!
  Line 500 [TODO]: // TODO: Implement!
  Line 528 [TODO]: // TODO: Implement!
  Line 535 [TODO]: // TODO: Implement!

File: src/system/kernel/arch/arm/arch_debug_console.cpp
  Line 42 [TODO]: // TODO: Implement correctly!
  Line 57 [TODO]: // TODO: Implement correctly!

File: src/system/kernel/arch/arm/arch_elf.cpp
  Line 342 [TODO]: // TODO: Get the GOT address!
  Line 349 [TODO]: // TODO: Get the PLT address!
  Line 399 [FIXME]: #warning ARM: FIXME!!!!!!!

File: src/system/kernel/arch/arm/arch_int.cpp
  Line 158 [new]: InterruptController *ic = new(std::nothrow) GICv2InterruptController(
  Line 165 [new]: InterruptController *ic = new(std::nothrow) OMAP3InterruptController(
  Line 171 [new]: InterruptController *ic = new(std::nothrow) PXAInterruptController(
  Line 177 [new]: InterruptController *ic = new(std::nothrow) Sun4iInterruptController(
  Line 356 [new]: addr_t newip = 0;
  Line 435 [new]: vm_page_fault(far, frame->pc, isWrite, isExec, isUser, &newip);
  Line 437 [new]: if (newip != 0) {
  Line 440 [new]: frame->pc = newip;
  Line 258 [user_memcpy]: status_t res = user_memcpy(&args[4], (void *)iframe->usr_sp,
  Line 405 [user_memcpy]: // TODO: Now we are generally allowing user_memcpy() with interrupts
  Line 153 [panic]: panic("user vector page @ %p could not be created (%x)!",
  Line 182 [panic]: panic("No interrupt controllers found!\n");
  Line 233 [panic]: panic("not handled!");
  Line 390 [panic]: panic("page fault in debugger without fault handler! Touching "
  Line 395 [panic]: panic("PXN violation trying to execute user-mapped address 0x%08" B_PRIxADDR " from kernel mode\n",
  Line 398 [panic]: panic("unhandled alignment exception\n");
  Line 400 [panic]: panic("unhandled access flag fault\n");
  Line 417 [panic]: panic("page fault, interrupts disabled, fault handler loop. "
  Line 423 [panic]: // allowed to happen and we must panic.
  Line 424 [panic]: panic("page fault, but interrupts were disabled. Touching address "
  Line 428 [panic]: panic("page fault not allowed at this place. Touching address "
  Line 501 [panic]: panic("FIQ not implemented yet!");
  Line 405 [TODO]: // TODO: Now we are generally allowing user_memcpy() with interrupts

File: src/system/kernel/arch/arm/arch_int_gicv2.cpp
  Line 25 [panic]: panic("not able to map the memory area for gicd\n");
  Line 33 [panic]: panic("not able to map the memory area for gicc\n");
  Line 42 [TODO]: // TODO: disable all interrupts

File: src/system/kernel/arch/arm/arch_smp.cpp
  Line 40 [panic]: panic("arch_smp_send_multicast_ici: called with interrupts enabled");
  Line 48 [panic]: panic("called arch_smp_send_ici!\n");
  Line 55 [panic]: panic("called arch_smp_send_broadcast_ici\n");

File: src/system/kernel/arch/arm/arch_system_info.cpp
  Line 32 [TODO]: // TODO: ARM_64?
  Line 37 [TODO]: //TODO node->data.package.vendor = sCPUVendor;
  Line 42 [TODO]: //TODO node->data.core.model = sPVR;
  Line 43 [TODO]: //TODO node->data.core.default_frequency = sCPUClockFrequency;

File: src/system/kernel/arch/arm/arch_thread.cpp
  Line 42 [new]: // a new thread structure.
  Line 148 [new]: VMAddressSpace *newAddressSpace = to->team->address_space;
  Line 149 [new]: VMTranslationMap *newTranslationMap = newAddressSpace->TranslationMap();
  Line 150 [new]: phys_addr_t newPageDirectoryAddress =
  Line 151 [new]: ((ARMVMTranslationMap *)newTranslationMap)->PagingStructures()->pgdir_phys;
  Line 153 [new]: if (oldPageDirectoryAddress != newPageDirectoryAddress) {
  Line 156 [new]: oldPageDirectoryAddress, newPageDirectoryAddress);
  Line 157 [new]: arm_swap_pgdir(newPageDirectoryAddress);
  Line 288 [user_memcpy]: status_t res = user_memcpy(userStack, signalFrameData,
  Line 296 [user_memcpy]: ASSERT(user_memcpy(&signalHandlerAddr,
  Line 220 [panic]: panic("arch_on_signal_stack(): No user iframe!");
  Line 252 [panic]: panic("arch_setup_signal_frame(): No user iframe!");
  Line 315 [panic]: panic("arch_restore_signal_frame(): No user iframe!");
  Line 355 [panic]: panic("arch_store_fork_frame(): No user iframe!");
  Line 133 [TODO]: //TODO: update Context ID (incl. ASID)
  Line 134 [TODO]: //TODO: check if any additional TLB or Cache maintenance is needed

File: src/system/kernel/arch/arm/arch_timer.cpp
  Line 70 [panic]: panic("No hardware timer found!\n");

File: src/system/kernel/arch/arm/arch_timer_generic.h
  Line 8 [new]: #include <new>
  Line 20 [new]: ARMGenericTimer *timer = new(std::nothrow) ARMGenericTimer();

File: src/system/kernel/arch/arm/arch_uart_8250_omap.cpp
  Line 14 [new]: #include <new>
  Line 65 [new]: ArchUART8250Omap* uart = new(buffer) ArchUART8250Omap(base, clock);

File: src/system/kernel/arch/arm/arch_uart_pl011.cpp
  Line 14 [new]: #include <new>
  Line 330 [new]: ArchUARTPL011 *uart = new(buffer) ArchUARTPL011(base, clock);
  Line 166 [TODO]: Out32(PL011_LCRH, 0); // TODO: ST is different tx, rx lcr

File: src/system/kernel/arch/arm/arch_vm.cpp
  Line 77 [panic]: panic("arch_vm_init_end(): No page mapping for %p\n", address);
  Line 86 [panic]: panic("arch_vm_init_end(): Failed to create area for boot loader "
  Line 123 [TODO]: // TODO check ARM protection possibilities

File: src/system/kernel/arch/arm/arch_vm_translation_map.cpp
  Line 80 [new]: gARMPagingMethod = new(&sPagingMethodBuffer) ARMPagingMethod32Bit;
  Line 78 [TODO]: //TODO: check for LPAE / long-descriptor format

File: src/system/kernel/arch/arm/paging/32bit/ARMPagingMethod32Bit.cpp
  Line 197 [new]: PhysicalPageSlotPool* pool = new(std::nothrow) PhysicalPageSlotPool;
  Line 294 [new]: new(&pool[i]) PhysicalPageSlotPool;
  Line 341 [new]: ARMVMTranslationMap32Bit* map = new(std::nothrow) ARMVMTranslationMap32Bit;
  Line 388 [new]: // zero it out in it's new mapping
  Line 95 [panic]: panic("LargeMemoryPhysicalPageMapper::Init(): Failed to reserve "
  Line 105 [panic]: panic("ARMPagingMethod32Bit::PhysicalPageSlotPool::InitInitial(): "
  Line 131 [panic]: panic("LargeMemoryPhysicalPageMapper::InitPostArea(): Failed to "
  Line 143 [panic]: panic("LargeMemoryPhysicalPageMapper::InitPostArea(): Failed to "
  Line 297 [panic]: panic("ARMPagingMethod32Bit::Init(): Failed to create initial pool "
  Line 360 [panic]: panic("ran out of early page tables");
  Line 306 [TODO]: // TODO: Select the best page mapper!
  Line 550 [TODO]: //! TODO: currently assumes this translation map is active

File: src/system/kernel/arch/arm/paging/32bit/ARMPagingMethod32Bit.h
  Line 62 [new]: page_table_entry newEntry);
  Line 67 [new]: page_table_entry newEntry,
  Line 113 [new]: page_table_entry newEntry)
  Line 115 [new]: return atomic_get_and_set((int32*)entry, newEntry);
  Line 129 [new]: page_table_entry newEntry, page_table_entry oldEntry)
  Line 131 [new]: return atomic_test_and_set((int32*)entry, newEntry, oldEntry);

File: src/system/kernel/arch/arm/paging/32bit/ARMPagingStructures32Bit.cpp
  Line 68 [new]: // zero out the bottom portion of the new pgdir
  Line 72 [new]: // insert this new map into the map list
  Line 119 [new]: new (&sPagingStructuresList) PagingStructuresList;
  Line 105 [panic]: panic("deleting a still active page directory\n");

File: src/system/kernel/arch/arm/paging/32bit/ARMVMTranslationMap32Bit.cpp
  Line 90 [new]: fPagingStructures = new(std::nothrow) ARMPagingStructures32Bit;
  Line 518 [new]: uint32 newProtectionFlags = ARMPagingMethod32Bit::AttributesToPageTableEntryFlags(attributes);
  Line 519 [new]: uint32 newMemoryTypeFlags = ARMPagingMethod32Bit::MemoryTypeToPageTableEntryFlags(memoryType);
  Line 548 [new]: // set the new protection flags -- we want to do that atomically,
  Line 556 [new]: | newProtectionFlags | newMemoryTypeFlags,
  Line 71 [panic]: panic("destroy_tmap: didn't find pgtable page\n");
  Line 423 [TODO]: // TODO: As in UnmapPage() we can lose page dirty flags here. ATM it's not

File: src/system/kernel/arch/arm/paging/arm_physical_page_mapper_large_memory.cpp
  Line 29 [new]: #include <new>
  Line 469 [new]: = new(std::nothrow) LargeMemoryTranslationMapPhysicalPageMapper;
  Line 716 [new]: // allocate new pool
  Line 770 [new]: new(&sPhysicalPageMapper) LargeMemoryPhysicalPageMapper;
  Line 625 [user_memcpy]: error = user_memcpy(to, (void*)(slot->address + pageOffset),
  Line 665 [user_memcpy]: error = user_memcpy((void*)(slot->address + pageOffset), from,
  Line 325 [panic]: panic("PhysicalPageOpsCPUData::Init(): Failed to get initial "
  Line 449 [panic]: panic("LargeMemoryPhysicalPageMapper::Init(): Failed to init "

File: src/system/kernel/arch/arm/soc.h
  Line 27 [panic]: panic("Multiple InterruptController objects created; that is currently unsupported!");
  Line 52 [panic]: panic("Multiple HardwareTimer objects created; that is currently unsupported!");

File: src/system/kernel/arch/arm/soc_omap3.cpp
  Line 104 [panic]: panic("OMAP3InterruptController: cannot map registers!");
  Line 194 [panic]: panic("Cannot map OMAP3Timer registers!");
  Line 198 [panic]: panic("Cannot get OMAP3Timer interrupt!");

File: src/system/kernel/arch/arm/soc_omap3.h
  Line 8 [new]: #include <new>
  Line 34 [new]: OMAP3Timer *timer = new(std::nothrow) OMAP3Timer(reg_base, interrupt);

File: src/system/kernel/arch/arm/soc_pxa.cpp
  Line 51 [panic]: panic("PXAInterruptController: cannot map registers!");
  Line 152 [panic]: panic("Cannot map PXATimer registers!");

File: src/system/kernel/arch/arm/soc_pxa.h
  Line 8 [new]: #include <new>
  Line 31 [new]: PXATimer *timer = new(std::nothrow) PXATimer(reg_base);

File: src/system/kernel/arch/arm/soc_sun4i.cpp
  Line 80 [panic]: panic("Sun4iInterruptController: cannot map registers!");
  Line 56 [FIXME]: // FIXME can we use the hardware managed interrupt vector instead?

File: src/system/kernel/arch/arm64/PMAPPhysicalPageMapper.cpp
  Line 46 [user_memcpy]: return user_memcpy(to, reinterpret_cast<void*>(KERNEL_PMAP_BASE + from), length);
  Line 60 [user_memcpy]: return user_memcpy(reinterpret_cast<void*>(KERNEL_PMAP_BASE + to), from, length);

File: src/system/kernel/arch/arm64/VMSAv8TranslationMap.cpp
  Line 326 [new]: // Make a new page sub-table.
  Line 327 [new]: // The parent table is `ptPa`, and the new sub-table's PTE will be at `index`
  Line 329 [new]: // Returns the physical address of the new table, or the address of the existing
  Line 347 [new]: // Create new table there
  Line 349 [new]: phys_addr_t newTablePa = page->physical_page_number << fPageBits;
  Line 360 [new]: newTablePa | kPteTypeL012Table, oldPte);
  Line 371 [new]: return newTablePa;
  Line 457 [new]: // When reservation is null, we can't create a new subtable. This can be intentional,
  Line 588 [new]: uint64_t newPte = effectivePa | attr | kPteTypeL3Page;
  Line 590 [new]: if (newPte == oldPte)
  Line 595 [new]: // entry and flush the TLB as appropriate before we can write the new PTE.
  Line 600 [new]: // Install the new PTE
  Line 601 [new]: atomic_set64((int64*)ptePtr, newPte);
  Line 810 [new]: uint64_t newPte = oldPte & ~kPteAttrMask;
  Line 811 [new]: newPte |= attr;
  Line 814 [new]: newPte |= oldPte & kAttrAF;
  Line 818 [new]: newPte = set_pte_dirty(newPte);
  Line 821 [new]: uint64_t newMemoryType = newPte & (kAttrShareability | kAttrMemoryAttrIdx);
  Line 822 [new]: if (oldMemoryType != newMemoryType) {
  Line 824 [new]: // entry and flush the TLB as appropriate before we can write the new PTE.
  Line 830 [new]: atomic_set64((int64_t*)ptePtr, newPte);
  Line 837 [new]: if ((uint64_t)atomic_test_and_set64((int64_t*)ptePtr, newPte, oldPte) == oldPte) {
  Line 869 [new]: uint64_t newPte = oldPte & ~kAttrAF;
  Line 870 [new]: newPte = set_pte_clean(newPte);
  Line 872 [new]: if ((uint64_t)atomic_test_and_set64((int64_t*)ptePtr, newPte, oldPte) == oldPte) {
  Line 884 [new]: uint64_t newPte = set_pte_clean(oldPte);
  Line 885 [new]: if ((uint64_t)atomic_test_and_set64((int64_t*)ptePtr, newPte, oldPte) == oldPte) {
  Line 917 [new]: uint64_t newPte = oldPte & ~kAttrAF;
  Line 918 [new]: newPte = set_pte_clean(newPte);
  Line 922 [new]: newPte = 0;
  Line 924 [new]: if ((uint64_t)atomic_test_and_set64((int64_t*)ptePtr, newPte, oldPte) == oldPte)
  Line 49 [panic]: panic("Could not free ASID!");
  Line 206 [panic]: panic("cannot assign ASID");
  Line 248 [panic]: panic("VMSAv8TranslationMap::MappedSize not implemented");
  Line 494 [panic]: panic("MAIR entry not found");
  Line 540 [TODO]: // TODO: This probably should be nGnRE for PCI
  Line 710 [TODO]: // TODO: As in UnmapPage() we can lose page dirty flags here. ATM it's not

File: src/system/kernel/arch/arm64/arch_commpage.cpp
  Line 26 [panic]: panic("register_commpage_function(): Failed to find signal frame function \"%s\"!",

File: src/system/kernel/arch/arm64/arch_debug.cpp
  Line 111 [malloc]: char* buffer = (char*)debug_malloc(kBufferSize);

File: src/system/kernel/arch/arm64/arch_debug_console.cpp
  Line 35 [TODO]: // TODO: Implement correctly!
  Line 50 [TODO]: // TODO: Implement correctly!

File: src/system/kernel/arch/arm64/arch_int.cpp
  Line 99 [new]: ic = new(std::nothrow) GICv2InterruptController(
  Line 157 [new]: uint64_t newPte = oldPte | kAttrAF;
  Line 158 [new]: if ((uint64_t)atomic_test_and_set64((int64*)pte, newPte, oldPte) != oldPte)
  Line 165 [new]: uint64_t newPte = oldPte & ~kAttrAPReadOnly;
  Line 166 [new]: if ((uint64_t)atomic_test_and_set64((int64*)pte, newPte, oldPte) != oldPte)
  Line 346 [user_memcpy]: || user_memcpy(&args[8], (void*)frame->sp, (count - 8) * 8) != B_OK) {
  Line 323 [panic]: panic("unhandled pagefault! FAR=%lx ELR=%lx ESR=%lx",
  Line 372 [panic]: panic("syscall restart");
  Line 382 [panic]: panic("unhandled exception! FAR=%lx ELR=%lx ESR=%lx (EC=%lx)",
  Line 396 [panic]: panic("unhandled error! FAR=%lx ELR=%lx ESR=%lx", frame->far, frame->elr, frame->esr);
  Line 430 [panic]: panic("do_fiq_handler");
  Line 125 [TODO]: // TODO: reuse things from VMSAv8TranslationMap

File: src/system/kernel/arch/arm64/arch_thread.cpp
  Line 124 [user_memcpy]: status_t ret = user_memcpy(&threadExitAddr,
  Line 157 [panic]: panic("arch_setup_signal_frame");
  Line 172 [panic]: panic("arch_store_fork_frame");

File: src/system/kernel/arch/arm64/arch_uart_linflex.cpp
  Line 13 [new]: #include <new>
  Line 198 [new]: ArchUARTlinflex *uart = new(buffer) ArchUARTlinflex(base, clock);
  Line 31 [TODO]: // TODO: good to go

File: src/system/kernel/arch/arm64/arch_vm.cpp
  Line 70 [panic]: panic("arch_vm_init_end(): No page mapping for %p\n", address);
  Line 79 [panic]: panic("arch_vm_init_end(): Failed to create area for boot loader "

File: src/system/kernel/arch/arm64/arch_vm_translation_map.cpp
  Line 51 [new]: *_map = new (std::nothrow) VMSAv8TranslationMap(kernel, pt, 12, 48, 1);
  Line 104 [new]: *_physicalPageMapper = new (&sPhysicalPageMapperData) PMAPPhysicalPageMapper();
  Line 181 [new]: uint64_t* newTableVa = TableFromPa(table);
  Line 188 [new]: newTableVa[i] = pteVal + i * entrySize;
  Line 190 [new]: memset(newTableVa, 0, 1 << page_bits);
  Line 143 [TODO]: // TODO: reuse some bits from VMSAv8TranslationMap

File: src/system/kernel/arch/generic/GenericVMPhysicalPageMapper.cpp
  Line 44 [TODO]: // TODO:...
  Line 53 [TODO]: // TODO:...
  Line 62 [TODO]: // TODO:...
  Line 70 [TODO]: // TODO:...

File: src/system/kernel/arch/generic/acpi_irq_routing_table.cpp
  Line 231 [new]: // A new link device, read possible IRQs and fill them in.
  Line 232 [new]: link = new(std::nothrow) link_device;
  Line 554 [new]: irq_routing_entry newEntry = *irqEntry;
  Line 555 [new]: newEntry.device_address = (device << 16) | 0xffff;
  Line 556 [new]: newEntry.pin = interruptPin - 1;
  Line 557 [new]: newEntry.pci_bus = bus;
  Line 558 [new]: newEntry.pci_device = device;
  Line 559 [new]: newEntry.pci_function_mask = 1 << function;
  Line 564 [new]: if (newEntry.bios_irq != 0 && newEntry.bios_irq != 255
  Line 565 [new]: && newEntry.bios_irq != biosIRQ) {
  Line 575 [new]: newEntry.bios_irq = biosIRQ;
  Line 579 [new]: print_irq_routing_entry(newEntry);
  Line 581 [new]: matchedTable.PushBack(newEntry);
  Line 234 [panic]: panic("ran out of memory while configuring irq link devices");
  Line 242 [panic]: panic("failed to read possible irqs of link device");
  Line 249 [panic]: panic("failed to read current irq of link device");
  Line 570 [panic]: panic("calculated irq routing doesn't match bios for "
  Line 852 [panic]: panic("failed to configure link devices");
  Line 31 [TODO]: // fields in ACPI. TODO: Query both/the correct root device.
  Line 33 [TODO]: // TODO: as per PCI 3.0, the PCI module hardcodes it in various places as well.
  Line 36 [TODO]: // TODO: actually this is mechanism dependent
  Line 792 [TODO]: // TODO: handle

File: src/system/kernel/arch/generic/debug_uart_8250.cpp
  Line 27 [new]: #include <new>
  Line 189 [new]: DebugUART8250* uart = new(buffer) DebugUART8250(base, clock);

File: src/system/kernel/arch/generic/generic_vm_physical_page_mapper.cpp
  Line 140 [panic]: panic("someone called put_physical_page on an invalid va 0x%lx\n", va);
  Line 148 [panic]: panic("put_physical_page called on page at va 0x%lx which is not checked out\n",
  Line 255 [panic]: panic("generic_vm_physical_page_mapper_init(): Failed to reserve IO "
  Line 310 [panic]: panic("generic_vm_physical_page_mapper_init_post_area(): Failed to "

File: src/system/kernel/arch/generic/generic_vm_physical_page_ops.cpp
  Line 61 [user_memcpy]: error = user_memcpy(to, (void*)(virtualAddress + pageOffset),
  Line 101 [user_memcpy]: error = user_memcpy((void*)(virtualAddress + pageOffset), from,
  Line 135 [panic]: panic("generic_vm_memcpy_physical_page(): Failed to map source page!");
  Line 148 [panic]: panic("generic_vm_memcpy_physical_page(): Failed to map destination "

File: src/system/kernel/arch/m68k/arch_asm.S
  Line 88 [new]: // void m68k_context_switch(addr_t *old_sp, addr_t new_sp);

File: src/system/kernel/arch/m68k/arch_atomic.cpp
  Line 28 [new]: atomic_set64(vint64 *value, int64 newValue)
  Line 35 [new]: *value = newValue;
  Line 42 [new]: atomic_test_and_set64(vint64 *value, int64 newValue, int64 testAgainst)
  Line 50 [new]: *value = newValue;
  Line 112 [new]: _user_atomic_set64(vint64 *value, int64 newValue)
  Line 123 [new]: *value = newValue;
  Line 135 [new]: _user_atomic_test_and_set64(vint64 *value, int64 newValue, int64 testAgainst)
  Line 147 [new]: *value = newValue;

File: src/system/kernel/arch/m68k/arch_cpu.cpp
  Line 82 [panic]: panic("unknown cpu_type %d\n", arch_cpu_type);
  Line 198 [TODO]: // TODO: This doesn't work correctly with gcc 4 anymore!

File: src/system/kernel/arch/m68k/arch_debug.cpp
  Line 142 [new]: // switch to the page directory of the new thread to be
  Line 144 [new]: addr_t newPageDirectory = (addr_t)x86_next_page_directory(
  Line 147 [new]: if (newPageDirectory != 0) {
  Line 149 [new]: write_cr3(newPageDirectory);
  Line 130 [TODO]: // TODO: Add support for stack traces of other threads.
  Line 298 [TODO]: // TODO: Correctly determine whether this is a kernel address!
  Line 343 [TODO]: // TODO: Implement!
  Line 351 [TODO]: // TODO: Implement!
  Line 359 [TODO]: // TODO: Implement! Most likely in assembly.
  Line 367 [TODO]: // TODO: Implement!
  Line 375 [TODO]: // TODO: Implement!
  Line 383 [TODO]: // TODO: Implement!
  Line 391 [TODO]: // TODO: Implement!

File: src/system/kernel/arch/m68k/arch_debug_console.cpp
  Line 37 [TODO]: // TODO: Implement correctly!
  Line 52 [TODO]: // TODO: Implement correctly!

File: src/system/kernel/arch/m68k/arch_elf.cpp
  Line 161 [TODO]: // TODO: Get the GOT address!
  Line 168 [TODO]: // TODO: Get the PLT address!
  Line 212 [TODO]: // TODO: Implement!

File: src/system/kernel/arch/m68k/arch_int.cpp
  Line 245 [new]: addr_t newip;
  Line 251 [new]: &newip);
  Line 252 [new]: if (newip != 0) {
  Line 255 [new]: iframe->cpu.pc = newip;
  Line 347 [new]: /* point VBR to the new table */
  Line 497 [new]: PICModule *module = new(nothrow) PICModule(moduleInfo);
  Line 222 [user_memcpy]: // TODO: Now we are generally allowing user_memcpy() with interrupts
  Line 169 [panic]: panic("can't determine r/w from iframe type %d\n",
  Line 198 [panic]: panic("system reset exception\n");
  Line 214 [panic]: panic("page fault in debugger without fault handler! Touching "
  Line 232 [panic]: // we must panic
  Line 233 [panic]: panic("page fault, but interrupts were disabled. Touching "
  Line 238 [panic]: panic("page fault not allowed at this place. Touching address "
  Line 273 [panic]: panic("m68k_exception_entry(): external interrupt although we "
  Line 304 [panic]: panic("unhandled exception type\n");
  Line 532 [panic]: panic("arch_int_init_post_device_manager(): Found no PIC modules!");
  Line 541 [panic]: panic("arch_int_init_post_device_manager(): Failed to get device "
  Line 579 [panic]: panic("arch_int_init_post_device_manager(): Found no supported PIC!");
  Line 604 [panic]: panic("m68k_set_current_cpu_exception_context(): Failed to get physical "
  Line 78 [TODO]: // TODO: I have no idea, what IRQ type is appropriate.
  Line 222 [TODO]: // TODO: Now we are generally allowing user_memcpy() with interrupts
  Line 284 [TODO]: // TODO: correctly pass level-triggered vs. edge-triggered to the handler!

File: src/system/kernel/arch/m68k/arch_platform.cpp
  Line 11 [new]: #include <new>
  Line 68 [panic]: panic("unknown platform d\n", kernelArgs->arch_args.platform);

File: src/system/kernel/arch/m68k/arch_smp.cpp
  Line 40 [panic]: panic("arch_smp_send_multicast_ici: called with interrupts enabled");
  Line 48 [panic]: panic("called arch_smp_send_ici!\n");
  Line 55 [panic]: panic("called arch_smp_send_broadcast_ici\n");

File: src/system/kernel/arch/m68k/arch_system_info.cpp
  Line 55 [TODO]: sCPURevision = args->arch_args.cpu_type; //TODO:is it what we want?

File: src/system/kernel/arch/m68k/arch_thread.cpp
  Line 36 [new]: // a new thread structure.
  Line 203 [new]: addr_t newPageDirectory;
  Line 205 [new]: newPageDirectory = (addr_t)m68k_next_page_directory(from, to);
  Line 207 [new]: if ((newPageDirectory % B_PAGE_SIZE) != 0)
  Line 208 [new]: panic("arch_thread_context_switch: bad pgdir 0x%lx\n", newPageDirectory);
  Line 211 [new]: //m68k_set_pgdir((void *)newPageDirectory);
  Line 212 [new]: gM68KPagingMethod->SetPageRoot(newPageDirectory);
  Line 187 [panic]: panic("arch_thread_init_kthread_stack(): Implement me!");
  Line 208 [panic]: panic("arch_thread_context_switch: bad pgdir 0x%lx\n", newPageDirectory);
  Line 230 [panic]: panic("arch_thread_enter_uspace(): not yet implemented\n");
  Line 195 [TODO]: // TODO: Implement!

File: src/system/kernel/arch/m68k/arch_vm.cpp
  Line 83 [panic]: panic("arch_vm_init_end(): Failed to create area for boot loader "

File: src/system/kernel/arch/m68k/arch_vm_translation_map.cpp
  Line 106 [new]: gM68KPagingMethod = new(&sPagingMethodBuffer) M68KPagingMethod030;
  Line 110 [new]: gM68KPagingMethod = new(&sPagingMethodBuffer) M68KPagingMethod040;
  Line 114 [new]: gM68KPagingMethod = new(&sPagingMethodBuffer) M68KPagingMethod060;

File: src/system/kernel/arch/m68k/arch_vm_translation_map_impl.cpp
  Line 1179 [malloc]: map->arch_data = (vm_translation_map_arch_info *)malloc(sizeof(vm_translation_map_arch_info));
  Line 1173 [new]: // initialize the new object
  Line 1206 [new]: // zero out the bottom portion of the new rtdir
  Line 1210 [new]: // insert this new map into the map list
  Line 355 [panic]: panic("rtdir[%d]: buggy descriptor type", i);
  Line 370 [panic]: panic("rtdir[%d][%d]: buggy descriptor type", i, j);
  Line 378 [panic]: panic("destroy_tmap: didn't find pgtable page\n");
  Line 1076 [panic]: panic("map_iospace_chunk: passed invalid va 0x%lx\n", va);
  Line 1151 [TODO]: // TODO: Replace the *_current_cpu() and *_debug() versions!
  Line 1157 [TODO]: // TODO: Verify that this is safe to use!
  Line 1363 [TODO]: // TODO: Note, this only works as long as all pages belong to the same
  Line 1523 [TODO]: // TODO: Implement!
  Line 498 [FIXME]: #warning M68K: FIXME?
  Line 1338 [FIXME]: #warning M68K: FIXME

File: src/system/kernel/arch/m68k/paging/040/M68KPagingMethod040.cpp
  Line 264 [new]: PhysicalPageSlotPool* pool = new(std::nothrow) PhysicalPageSlotPool;
  Line 379 [new]: = new(&PhysicalPageSlotPool::sInitialPhysicalPagePool)
  Line 453 [new]: map = new(std::nothrow) M68KVMTranslationMap040;
  Line 568 [new]: // zero it out in it's new mapping
  Line 167 [panic]: panic("LargeMemoryPhysicalPageMapper::Init(): Failed to reserve "
  Line 200 [panic]: panic("LargeMemoryPhysicalPageMapper::InitPostArea(): Failed to "
  Line 212 [panic]: panic("LargeMemoryPhysicalPageMapper::InitPostArea(): Failed to "
  Line 307 [panic]: panic("I'm lazy");
  Line 383 [panic]: panic("M68KPagingMethod040::Init(): Failed to create initial pool "
  Line 391 [TODO]: // TODO: Select the best page mapper!
  Line 429 [TODO]: // TODO: Note, this only works as long as all pages belong to the same
  Line 598 [TODO]: #warning M68K:TODO:override this for 060
  Line 701 [TODO]: //! TODO: currently assumes this translation map is active
  Line 306 [FIXME]: #warning M68K:FIXME: insert *all* page tables!

File: src/system/kernel/arch/m68k/paging/040/M68KPagingMethod040.h
  Line 73 [new]: page_table_entry newEntry);
  Line 78 [new]: page_table_entry newEntry,
  Line 122 [new]: page_table_entry newEntry)
  Line 124 [new]: return atomic_get_and_set((int32*)entry, newEntry);
  Line 138 [new]: page_table_entry newEntry, page_table_entry oldEntry)
  Line 140 [new]: return atomic_test_and_set((int32*)entry, newEntry, oldEntry);

File: src/system/kernel/arch/m68k/paging/040/M68KPagingStructures040.cpp
  Line 68 [new]: // zero out the bottom portion of the new pgroot
  Line 72 [new]: // insert this new map into the map list
  Line 120 [new]: new (&sPagingStructuresList) PagingStructuresList;
  Line 106 [panic]: panic("deleting a still active page directory\n");
  Line 128 [TODO]: #warning M68K: TODO: allocate all kernel pgdirs at boot and remove this (also dont remove them anymore from unmap)
  Line 129 [FIXME]: #warning M68K:FIXME

File: src/system/kernel/arch/m68k/paging/040/M68KVMTranslationMap040.cpp
  Line 139 [new]: fPagingStructures = new(std::nothrow) M68KPagingStructures040;
  Line 756 [new]: uint32 newProtectionFlags = 0;
  Line 758 [new]: newProtectionFlags = M68K_PTE_USER;
  Line 760 [new]: newProtectionFlags |= M68K_PTE_WRITABLE;
  Line 762 [new]: newProtectionFlags = M68K_PTE_WRITABLE;
  Line 791 [new]: // set the new protection flags -- we want to do that atomically,
  Line 799 [new]: | newProtectionFlags
  Line 73 [panic]: panic("rtdir[%ld]: buggy descriptor type", i);
  Line 89 [panic]: panic("pgroot[%ld][%ld]: buggy descriptor type", i, j);
  Line 97 [panic]: panic("destroy_tmap: didn't find pgtable page\n");
  Line 120 [panic]: panic("destroy_tmap: didn't find pgtable page\n");
  Line 600 [TODO]: // TODO: As in UnmapPage() we can lose page dirty flags here. ATM it's not
  Line 190 [FIXME]: #warning M68K: FIXME?

File: src/system/kernel/arch/m68k/paging/m68k_physical_page_mapper_large_memory.cpp
  Line 30 [new]: #include <new>
  Line 468 [new]: = new(std::nothrow) LargeMemoryTranslationMapPhysicalPageMapper;
  Line 714 [new]: // allocate new pool
  Line 767 [new]: new(&sPhysicalPageMapper) LargeMemoryPhysicalPageMapper;
  Line 623 [user_memcpy]: error = user_memcpy(to, (void*)(slot->address + pageOffset),
  Line 663 [user_memcpy]: error = user_memcpy((void*)(slot->address + pageOffset), from,
  Line 330 [panic]: panic("PhysicalPageOpsCPUData::Init(): Failed to get initial "
  Line 448 [panic]: panic("LargeMemoryPhysicalPageMapper::Init(): Failed to init "

File: src/system/kernel/arch/mips/arch_pmap.cpp
  Line 39 [panic]: panic("pmap_unmap_page unimplemented!\n");

File: src/system/kernel/arch/mips/arch_smp.cpp
  Line 20 [panic]: panic("called arch_smp_send_ici!\n");
  Line 25 [panic]: panic("called arch_smp_send_broadcast_ici\n");

File: src/system/kernel/arch/mips/arch_vm.cpp
  Line 21 [panic]: panic("map_page_into_kspace: XXX finish or dont use!\n");

File: src/system/kernel/arch/ppc/arch_asm.S
  Line 225 [new]: // void ppc_context_switch(addr_t *old_sp, addr_t new_sp);
  Line 283 [new]: // restore the new stack pointer
  Line 286 [new]: // restore the new regs
  Line 418 [user_memcpy]: /* status_t arch_cpu_user_memcpy(void *to, const void *from, size_t size, addr_t *faultHandler) */
  Line 419 [user_memcpy]: FUNCTION(_arch_cpu_user_memcpy):
  Line 422 [user_memcpy]: FUNCTION_END(_arch_cpu_user_memcpy)
  Line 17 [TODO]: // TODO: FIXME
  Line 77 [TODO]: // TODO: FIXME
  Line 420 [TODO]: // TODO
  Line 427 [TODO]: // TODO
  Line 434 [TODO]: // TODO
  Line 17 [FIXME]: // TODO: FIXME
  Line 77 [FIXME]: // TODO: FIXME

File: src/system/kernel/arch/ppc/arch_cpu.cpp
  Line 179 [user_memcpy]: arch_cpu_user_memcpy(void *to, const void *from, size_t size,
  Line 36 [TODO]: // TODO: Let the boot loader put that info into the kernel args
  Line 175 [TODO]: // TODO: all functions that use fault handlers need to be implemented
  Line 186 [TODO]: // TODO: This doesn't work correctly with gcc 4 anymore!
  Line 218 [TODO]: // TODO: This doesn't work correctly with gcc 4 anymore!
  Line 249 [TODO]: // TODO: This doesn't work correctly with gcc 4 anymore!
  Line 289 [TODO]: // TODO: This doesn't work correctly with gcc 4 anymore!

File: src/system/kernel/arch/ppc/arch_debug.cpp
  Line 142 [new]: // switch to the page directory of the new thread to be
  Line 144 [new]: addr_t newPageDirectory = (addr_t)x86_next_page_directory(
  Line 147 [new]: if (newPageDirectory != 0) {
  Line 149 [new]: write_cr3(newPageDirectory);
  Line 130 [TODO]: // TODO: Add support for stack traces of other threads.
  Line 287 [TODO]: // TODO: Implement!
  Line 295 [TODO]: // TODO: Implement!
  Line 303 [TODO]: // TODO: Implement!
  Line 310 [TODO]: // TODO: Implement!
  Line 318 [TODO]: // TODO: Implement!
  Line 326 [TODO]: // TODO: Implement!
  Line 334 [TODO]: // TODO: Implement!

File: src/system/kernel/arch/ppc/arch_debug_console.cpp
  Line 34 [TODO]: // TODO: Implement correctly!
  Line 49 [TODO]: // TODO: Implement correctly!

File: src/system/kernel/arch/ppc/arch_elf.cpp
  Line 140 [TODO]: // TODO: Get the GOT address!
  Line 147 [TODO]: // TODO: Get the PLT address!
  Line 211 [TODO]: // TODO: Implement!
  Line 299 [TODO]: // TODO: Implement!
  Line 320 [TODO]: // TODO: Implement!
  Line 365 [TODO]: // TODO: Implement!

File: src/system/kernel/arch/ppc/arch_exceptions.S
  Line 123 [new]: mtmsr	%r3						/* load new msr (turning the mmu back on) */

File: src/system/kernel/arch/ppc/arch_exceptions_440.S
  Line 126 [new]: mtmsr	%r3						/* load new msr (turning the mmu back on) */

File: src/system/kernel/arch/ppc/arch_int.cpp
  Line 165 [new]: addr_t newip;
  Line 171 [new]: &newip);
  Line 172 [new]: if (newip != 0) {
  Line 175 [new]: iframe->srr0 = newip;
  Line 463 [new]: PICModule *module = new(nothrow) PICModule(moduleInfo);
  Line 118 [panic]: panic("system reset exception\n");
  Line 121 [panic]: panic("machine check exception\n");
  Line 145 [panic]: panic("page fault in debugger without fault handler! Touching "
  Line 152 [panic]: // we must panic
  Line 153 [panic]: panic("page fault, but interrupts were disabled. Touching "
  Line 158 [panic]: panic("page fault not allowed at this place. Touching address "
  Line 183 [panic]: panic("ppc_exception_entry(): external interrupt although we "
  Line 199 [panic]: panic("alignment exception: unimplemented\n");
  Line 202 [panic]: panic("program exception: unimplemented\n");
  Line 205 [panic]: panic("FP unavailable exception: unimplemented\n");
  Line 211 [panic]: panic("system call exception: unimplemented\n");
  Line 214 [panic]: panic("trace exception: unimplemented\n");
  Line 217 [panic]: panic("FP assist exception: unimplemented\n");
  Line 220 [panic]: panic("performance monitor exception: unimplemented\n");
  Line 223 [panic]: panic("alitivec unavailable exception: unimplemented\n");
  Line 228 [panic]: panic("TLB miss exception: unimplemented\n");
  Line 231 [panic]: panic("instruction address exception: unimplemented\n");
  Line 234 [panic]: panic("system management exception: unimplemented\n");
  Line 237 [panic]: panic("altivec assist exception: unimplemented\n");
  Line 240 [panic]: panic("thermal management exception: unimplemented\n");
  Line 245 [panic]: panic("unhandled exception type\n");
  Line 293 [panic]: panic("arch_int_init_post_vm(): Failed to remap the exception "
  Line 305 [panic]: panic("arch_int_init2: could not create exception handler region\n");
  Line 496 [panic]: panic("arch_int_init_post_device_manager(): Found no PIC modules!");
  Line 505 [panic]: panic("arch_int_init_post_device_manager(): Failed to get device "
  Line 541 [panic]: panic("arch_int_init_post_device_manager(): Found no supported PIC!");
  Line 565 [panic]: panic("ppc_set_current_cpu_exception_context(): Failed to get physical "
  Line 62 [TODO]: // TODO: I have no idea, what IRQ type is appropriate.
  Line 191 [TODO]: // TODO: correctly pass level-triggered vs. edge-triggered to the handler!

File: src/system/kernel/arch/ppc/arch_platform.cpp
  Line 8 [new]: #include <new>
  Line 366 [new]: sPPCPlatform = new(sPPCPlatformBuffer) PPCOpenFirmware;
  Line 369 [new]: sPPCPlatform = new(sPPCPlatformBuffer) PPCUBoot;
  Line 293 [TODO]: // TODO: get relevant debug uart from fdt

File: src/system/kernel/arch/ppc/arch_smp.cpp
  Line 33 [panic]: panic("called arch_smp_send_ici!\n");
  Line 42 [panic]: panic("arch_smp_send_multicast_ici: called with interrupts enabled");
  Line 50 [panic]: panic("called arch_smp_send_broadcast_ici\n");

File: src/system/kernel/arch/ppc/arch_thread.cpp
  Line 26 [new]: // a new thread structure.
  Line 175 [new]: // set the new kernel stack in the EAR register.
  Line 184 [new]: // switching to a new address space
  Line 159 [panic]: panic("arch_thread_init_kthread_stack(): Implement me!");
  Line 206 [panic]: panic("arch_thread_enter_uspace(): not yet implemented\n");
  Line 167 [TODO]: // TODO: Implement!

File: src/system/kernel/arch/ppc/arch_timer.cpp
  Line 21 [new]: bigtime_t new_val_64;
  Line 26 [new]: new_val_64 = (timeout * sTickRate) / 1000000;
  Line 28 [new]: asm("mtdec	%0" :: "r"((uint32)new_val_64));

File: src/system/kernel/arch/ppc/arch_vm.cpp
  Line 125 [panic]: panic("arch_vm_init_end(): No page mapping for %p\n", address);
  Line 132 [panic]: panic("arch_vm_init_end(): Failed to create area for boot loader "

File: src/system/kernel/arch/ppc/arch_vm_translation_map.cpp
  Line 251 [new]: //XXX:gPPCPagingMethod = new(&sPagingMethodBuffer) PPCPagingMethod460;
  Line 254 [new]: gPPCPagingMethod = new(&sPagingMethodBuffer) PPCPagingMethodClassic;
  Line 250 [panic]: panic("XXX");
  Line 301 [panic]: panic("vm_translation_map_early_query(): not yet implemented\n");
  Line 64 [TODO]: TODO:
  Line 248 [TODO]: if (false /* TODO:Check for AMCC460! */) {

File: src/system/kernel/arch/ppc/paging/460/PPCPagingMethod460.cpp
  Line 103 [new]: new(&fPhysicalPageMapper) GenericVMPhysicalPageMapper;
  Line 123 [new]: = new(&PhysicalPageSlotPool::sInitialPhysicalPagePool)
  Line 159 [new]: addr_t newAddress = (addr_t)fPageTable;
  Line 160 [new]: status_t error = ppc_remap_address_range(&newAddress, fPageTableSize,
  Line 168 [new]: // set the new page table address
  Line 170 [new]: fPageTable = (page_table_entry_group*)newAddress;
  Line 222 [new]: PPCVMTranslationMap460* map = new(std::nothrow) PPCVMTranslationMap460;
  Line 58 [panic]: panic("map_iospace_chunk: passed invalid va 0x%lx\n", va);
  Line 127 [panic]: panic("PPCPagingMethod460::Init(): Failed to create initial pool "
  Line 163 [panic]: panic("arch_vm_translation_map_init_post_area(): Failed to remap "
  Line 46 [TODO]: // TODO: Implement a page mapper more suitable for small pages!
  Line 135 [TODO]: // TODO: Select the best page mapper!
  Line 175 [TODO]: // TODO: We should probably map the page table via BAT. It is relatively large,
  Line 311 [TODO]: // TODO: we ignore the attributes of the page table - for compatibility
  Line 373 [TODO]: //! TODO: currently assumes this translation map is active

File: src/system/kernel/arch/ppc/paging/460/PPCPagingMethod460.h
  Line 79 [new]: page_table_entry newEntry);
  Line 84 [new]: page_table_entry newEntry,
  Line 138 [new]: page_table_entry newEntry)
  Line 140 [new]: return atomic_set((int32*)entry, newEntry);
  Line 154 [new]: page_table_entry newEntry, page_table_entry oldEntry)
  Line 156 [new]: return atomic_test_and_set((int32*)entry, newEntry, oldEntry);

File: src/system/kernel/arch/ppc/paging/460/PPCPagingStructures460.cpp
  Line 72 [new]: // zero out the bottom portion of the new pgdir
  Line 77 [new]: // insert this new map into the map list
  Line 126 [new]: new (&sPagingStructuresList) PagingStructuresList;
  Line 112 [panic]: panic("deleting a still active page directory\n");

File: src/system/kernel/arch/ppc/paging/460/PPCVMTranslationMap460.cpp
  Line 214 [new]: fPagingStructures = new(std::nothrow) PPCPagingStructures460;
  Line 561 [new]: void *newAddress = NULL;
  Line 562 [new]: status_t error = vm_reserve_address_range(addressSpace->ID(), &newAddress,
  Line 574 [new]: error = ppc_map_address_range((addr_t)newAddress, physicalBase, size);
  Line 578 [new]: *_virtualAddress = (addr_t)newAddress;
  Line 906 [new]: uint32 newProtectionFlags = 0;
  Line 908 [new]: newProtectionFlags = PPC_PTE_USER;
  Line 910 [new]: newProtectionFlags |= PPC_PTE_WRITABLE;
  Line 912 [new]: newProtectionFlags = PPC_PTE_WRITABLE;
  Line 941 [new]: // set the new protection flags -- we want to do that atomically,
  Line 949 [new]: | newProtectionFlags
  Line 141 [panic]: panic("vm_translation_map.destroy_tmap: map %p has positive map count %ld\n",
  Line 160 [panic]: panic("destroy_tmap: didn't find pgtable page\n");
  Line 207 [panic]: panic("vm_translation_map_create: out of VSID bases\n");
  Line 402 [panic]: panic("vm_translation_map.map_tmap: hash table full\n");
  Line 700 [panic]: panic("%s: UNIMPLEMENTED", __FUNCTION__);
  Line 64 [TODO]: TODO:
  Line 762 [TODO]: // TODO: As in UnmapPage() we can lose page dirty flags here. ATM it's not
  Line 1040 [TODO]: // TODO: Implement for real! ATM this is just an approximation using
  Line 1066 [TODO]: // TODO: Obvious race condition: Between querying and unmapping the

File: src/system/kernel/arch/ppc/paging/classic/PPCPagingMethodClassic.cpp
  Line 103 [new]: new(&fPhysicalPageMapper) GenericVMPhysicalPageMapper;
  Line 123 [new]: = new(&PhysicalPageSlotPool::sInitialPhysicalPagePool)
  Line 159 [new]: addr_t newAddress = (addr_t)fPageTable;
  Line 160 [new]: status_t error = ppc_remap_address_range(&newAddress, fPageTableSize,
  Line 168 [new]: // set the new page table address
  Line 170 [new]: fPageTable = (page_table_entry_group*)newAddress;
  Line 222 [new]: PPCVMTranslationMapClassic* map = new(std::nothrow) PPCVMTranslationMapClassic;
  Line 58 [panic]: panic("map_iospace_chunk: passed invalid va 0x%lx\n", va);
  Line 127 [panic]: panic("PPCPagingMethodClassic::Init(): Failed to create initial pool "
  Line 163 [panic]: panic("arch_vm_translation_map_init_post_area(): Failed to remap "
  Line 46 [TODO]: // TODO: Implement a page mapper more suitable for small pages!
  Line 135 [TODO]: // TODO: Select the best page mapper!
  Line 175 [TODO]: // TODO: We should probably map the page table via BAT. It is relatively large,
  Line 311 [TODO]: // TODO: we ignore the attributes of the page table - for compatibility
  Line 373 [TODO]: //! TODO: currently assumes this translation map is active

File: src/system/kernel/arch/ppc/paging/classic/PPCPagingMethodClassic.h
  Line 79 [new]: page_table_entry newEntry);
  Line 84 [new]: page_table_entry newEntry,
  Line 138 [new]: page_table_entry newEntry)
  Line 140 [new]: return atomic_set((int32*)entry, newEntry);
  Line 154 [new]: page_table_entry newEntry, page_table_entry oldEntry)
  Line 156 [new]: return atomic_test_and_set((int32*)entry, newEntry, oldEntry);

File: src/system/kernel/arch/ppc/paging/classic/PPCPagingStructuresClassic.cpp
  Line 72 [new]: // zero out the bottom portion of the new pgdir
  Line 77 [new]: // insert this new map into the map list
  Line 126 [new]: new (&sPagingStructuresList) PagingStructuresList;
  Line 112 [panic]: panic("deleting a still active page directory\n");

File: src/system/kernel/arch/ppc/paging/classic/PPCVMTranslationMapClassic.cpp
  Line 214 [new]: fPagingStructures = new(std::nothrow) PPCPagingStructuresClassic;
  Line 561 [new]: void *newAddress = NULL;
  Line 562 [new]: status_t error = vm_reserve_address_range(addressSpace->ID(), &newAddress,
  Line 574 [new]: error = ppc_map_address_range((addr_t)newAddress, physicalBase, size);
  Line 578 [new]: *_virtualAddress = (addr_t)newAddress;
  Line 906 [new]: uint32 newProtectionFlags = 0;
  Line 908 [new]: newProtectionFlags = PPC_PTE_USER;
  Line 910 [new]: newProtectionFlags |= PPC_PTE_WRITABLE;
  Line 912 [new]: newProtectionFlags = PPC_PTE_WRITABLE;
  Line 941 [new]: // set the new protection flags -- we want to do that atomically,
  Line 949 [new]: | newProtectionFlags
  Line 141 [panic]: panic("vm_translation_map.destroy_tmap: map %p has positive map count %d\n", this,
  Line 160 [panic]: panic("destroy_tmap: didn't find pgtable page\n");
  Line 207 [panic]: panic("vm_translation_map_create: out of VSID bases\n");
  Line 402 [panic]: panic("vm_translation_map.map_tmap: hash table full\n");
  Line 700 [panic]: panic("%s: UNIMPLEMENTED", __FUNCTION__);
  Line 64 [TODO]: TODO:
  Line 762 [TODO]: // TODO: As in UnmapPage() we can lose page dirty flags here. ATM it's not
  Line 1040 [TODO]: // TODO: Implement for real! ATM this is just an approximation using
  Line 1066 [TODO]: // TODO: Obvious race condition: Between querying and unmapping the

File: src/system/kernel/arch/riscv64/RISCV64VMTranslationMap.cpp
  Line 130 [new]: Pte newPte {
  Line 135 [new]: pte->store(newPte);
  Line 255 [new]: Pte newPte {
  Line 262 [new]: newPte.isUser = true;
  Line 264 [new]: newPte.isRead = true;
  Line 266 [new]: newPte.isWrite = true;
  Line 268 [new]: newPte.isExec = true;
  Line 273 [new]: newPte.isRead = true;
  Line 275 [new]: newPte.isWrite = true;
  Line 277 [new]: newPte.isExec = true;
  Line 282 [new]: pte->store(newPte);
  Line 491 [new]: Pte newPte {};
  Line 495 [new]: newPte = oldPte;
  Line 497 [new]: newPte.isUser = true;
  Line 498 [new]: newPte.isRead  = (attributes & B_READ_AREA)    != 0;
  Line 499 [new]: newPte.isWrite = (attributes & B_WRITE_AREA)   != 0;
  Line 500 [new]: newPte.isExec  = (attributes & B_EXECUTE_AREA) != 0;
  Line 502 [new]: newPte.isUser = false;
  Line 503 [new]: newPte.isRead  = (attributes & B_KERNEL_READ_AREA)    != 0;
  Line 504 [new]: newPte.isWrite = (attributes & B_KERNEL_WRITE_AREA)   != 0;
  Line 505 [new]: newPte.isExec  = (attributes & B_KERNEL_EXECUTE_AREA) != 0;
  Line 508 [new]: if (pte->compare_exchange_strong(oldPte, newPte))
  Line 512 [new]: fInvalidCode = newPte.isExec;
  Line 771 [new]: addr_t newIP;
  Line 772 [new]: vm_page_fault(va0, Ra(), true, false, true, &newIP);
  Line 811 [new]: addr_t newIP;
  Line 812 [new]: vm_page_fault(va0, Ra(), true, false, true, &newIP);
  Line 939 [user_memcpy]: return user_memcpy(to, VirtFromPhys(from), length);
  Line 950 [user_memcpy]: return user_memcpy(VirtFromPhys(to), from, length);
  Line 960 [user_memcpy]: user_memcpy(VirtFromPhys(to), VirtFromPhys(from), B_PAGE_SIZE);
  Line 32 [panic]: panic("not implemented: %s\n", __PRETTY_FUNCTION__)
  Line 253 [panic]: panic("can't allocate page table");
  Line 403 [TODO]: // TODO: As in UnmapPage() we can lose page dirty flags here. ATM it's not
  Line 627 [TODO]: // TODO: move to common VMTranslationMap class
  Line 698 [TODO]: // TODO: handle hart ID >= 64

File: src/system/kernel/arch/riscv64/arch_commpage.cpp
  Line 58 [panic]: panic("register_commpage_function(): Failed to find "

File: src/system/kernel/arch/riscv64/arch_debug.cpp
  Line 165 [malloc]: char* buffer = (char*)debug_malloc(kBufferSize);
  Line 429 [new]: // switch to the page directory of the new thread to be
  Line 431 [new]: phys_addr_t newPageDirectory = get_thread_page_directory(thread);
  Line 433 [new]: if (newPageDirectory != 0) {
  Line 435 [new]: SetSatp(newPageDirectory);
  Line 806 [new]: phys_addr_t newPageDirectory = get_thread_page_directory(thread);
  Line 808 [new]: if (newPageDirectory != 0) {
  Line 810 [new]: SetSatp(newPageDirectory);
  Line 108 [user_memcpy]: || user_memcpy(&frame, (stack_frame*)fp - 1, sizeof(frame)) != B_OK) {
  Line 102 [TODO]: // TODO: Do this more efficiently in assembly.

File: src/system/kernel/arch/riscv64/arch_debug_console.cpp
  Line 54 [TODO]: // TODO: Implement correctly!

File: src/system/kernel/arch/riscv64/arch_int.cpp
  Line 246 [new]: addr_t newIP = 0;
  Line 251 [new]: SstatusReg{.val = frame->status}.spp == modeU, &newIP);
  Line 253 [new]: if (newIP != 0)
  Line 254 [new]: frame->epc = newIP;
  Line 234 [user_memcpy]: // user_memcpy() failure
  Line 288 [user_memcpy]: if (status_t res = user_memcpy(&args[8], (void*)frame->sp,
  Line 57 [panic]: panic("Unexpected exception occurred in kernel mode!");
  Line 189 [panic]: panic("hit kernel breakpoint");
  Line 228 [panic]: panic("page fault in debugger without fault handler! Touching "
  Line 243 [panic]: panic("page fault with interrupts disabled@!dump_virt_page %#" B_PRIx64, stval);
  Line 305 [panic]: panic("unhandled STrap");
  Line 325 [TODO]: // TODO: read from FDT

File: src/system/kernel/arch/riscv64/arch_smp.cpp
  Line 63 [panic]: panic("arch_smp_send_multicast_ici: called with interrupts enabled");
  Line 53 [TODO]: // TODO: handle hart ID >= 64

File: src/system/kernel/arch/riscv64/arch_thread.cpp
  Line 114 [user_memcpy]: ASSERT(user_memcpy(&threadExitAddr,
  Line 241 [user_memcpy]: status_t res = user_memcpy(userStack, signalFrameData,
  Line 249 [user_memcpy]: ASSERT(user_memcpy(&signalHandlerAddr,
  Line 151 [panic]: panic("arch_on_signal_stack(): No user iframe!");
  Line 89 [TODO]: // TODO: save/restore FPU only if needed
  Line 221 [TODO]: // TODO: don't assume that kernel code don't use FPU

File: src/system/kernel/arch/riscv64/arch_uart_sifive.cpp
  Line 8 [new]: #include <new>
  Line 121 [new]: ArchUARTSifive* uart = new(buffer) ArchUARTSifive(base, clock);
  Line 76 [TODO]: // TODO: Needs to be more atomic?

File: src/system/kernel/arch/riscv64/arch_user_debugger.cpp
  Line 132 [TODO]: // TODO: don't assume that kernel code don't use FPU

File: src/system/kernel/arch/riscv64/arch_vm.cpp
  Line 326 [panic]: panic("arch_vm_init_end(): No page mapping for %p\n", address);
  Line 333 [panic]: panic("arch_vm_init_end(): Failed to create area for boot loader "
  Line 42 [TODO]: // TODO: Handle superpages (RWX=0 when not at lowest level)

File: src/system/kernel/arch/riscv64/arch_vm_translation_map.cpp
  Line 57 [new]: Pte newPte {
  Line 62 [new]: pte->val = newPte.val;
  Line 78 [new]: Pte newPte {
  Line 85 [new]: newPte.val |= flags;
  Line 87 [new]: pte->val = newPte.val;
  Line 139 [new]: *_physicalPageMapper = new(&sPhysicalPageMapperData)
  Line 179 [new]: *_map = new(std::nothrow) RISCV64VMTranslationMap(kernel,
  Line 76 [panic]: if (pte == NULL) panic("can't allocate page table");
  Line 42 [TODO]: // TODO: Consolidate function with RISCV64VMTranslationMap

File: src/system/kernel/arch/sparc/arch_asm.S
  Line 13 [user_memcpy]: /* status_t arch_cpu_user_memcpy(void *to, const void *from, size_t size, addr_t *faultHandler) */
  Line 14 [user_memcpy]: FUNCTION(_arch_cpu_user_memcpy):
  Line 18 [user_memcpy]: FUNCTION_END(_arch_cpu_user_memcpy)
  Line 15 [TODO]: // TODO
  Line 23 [TODO]: // TODO
  Line 31 [TODO]: // TODO

File: src/system/kernel/arch/sparc/arch_debug.cpp
  Line 50 [TODO]: // TODO: Implement!
  Line 58 [TODO]: // TODO: Implement!
  Line 66 [TODO]: // TODO: Implement!
  Line 82 [TODO]: // TODO: Implement!
  Line 90 [TODO]: // TODO: Implement!

File: src/system/kernel/arch/sparc/arch_debug_console.cpp
  Line 34 [TODO]: // TODO: Implement correctly!
  Line 49 [TODO]: // TODO: Implement correctly!

File: src/system/kernel/arch/sparc/arch_elf.cpp
  Line 128 [TODO]: // TODO: Get the GOT address!
  Line 135 [TODO]: // TODO: Get the PLT address!
  Line 224 [TODO]: // TODO: Implement!

File: src/system/kernel/arch/sparc/arch_platform.cpp
  Line 9 [new]: #include <new>
  Line 241 [new]: sSparcPlatform = new(sSparcPlatformBuffer) SparcOpenFirmware;

File: src/system/kernel/arch/sparc/arch_smp.cpp
  Line 40 [panic]: panic("arch_smp_send_multicast_ici: called with interrupts enabled");
  Line 48 [panic]: panic("called arch_smp_send_ici!\n");
  Line 55 [panic]: panic("called arch_smp_send_broadcast_ici\n");

File: src/system/kernel/arch/sparc/arch_thread.cpp
  Line 86 [panic]: panic("arch_thread_init_kthread_stack(): Implement me!");
  Line 114 [panic]: panic("arch_thread_enter_uspace(): not yet implemented\n");
  Line 94 [TODO]: // TODO: Implement!

File: src/system/kernel/arch/sparc/arch_timer.cpp
  Line 38 [TODO]: // TODO

File: src/system/kernel/arch/sparc/arch_vm.cpp
  Line 64 [panic]: panic("arch_vm_init_end(): No page mapping for %p\n", address);
  Line 71 [panic]: panic("arch_vm_init_end(): Failed to create area for boot loader "

File: src/system/kernel/arch/x86/32/apm.cpp
  Line 247 [user_memcpy]: return user_memcpy(buffer, &info, sizeof(struct apm_battery_info));
  Line 321 [TODO]: // TODO: test if APM segments really are in the BIOS ROM area

File: src/system/kernel/arch/x86/32/arch.S
  Line 50 [new]: /* void x86_noop_swap(void *old_fpu_state, const void *new_fpu_state); */
  Line 56 [new]: /* void x86_fnsave_swap(void *old_fpu_state, const void *new_fpu_state); */
  Line 65 [new]: /* void x86_fxsave_swap(void *old_fpu_state, const void *new_fpu_state); */
  Line 81 [new]: struct arch_thread* newState); */
  Line 89 [new]: movl	40(%esp),%eax	/* get new newState->current_stack */
  Line 95 [new]: /* void x86_swap_pgdir(uint32 newPageDir); */
  Line 128 [user_memcpy]: /* status_t arch_cpu_user_memcpy(void *to, const void *from, size_t size, addr_t *faultHandler) */
  Line 129 [user_memcpy]: FUNCTION(_arch_cpu_user_memcpy):
  Line 139 [user_memcpy]: movl	$.L_user_memcpy_error, (%edx)
  Line 162 [user_memcpy]: .L_user_memcpy_error:
  Line 169 [user_memcpy]: FUNCTION_END(_arch_cpu_user_memcpy)

File: src/system/kernel/arch/x86/32/descriptors.cpp
  Line 241 [new]: // add TSS descriptor for this new TSS
  Line 274 [new]: // add TSS descriptor for this new TSS

File: src/system/kernel/arch/x86/32/errata.cpp
  Line 16 [TODO]: // TODO.

File: src/system/kernel/arch/x86/32/interrupts.S
  Line 717 [TODO]: // TODO: this only needs to be done for syscalls!

File: src/system/kernel/arch/x86/32/signals.cpp
  Line 85 [panic]: panic("x86_initialize_commpage_signal_handler(): Failed to find "

File: src/system/kernel/arch/x86/32/syscalls.cpp
  Line 74 [TODO]: // TODO: ...

File: src/system/kernel/arch/x86/32/thread.cpp
  Line 63 [new]: #	define TSYSCALL(x)	new(std::nothrow) SyscallTracing::x
  Line 150 [new]: // part of each new thread
  Line 325 [new]: signalFrameData->context.uc_mcontext.xregs.state.new_format.fault_address = x86_read_cr2();
  Line 326 [new]: signalFrameData->context.uc_mcontext.xregs.state.new_format.error_code = frame->error_code;
  Line 327 [new]: signalFrameData->context.uc_mcontext.xregs.state.new_format.cs = frame->cs;
  Line 328 [new]: signalFrameData->context.uc_mcontext.xregs.state.new_format.ds = frame->ds;
  Line 329 [new]: signalFrameData->context.uc_mcontext.xregs.state.new_format.es = frame->es;
  Line 330 [new]: signalFrameData->context.uc_mcontext.xregs.state.new_format.fs = frame->fs;
  Line 331 [new]: signalFrameData->context.uc_mcontext.xregs.state.new_format.gs = frame->gs;
  Line 332 [new]: signalFrameData->context.uc_mcontext.xregs.state.new_format.ss = frame->user_ss;
  Line 333 [new]: signalFrameData->context.uc_mcontext.xregs.state.new_format.trap_number = frame->vector;
  Line 405 [new]: frame->cs = signalFrameData->context.uc_mcontext.xregs.state.new_format.cs;
  Line 406 [new]: frame->ds = signalFrameData->context.uc_mcontext.xregs.state.new_format.ds;
  Line 407 [new]: frame->es = signalFrameData->context.uc_mcontext.xregs.state.new_format.es;
  Line 408 [new]: frame->fs = signalFrameData->context.uc_mcontext.xregs.state.new_format.fs;
  Line 409 [new]: frame->gs = signalFrameData->context.uc_mcontext.xregs.state.new_format.gs;
  Line 410 [new]: frame->user_ss = signalFrameData->context.uc_mcontext.xregs.state.new_format.ss;
  Line 242 [user_memcpy]: if (user_memcpy((void *)stackTop, args, sizeof(args)) < B_OK)
  Line 348 [user_memcpy]: if (user_memcpy(userSignalFrameData, signalFrameData,
  Line 359 [user_memcpy]: if (user_memcpy(userStack, stackFrame, sizeof(stackFrame)) != B_OK)
  Line 298 [panic]: panic("arch_setup_signal_frame(): No user iframe!");

File: src/system/kernel/arch/x86/64/descriptors.cpp
  Line 398 [new]: new(&sGDT) GlobalDescriptorTable;
  Line 399 [new]: new(&sIDT) InterruptDescriptorTable;

File: src/system/kernel/arch/x86/64/entry_compat.S
  Line 144 [TODO]: // TODO: implement for AMD SYSCALL
  Line 272 [TODO]: // TODO: pre-syscall tracing
  Line 281 [TODO]: // TODO: post-syscall tracing
  Line 355 [TODO]: // TODO: restore arguments from the stack
  Line 418 [TODO]: // TODO: build with the x86 compiler

File: src/system/kernel/arch/x86/64/interrupts.S
  Line 433 [TODO]: // TODO: pre-syscall tracing
  Line 439 [TODO]: // TODO: post-syscall tracing

File: src/system/kernel/arch/x86/64/signals.cpp
  Line 57 [panic]: panic("register_commpage_function(): Failed to find "

File: src/system/kernel/arch/x86/64/signals_compat_asm.S
  Line 12 [TODO]: // TODO: build from arch/x86/32/signals.cpp with the x86 compiler

File: src/system/kernel/arch/x86/64/thread.cpp
  Line 63 [new]: #	define TSYSCALL(x)	new(std::nothrow) SyscallTracing::x
  Line 174 [new]: // part of each new thread.
  Line 219 [new]: // Copy the initial saved FPU state to the new thread.
  Line 153 [user_memcpy]: || user_memcpy(&base, buffer, sizeof(base)) < B_OK) {
  Line 295 [user_memcpy]: if (user_memcpy((void*)stackTop, (const void*)&codeAddr, sizeof(codeAddr))
  Line 400 [user_memcpy]: if (user_memcpy(userSignalFrameData, signalFrameData,
  Line 406 [user_memcpy]: if (user_memcpy(userStack, &frame->ip, sizeof(frame->ip)) != B_OK)
  Line 349 [panic]: panic("arch_setup_signal_frame(): No user iframe!");

File: src/system/kernel/arch/x86/apic.cpp
  Line 304 [panic]: panic("mapping the local apic failed");

File: src/system/kernel/arch/x86/arch_altcodepatch.cpp
  Line 32 [new]: arch_altcodepatch_replace(uint16 tag, void* newcodepatch, size_t length)
  Line 47 [new]: panic("can't copy patch: new code is too long\n");
  Line 48 [new]: memcpy(address, newcodepatch, length);
  Line 47 [panic]: panic("can't copy patch: new code is too long\n");

File: src/system/kernel/arch/x86/arch_cpu.cpp
  Line 102 [new]: void (*gX86SwapFPUFunc)(void* oldState, const void* newState) = x86_noop_swap;
  Line 1874 [panic]: panic("failed to create double fault stacks area: %" B_PRId32, stacks);

File: src/system/kernel/arch/x86/arch_debug.cpp
  Line 158 [malloc]: char* buffer = (char*)debug_malloc(kBufferSize);
  Line 329 [malloc]: char* buffer = (char*)debug_malloc(kBufferSize);
  Line 478 [new]: // switch to the page directory of the new thread to be
  Line 480 [new]: phys_addr_t newPageDirectory = x86_next_page_directory(
  Line 483 [new]: if (newPageDirectory != 0) {
  Line 485 [new]: x86_write_cr3(newPageDirectory);
  Line 1021 [new]: phys_addr_t newPageDirectory = x86_next_page_directory(
  Line 1024 [new]: if (newPageDirectory != 0) {
  Line 1026 [new]: x86_write_cr3(newPageDirectory);
  Line 79 [user_memcpy]: || user_memcpy(&frame, (void*)bp, sizeof(frame)) != B_OK) {
  Line 73 [TODO]: // TODO: Do this more efficiently in assembly.

File: src/system/kernel/arch/x86/arch_int.cpp
  Line 287 [new]: addr_t newip;
  Line 372 [new]: &newip);
  Line 373 [new]: if (newip != 0) {
  Line 376 [new]: frame->ip = newip;
  Line 337 [user_memcpy]: // TODO: Now we are generally allowing user_memcpy() with interrupts
  Line 92 [panic]: panic("unhandled trap 0x%lx (%s) at ip 0x%lx, thread %" B_PRId32 "!\n",
  Line 103 [panic]: panic("Fatal exception \"%s\" occurred! Error code: 0x%lx\n",
  Line 226 [panic]: panic("Unexpected exception \"%s\" occurred in kernel mode! "
  Line 315 [panic]: panic("page fault in debugger without fault handler! Touching "
  Line 323 [panic]: panic("SMEP violation user-mapped address %p touched from kernel %p\n",
  Line 331 [panic]: panic("SMAP violation user-mapped address %p touched from kernel %p\n",
  Line 350 [panic]: panic("page fault, interrupts disabled, fault handler loop. "
  Line 356 [panic]: // allowed to happen and we must panic.
  Line 357 [panic]: panic("page fault, but interrupts were disabled. Touching address "
  Line 361 [panic]: panic("page fault not allowed at this place. Touching address "
  Line 337 [TODO]: // TODO: Now we are generally allowing user_memcpy() with interrupts

File: src/system/kernel/arch/x86/arch_smp.cpp
  Line 163 [panic]: panic("arch_smp_send_multicast_ici: called with interrupts enabled");
  Line 201 [panic]: panic("arch_smp_send_broadcast_ici: called with interrupts enabled");
  Line 222 [panic]: panic("arch_smp_send_ici: called with interrupts enabled");

File: src/system/kernel/arch/x86/arch_system_info.cpp
  Line 205 [user_memcpy]: && user_memcpy(userInfo, &info, sizeof(cpuid_info)) < B_OK)

File: src/system/kernel/arch/x86/arch_thread.cpp
  Line 34 [new]: extern void (*gX86SwapFPUFunc)(void *oldState, const void *newState);
  Line 222 [new]: // assign the new paging structures to the CPU
  Line 227 [new]: addr_t newPageDirectory = toPagingStructures->pgdir_phys;
  Line 228 [new]: if (newPageDirectory != activePagingStructures->pgdir_phys)
  Line 229 [new]: x86_swap_pgdir(newPageDirectory);

File: src/system/kernel/arch/x86/arch_timer.cpp
  Line 112 [panic]: panic("No system timers were found usable.\n");

File: src/system/kernel/arch/x86/arch_user_debugger.cpp
  Line 1058 [new]: // TODO: This is not yet fully correct, since a newly created
  Line 1165 [new]: "If \"rw\" is given the new watchpoint is a read/write watchpoint\n"
  Line 856 [panic]: panic("arch_set_kernel_breakpoint() failed to set breakpoint: %s",
  Line 870 [panic]: panic("arch_clear_kernel_breakpoint() failed to clear breakpoint: %s",
  Line 889 [panic]: panic("arch_set_kernel_watchpoint() failed to set watchpoint: %s",
  Line 903 [panic]: panic("arch_clear_kernel_watchpoint() failed to clear watchpoint: %s",
  Line 1026 [panic]: panic("hit kernel %spoint: dr6: 0x%lx, dr7: 0x%lx",
  Line 1039 [panic]: panic("spurious general detect exception in kernel mode");
  Line 1065 [panic]: panic("kernel single step");
  Line 1102 [panic]: panic("spurious task switch exception in kernel mode");
  Line 1110 [panic]: panic("spurious debug exception in kernel mode (no condition "
  Line 1129 [panic]: panic("breakpoint exception in kernel mode");
  Line 33 [TODO]: // TODO: Make those real error codes.
  Line 212 [TODO]: // TODO check the xsave header to know the actual size of the
  Line 248 [TODO]: // TODO: Convert to fxsave format!
  Line 675 [TODO]: // TODO: Since we need an iframe, this doesn't work when KDL wasn't entered
  Line 766 [TODO]: // TODO: Implement! We need to convert the format first.
  Line 1058 [TODO]: // TODO: This is not yet fully correct, since a newly created

File: src/system/kernel/arch/x86/arch_vm.cpp
  Line 16 [new]: #include <new>
  Line 304 [new]: memory_type_range* ranges = new(std::nothrow) memory_type_range[count];
  Line 317 [new]: = new(std::nothrow) memory_type_range_point[count];
  Line 413 [new]: // we need to start a new range -- find the strictest pending range
  Line 426 [new]: // we can't join with the previous range -- add a new one
  Line 611 [new]: range = new(std::nothrow) memory_type_range;
  Line 543 [panic]: panic("update_mtrrs(): Out of MTRRs!");
  Line 592 [panic]: (KDEBUG ? panic : dprintf)("incompatible overlapping memory %#" B_PRIx64
  Line 730 [panic]: panic("arch_vm_init_post_area: unable to map dma region\n");

File: src/system/kernel/arch/x86/arch_vm_translation_map.cpp
  Line 91 [new]: gX86PagingMethod = new(&sPagingMethodBuffer) X86PagingMethod64Bit(enabled);
  Line 112 [new]: gX86PagingMethod = new(&sPagingMethodBuffer) X86PagingMethodPAE;
  Line 118 [new]: gX86PagingMethod = new(&sPagingMethodBuffer) X86PagingMethod32Bit;
  Line 121 [new]: gX86PagingMethod = new(&sPagingMethodBuffer) X86PagingMethod32Bit;

File: src/system/kernel/arch/x86/ioapic.cpp
  Line 443 [malloc]: = (struct ioapic*)malloc(sizeof(struct ioapic));
  Line 339 [panic]: panic("mapping io-apic %u failed", ioapic.number);
  Line 768 [panic]: panic("failed to initialize io-apic %u", current->number);
  Line 783 [panic]: panic("failed to enable IRQ routing");
  Line 614 [TODO]: // TODO: take these into account, but at apic.cpp
  Line 625 [TODO]: // TODO: take these into account, but at apic.cpp
  Line 803 [TODO]: // TODO: This uses the assumption that our init is running on the

File: src/system/kernel/arch/x86/msi.cpp
  Line 85 [panic]: panic("trying to free msi vectors but msi not supported\n");

File: src/system/kernel/arch/x86/paging/32bit/X86PagingMethod32Bit.cpp
  Line 195 [new]: PhysicalPageSlotPool* pool = new(std::nothrow) PhysicalPageSlotPool;
  Line 316 [new]: new(&pool[i]) PhysicalPageSlotPool;
  Line 378 [new]: X86VMTranslationMap32Bit* map = new(std::nothrow) X86VMTranslationMap32Bit;
  Line 421 [new]: // zero it out in it's new mapping
  Line 95 [panic]: panic("LargeMemoryPhysicalPageMapper::Init(): Failed to reserve "
  Line 105 [panic]: panic("X86PagingMethod32Bit::PhysicalPageSlotPool::InitInitial(): "
  Line 131 [panic]: panic("LargeMemoryPhysicalPageMapper::InitPostArea(): Failed to "
  Line 143 [panic]: panic("LargeMemoryPhysicalPageMapper::InitPostArea(): Failed to "
  Line 319 [panic]: panic("X86PagingMethod32Bit::Init(): Failed to create initial pool "
  Line 328 [TODO]: // TODO: Select the best page mapper!
  Line 511 [TODO]: // TODO: we ignore the attributes of the page table - for compatibility
  Line 582 [TODO]: //! TODO: currently assumes this translation map is active

File: src/system/kernel/arch/x86/paging/32bit/X86PagingMethod32Bit.h
  Line 63 [new]: page_table_entry newEntry);
  Line 68 [new]: page_table_entry newEntry,
  Line 110 [new]: page_table_entry newEntry)
  Line 112 [new]: return atomic_get_and_set((int32*)entry, newEntry);
  Line 126 [new]: page_table_entry newEntry, page_table_entry oldEntry)
  Line 128 [new]: return atomic_test_and_set((int32*)entry, newEntry, oldEntry);

File: src/system/kernel/arch/x86/paging/32bit/X86PagingStructures32Bit.cpp
  Line 68 [new]: // zero out the bottom portion of the new pgdir
  Line 72 [new]: // insert this new map into the map list
  Line 119 [new]: new (&sPagingStructuresList) PagingStructuresList;
  Line 105 [panic]: panic("deleting a still active page directory\n");

File: src/system/kernel/arch/x86/paging/32bit/X86VMTranslationMap32Bit.cpp
  Line 85 [new]: fPagingStructures = new(std::nothrow) X86PagingStructures32Bit;
  Line 519 [new]: uint32 newProtectionFlags = 0;
  Line 521 [new]: newProtectionFlags = X86_PTE_USER;
  Line 523 [new]: newProtectionFlags |= X86_PTE_WRITABLE;
  Line 525 [new]: newProtectionFlags = X86_PTE_WRITABLE;
  Line 554 [new]: // set the new protection flags -- we want to do that atomically,
  Line 562 [new]: | newProtectionFlags
  Line 66 [panic]: panic("destroy_tmap: didn't find pgtable page\n");
  Line 409 [TODO]: // TODO: As in UnmapPage() we can lose page dirty flags here. ATM it's not

File: src/system/kernel/arch/x86/paging/64bit/X86PagingMethod64Bit.cpp
  Line 114 [new]: X86VMTranslationMap64Bit* map = new(std::nothrow) X86VMTranslationMap64Bit(la57);
  Line 223 [new]: for a virtual address, allocating new tables if required.
  Line 239 [new]: // Allocate a new PDPT.
  Line 270 [new]: // Allocate a new PDPT.
  Line 300 [new]: // Allocate a new page directory.
  Line 343 [new]: virtual address, allocating new tables if required.
  Line 363 [new]: // Allocate a new page table.

File: src/system/kernel/arch/x86/paging/64bit/X86PagingMethod64Bit.h
  Line 90 [new]: uint64_t newEntry);
  Line 94 [new]: uint64 newEntry, uint64 oldEntry);
  Line 127 [new]: X86PagingMethod64Bit::SetTableEntry(uint64_t* entryPointer, uint64_t newEntry)
  Line 130 [new]: entry.store(newEntry, std::memory_order_relaxed);
  Line 143 [new]: X86PagingMethod64Bit::TestAndSetTableEntry(uint64* entry, uint64 newEntry, uint64 oldEntry)
  Line 145 [new]: return atomic_test_and_set64((int64*)entry, newEntry, oldEntry);

File: src/system/kernel/arch/x86/paging/64bit/X86VMTranslationMap64Bit.cpp
  Line 160 [new]: fPagingStructures = new(std::nothrow) X86PagingStructures64Bit;
  Line 245 [new]: // Look up the page table for the virtual address, allocating new tables
  Line 541 [new]: uint64 newProtectionFlags = 0;
  Line 543 [new]: newProtectionFlags = X86_64_PTE_USER;
  Line 545 [new]: newProtectionFlags |= X86_64_PTE_WRITABLE;
  Line 548 [new]: newProtectionFlags |= X86_64_PTE_NOT_EXECUTABLE;
  Line 551 [new]: newProtectionFlags = X86_64_PTE_WRITABLE;
  Line 575 [new]: // set the new protection flags -- we want to do that atomically,
  Line 583 [new]: | newProtectionFlags
  Line 100 [panic]: panic("page table %u %u %u on invalid page %#"
  Line 111 [panic]: panic("page directory %u %u on invalid page %#"
  Line 122 [panic]: panic("PDPT %u on invalid page %#" B_PRIxPHYSADDR "\n", i,
  Line 134 [panic]: panic("PML4 %u on invalid page %#" B_PRIxPHYSADDR "\n", p,
  Line 451 [TODO]: // TODO: As in UnmapPage() we can lose page dirty flags here. ATM it's not

File: src/system/kernel/arch/x86/paging/pae/X86PagingMethodPAE.cpp
  Line 105 [new]: // We need additional PAE page tables for the new pages we're going to
  Line 505 [new]: PhysicalPageSlotPool* pool = new(std::nothrow) PhysicalPageSlotPool;
  Line 608 [new]: new(&pool[i]) PhysicalPageSlotPool;
  Line 660 [new]: X86VMTranslationMapPAE* map = new(std::nothrow) X86VMTranslationMapPAE;
  Line 233 [panic]: panic("Failed to reserve virtual address space for the switch to "
  Line 290 [panic]: panic("Failed to allocate 32-bit-addressable page for the switch "
  Line 300 [panic]: panic("X86PagingMethodPAE::ToPAESwitcher::_NextPage(): no more "
  Line 394 [panic]: panic("LargeMemoryPhysicalPageMapper::Init(): Failed to reserve "
  Line 405 [panic]: panic("X86PagingMethodPAE::PhysicalPageSlotPool::InitInitial(): Failed "
  Line 440 [panic]: panic("LargeMemoryPhysicalPageMapper::InitPostArea(): Failed to "
  Line 452 [panic]: panic("LargeMemoryPhysicalPageMapper::InitPostArea(): Failed to "
  Line 611 [panic]: panic("X86PagingMethodPAE::Init(): Failed to create initial pool "
  Line 800 [TODO]: // TODO: We ignore the attributes of the page table -- for compatibility

File: src/system/kernel/arch/x86/paging/pae/X86PagingMethodPAE.h
  Line 77 [new]: uint64_t newEntry);
  Line 81 [new]: uint64_t newEntry, uint64_t oldEntry);
  Line 156 [new]: X86PagingMethodPAE::SetTableEntry(uint64_t* entry, uint64_t newEntry)
  Line 158 [new]: return atomic_get_and_set64((int64*)entry, newEntry);
  Line 171 [new]: uint64_t newEntry, uint64_t oldEntry)
  Line 173 [new]: return atomic_test_and_set64((int64*)entry, newEntry, oldEntry);

File: src/system/kernel/arch/x86/paging/pae/X86VMTranslationMapPAE.cpp
  Line 128 [new]: pae_page_table_entry oldEntry, pae_page_table_entry newEntry)
  Line 134 [new]: fNewEntry(newEntry)
  Line 221 [new]: #	define T(x)	new(std::nothrow) TranslationMapTracing::x
  Line 284 [new]: fPagingStructures = new(std::nothrow) X86PagingStructuresPAE;
  Line 310 [new]: // of the kernel and create two new lower page directories for the
  Line 782 [new]: uint64 newFlags
  Line 785 [new]: newFlags |= X86_PAE_PTE_USER;
  Line 787 [new]: newFlags |= X86_PAE_PTE_WRITABLE;
  Line 790 [new]: newFlags |= X86_PAE_PTE_NOT_EXECUTABLE;
  Line 793 [new]: newFlags |= X86_PAE_PTE_WRITABLE;
  Line 825 [new]: // set the new protection flags -- we want to do that atomically,
  Line 833 [new]: | newFlags,
  Line 843 [new]: | newFlags));
  Line 261 [panic]: panic("X86VMTranslationMapPAE::~X86VMTranslationMapPAE: "
  Line 652 [TODO]: // TODO: As in UnmapPage() we can lose page dirty flags here. ATM it's not

File: src/system/kernel/arch/x86/paging/x86_physical_page_mapper_large_memory.cpp
  Line 28 [new]: #include <new>
  Line 465 [new]: = new(std::nothrow) LargeMemoryTranslationMapPhysicalPageMapper;
  Line 711 [new]: // allocate new pool
  Line 765 [new]: new(&sPhysicalPageMapper) LargeMemoryPhysicalPageMapper;
  Line 620 [user_memcpy]: error = user_memcpy(to, (void*)(slot->address + pageOffset),
  Line 660 [user_memcpy]: error = user_memcpy((void*)(slot->address + pageOffset), from,
  Line 323 [panic]: panic("PhysicalPageOpsCPUData::Init(): Failed to get initial "
  Line 445 [panic]: panic("LargeMemoryPhysicalPageMapper::Init(): Failed to init "

File: src/system/kernel/arch/x86/paging/x86_physical_page_mapper_mapped.cpp
  Line 7 [new]: #include <new>
  Line 27 [new]: new(&sPhysicalPageMapper) X86PhysicalPageMapper;
  Line 28 [new]: new(&sKernelPageMapper) TranslationMapPhysicalPageMapper;

File: src/system/kernel/arch/x86/paging/x86_physical_page_mapper_mapped.h
  Line 62 [new]: auto mapper = new(std::nothrow) TranslationMapPhysicalPageMapper;
  Line 161 [user_memcpy]: return user_memcpy(to, from, length);
  Line 179 [user_memcpy]: return user_memcpy(to, from, length);

File: src/system/kernel/arch/x86/timers/x86_hpet.cpp
  Line 228 [panic]: // Would it be better to panic here?
  Line 53 [TODO]: // TODO: Fix HPET in SMP mode.

File: src/system/kernel/arch/x86/x86_syscalls.h
  Line 26 [TODO]: // TODO on x86_64, only necessary for 32-bit threads

File: src/system/kernel/boot_item.cpp
  Line 16 [new]: //		new items.
  Line 33 [new]: boot_item *item = new(nothrow) boot_item;
  Line 71 [new]: new(&sItemList) ItemList;

File: src/system/kernel/cache/block_cache.cpp
  Line 1174 [malloc]: newBlocks = (cached_block**)malloc(newCapacity * sizeof(void*));
  Line 39 [new]: //		new data must be written, ie. in low memory situations.
  Line 86 [new]: // new block containing the contents changed in the parent transaction.
  Line 128 [new]: static inline void* operator new(size_t size);
  Line 155 [new]: cache_notification::operator new(size_t size)
  Line 658 [new]: #	define TB(x) new(std::nothrow) BlockTracing::x;
  Line 664 [new]: #	define TB2(x) new(std::nothrow) BlockTracing::x;
  Line 709 [new]: cache_transaction* newTransaction)
  Line 715 [new]: fNewTransaction(newTransaction),
  Line 716 [new]: fNewID(newTransaction->id)
  Line 796 [new]: #	define T(x) new(std::nothrow) TransactionTracing::x;
  Line 1039 [new]: cache_listener* listener = new cache_listener;
  Line 1171 [new]: cached_block** newBlocks;
  Line 1172 [new]: size_t newCapacity = max_c(256, fCapacity * 2);
  Line 1174 [new]: newBlocks = (cached_block**)malloc(newCapacity * sizeof(void*));
  Line 1176 [new]: newBlocks = (cached_block**)realloc(fBlocks,
  Line 1177 [new]: newCapacity * sizeof(void*));
  Line 1180 [new]: if (newBlocks == NULL) {
  Line 1186 [new]: memcpy(newBlocks, fBuffer, kBufferSize * sizeof(void*));
  Line 1188 [new]: fBlocks = newBlocks;
  Line 1189 [new]: fCapacity = newCapacity;
  Line 1491 [new]: fBlocks = new(std::nothrow) cached_block*[fNumRequested];
  Line 1492 [new]: fDestVecs = new(std::nothrow) generic_io_vec[fNumRequested];
  Line 1557 [new]: IORequest* request = new IORequest;
  Line 1723 [new]: // recycle existing before allocating a new one
  Line 1748 [new]: /*! Allocates a new block for \a blockNumber, ready for use */
  Line 1756 [new]: // recycle existing instead of allocating a new one
  Line 2083 [new]: TRACE_ALWAYS("new block:\n");
  Line 2165 [new]: \param _allocated tells you whether or not a new block has been allocated
  Line 2322 [new]: // get new transaction
  Line 3035 [new]: new (&sCaches) DoublyLinkedList<block_cache>;
  Line 3106 [new]: cache_transaction* transaction = new(std::nothrow) cache_transaction;
  Line 3287 [new]: /*!	Acknowledges the current parent transaction, and starts a new transaction
  Line 3289 [new]: The new transaction also gets a new transaction ID.
  Line 3314 [new]: // create a new transaction for the sub transaction
  Line 3315 [new]: cache_transaction* newTransaction = new(std::nothrow) cache_transaction;
  Line 3316 [new]: if (newTransaction == NULL)
  Line 3319 [new]: newTransaction->id = atomic_add(&cache->next_transaction_id, 1);
  Line 3320 [new]: T(Detach(cache, transaction, newTransaction));
  Line 3326 [new]: delete newTransaction;
  Line 3365 [new]: // we need to move this block over to the new transaction.
  Line 3369 [new]: newTransaction->first_block = block;
  Line 3373 [new]: block->transaction = newTransaction;
  Line 3381 [new]: newTransaction->num_blocks = transaction->sub_num_blocks;
  Line 3388 [new]: cache->transaction_hash.Insert(newTransaction);
  Line 3389 [new]: cache->last_transaction = newTransaction;
  Line 3391 [new]: return newTransaction->id;
  Line 3744 [new]: block_cache* cache = new(std::nothrow) block_cache(fd, numBlocks, blockSize,
  Line 4087 [new]: BlockPrefetcher* blockPrefetcher = new(std::nothrow) BlockPrefetcher(cache, blockNumber,
  Line 56 [panic]: // system, like out of memory situations - should only panic for debugging.
  Line 57 [panic]: #define FATAL(x) panic x
  Line 1504 [panic]: panic("BlockPrefetcher::Allocate: invalid block number %" B_PRIdOFF " (max %"
  Line 1736 [panic]: panic("block_cache::FreeBlock(): %" B_PRIdOFF ", original %p, parent %p\n",
  Line 2088 [panic]: panic("block_cache: supposed to be clean block was changed!\n");
  Line 2119 [panic]: panic("Invalid ref_count for block %p, cache %p\n", block, cache);
  Line 2148 [panic]: panic("put_cached_block: invalid block number %" B_PRIdOFF " (max %" B_PRIdOFF ")",
  Line 2179 [panic]: panic("get_cached_block: invalid block number %" B_PRIdOFF " (max %" B_PRIdOFF ")",
  Line 2262 [panic]: panic("get_writable_cached_block: invalid block number %" B_PRIdOFF " (max %" B_PRIdOFF ")",
  Line 2315 [panic]: //	Maybe we should even panic, since we can't prevent any deadlocks.
  Line 2316 [panic]: panic("get_writable_cached_block(): asked to get busy writable block "
  Line 2325 [panic]: panic("get_writable_cached_block(): invalid transaction %" B_PRId32 "!\n",
  Line 2331 [panic]: panic("get_writable_cached_block(): transaction already done!\n");
  Line 3102 [panic]: panic("last transaction (%" B_PRId32 ") still open!\n",
  Line 3183 [panic]: panic("cache_end_transaction(): invalid transaction ID\n");
  Line 3249 [panic]: panic("cache_abort_transaction(): invalid transaction ID\n");
  Line 3302 [panic]: panic("cache_detach_sub_transaction(): invalid transaction ID\n");
  Line 3405 [panic]: panic("cache_abort_sub_transaction(): invalid transaction ID\n");
  Line 3490 [panic]: panic("cache_start_sub_transaction(): invalid transaction ID %" B_PRId32 "\n",
  Line 3800 [panic]: panic("block_cache_sync_etc: invalid block number %" B_PRIdOFF
  Line 3872 [panic]: panic("Discarded block %" B_PRIdOFF " has already been changed in this "
  Line 3890 [panic]: panic("tried to make block writable on a read-only cache!");
  Line 3917 [panic]: panic("tried to get writable block on a read-only cache!");
  Line 3945 [panic]: panic("tried to get empty writable block on a read-only cache!");
  Line 4047 [panic]: panic("block_cache_set_dirty(): not yet implemented that way!\n");
  Line 35 [TODO]: // TODO: this is a naive but growing implementation to test the API:
  Line 38 [TODO]: // TODO: the retrieval/copy of the original data could be delayed until the
  Line 812 [TODO]: // TODO: this only works if the link is the first entry of block_cache
  Line 1953 [TODO]: // TODO: see if compare data is handled correctly here!
  Line 2314 [TODO]: // TODO: we have to wait here until the other transaction is done.
  Line 2371 [TODO]: // TODO: maybe we should just continue the current transaction in
  Line 3837 [TODO]: // TODO: this could be a nice place to issue the ATA trim command
  Line 3894 [TODO]: // TODO: this can be done better!
  Line 4045 [TODO]: // TODO: not yet implemented
  Line 2779 [dynamic_cast]: Action* action = dynamic_cast<Action*>(entry);
  Line 2786 [dynamic_cast]: BlockData* blockData = dynamic_cast<BlockData*>(entry);

File: src/system/kernel/cache/file_cache.cpp
  Line 12 [new]: #include <new>
  Line 157 [new]: fPages = new(std::nothrow) vm_page*[fPageCount];
  Line 161 [new]: fVecs = new(std::nothrow) generic_io_vec[fPageCount];
  Line 259 [new]: // we need to start a new iovec
  Line 396 [new]: generic_io_vec* vecs = new(std::nothrow) generic_io_vec[MAX_IO_VECS];
  Line 397 [new]: vm_page** pages = new(std::nothrow) vm_page*[MAX_IO_VECS];
  Line 548 [new]: generic_io_vec* vecs = new(std::nothrow) generic_io_vec[MAX_IO_VECS];
  Line 549 [new]: vm_page** pages = new(std::nothrow) vm_page*[MAX_IO_VECS];
  Line 1069 [new]: // get new module, if any
  Line 1157 [new]: PrecacheIO* io = new(std::nothrow) PrecacheIO(ref, lastOffset,
  Line 1293 [new]: file_cache_ref* ref = new file_cache_ref;
  Line 1371 [new]: // that the file cache functions add any new ones until re-enabled. The
  Line 1408 [new]: file_cache_set_size(void* _cacheRef, off_t newSize)
  Line 1412 [new]: TRACE(("file_cache_set_size(ref = %p, size = %lld)\n", ref, newSize));
  Line 1420 [new]: status_t status = cache->Resize(newSize, VM_PRIORITY_USER);
  Line 257 [panic]: panic("no more space for iovecs!");
  Line 828 [panic]: panic("cache_io() called with NULL ref!\n");
  Line 1359 [panic]: panic("Unbalanced file_cache_enable()!");
  Line 322 [TODO]: // TODO: start with oldest
  Line 581 [TODO]: // TODO: if space is becoming tight, and this cache is already grown
  Line 584 [TODO]: // TODO: the pages we allocate here should have been reserved upfront
  Line 1301 [TODO]: // TODO: delay VMCache creation until data is
  Line 1370 [TODO]: // TODO: This function only removes all pages from the cache and prevents

File: src/system/kernel/cache/file_map.cpp
  Line 7 [new]: #include <new>
  Line 193 [new]: // the new size is smaller than the minimal array size
  Line 208 [new]: // allocate new array
  Line 216 [new]: file_extent* newArray = (file_extent *)realloc(oldArray,
  Line 218 [new]: if (newArray == NULL)
  Line 222 [new]: memcpy(newArray, fDirect, sizeof(file_extent) * fCount);
  Line 224 [new]: fIndirect.array = newArray;
  Line 416 [new]: file_extent* newExtent = ExtentAt(startIndex + 1);
  Line 418 [new]: newExtent->offset = end;
  Line 419 [new]: newExtent->disk.length = startExtent->offset
  Line 422 [new]: newExtent->disk.offset = startExtent->disk.offset
  Line 425 [new]: newExtent->disk.offset = -1;
  Line 749 [new]: return new(std::nothrow) FileMap(vnode, size);
  Line 43 [TODO]: // TODO: use a sparse array - eventually, the unused BlockMap would be something
  Line 46 [TODO]: // TODO: it would be nice if we could free a file map in low memory situations.
  Line 51 [TODO]: // TODO: find out how much of these are typically used

File: src/system/kernel/cache/vnode_store.cpp
  Line 40 [TODO]: // TODO: We do need to commit memory when pages are mapped, though,

File: src/system/kernel/condition_variable.cpp
  Line 9 [new]: #include <new>
  Line 233 [new]: new(&fEntries) EntryList;
  Line 537 [new]: new(&sConditionVariableHash) ConditionVariableHash;
  Line 169 [panic]: panic("ConditionVariableEntry::Wait() called with interrupts "
  Line 256 [panic]: panic("Condition variable %p already published", object);
  Line 276 [panic]: panic("Condition variable %p not published, found: %p", this, variable);
  Line 375 [panic]: panic("tried to notify with invalid result %" B_PRId32 "\n", result);
  Line 541 [panic]: panic("condition_variable_init(): Failed to init hash table: %s",

File: src/system/kernel/cpu.cpp
  Line 207 [new]: cpu_topology_node* newNode = new(std::nothrow) cpu_topology_node;
  Line 208 [new]: if (newNode == NULL)
  Line 210 [new]: node->children[id] = newNode;
  Line 212 [new]: newNode->level = level;
  Line 214 [new]: newNode->children_count = maxID[level - 1];
  Line 215 [new]: newNode->children
  Line 216 [new]: = new(std::nothrow) cpu_topology_node*[maxID[level - 1]];
  Line 217 [new]: if (newNode->children == NULL)
  Line 220 [new]: memset(newNode->children, 0,
  Line 223 [new]: newNode->children_count = 0;
  Line 224 [new]: newNode->children = NULL;
  Line 274 [new]: = new(std::nothrow) cpu_topology_node*[maxID[CPU_TOPOLOGY_LEVELS - 1]];
  Line 345 [panic]: panic("cpu_idle() called with interrupts disabled.");
  Line 194 [TODO]: // TODO: data cache

File: src/system/kernel/debug/BreakpointManager.cpp
  Line 82 [new]: Breakpoint* breakpoint = new(std::nothrow) Breakpoint;
  Line 114 [new]: installed = new(std::nothrow) InstalledBreakpoint(address);
  Line 188 [new]: watchpoint = new(std::nothrow) InstalledWatchpoint;
  Line 492 [new]: Breakpoint* breakpoint = new(std::nothrow) Breakpoint;
  Line 742 [new]: TRACE("BreakpointManager::_WriteMemory(): failed to set new "
  Line 666 [user_memcpy]: error = user_memcpy(buffer, address, toRead);
  Line 750 [user_memcpy]: error = user_memcpy(address, buffer, toWrite);
  Line 757 [user_memcpy]: TRACE("BreakpointManager::_WriteMemory(): user_memcpy() failed: "

File: src/system/kernel/debug/blue_screen.cpp
  Line 363 [new]: int32 newX = argCount > 0 ? args[0] : 1;
  Line 364 [new]: if (newX > 0)
  Line 365 [new]: newX--;
  Line 366 [new]: move_cursor(newX, sScreen.y);
  Line 371 [new]: int32 newY = argCount > 0 ? args[0] : 1;
  Line 372 [new]: if (newY > 0)
  Line 373 [new]: newY--;
  Line 374 [new]: move_cursor(sScreen.x, newY);
  Line 114 [TODO]: // TODO: scrolling is usually too slow; we could probably just remove it
  Line 484 [TODO]: // TODO: real tab...

File: src/system/kernel/debug/core_dump.cpp
  Line 90 [malloc]: fAligned = (uint8*)malloc(totalCapacity);
  Line 428 [malloc]: fSymbolTableData = (elf_sym*)malloc(sizeof(elf_sym) * symbolCount);
  Line 429 [malloc]: fStringTableData = (char*)malloc(stringTableSize);
  Line 609 [malloc]: fBuffer = (uint8*)malloc(fCapacity);
  Line 13 [new]: #include <new>
  Line 138 [new]: return new(buffer) Type;
  Line 147 [new]: char* newString = AllocateString(length);
  Line 148 [new]: if (newString != NULL)
  Line 149 [new]: memcpy(newString, string, length + 1);
  Line 151 [new]: return newString;
  Line 183 [new]: ThreadState* state = new(std::nothrow) ThreadState;
  Line 307 [new]: ImageInfo* imageInfo = new(std::nothrow) ImageInfo(image);
  Line 1624 [new]: CoreDumper* coreDumper = new(std::nothrow) CoreDumper();
  Line 719 [user_memcpy]: if (user_memcpy(fBuffer + fBuffered, data, B_PAGE_SIZE) != B_OK)

File: src/system/kernel/debug/debug.cpp
  Line 752 [malloc]: if (char* format = (char*)debug_malloc(length + 1)) {
  Line 785 [malloc]: char* commandBuffer = (char*)debug_malloc(kCommandBufferSize);
  Line 875 [malloc]: jmp_buf* jumpBuffer = (jmp_buf*)debug_malloc(sizeof(jmp_buf));
  Line 1120 [malloc]: char* buffer = (char*)debug_malloc(bufferSize);
  Line 1358 [malloc]: sSyslogMessage = (syslog_message*)malloc(SYSLOG_MESSAGE_BUFFER_SIZE);
  Line 1413 [malloc]: sPreviousSessionSyslogBuffer = malloc(args->previous_debug_size);
  Line 265 [new]: // print the new chars (and the following ones)
  Line 1128 [new]: bool newLine = false;
  Line 1144 [new]: newLine = buffer[toPrint - 1] == '\n';
  Line 1161 [new]: if (!newLine)
  Line 1184 [new]: int32 newCPU = parse_expression(argv[1]);
  Line 1185 [new]: if (newCPU < 0 || newCPU >= smp_get_num_cpus()) {
  Line 1190 [new]: if (newCPU == smp_get_current_cpu()) {
  Line 1191 [new]: kprintf("already running on CPU %" B_PRId32 "\n", newCPU);
  Line 1195 [new]: sHandOverKDLToCPU = newCPU;
  Line 1689 [new]: new(&gDefaultDebugOutputFilter) DefaultDebugOutputFilter;
  Line 2135 [new]: set_dprintf_enabled(bool newState)
  Line 2138 [new]: sSerialDebugEnabled = newState;
  Line 1944 [user_memcpy]: /*!	Similar to user_memcpy(), but can only be invoked from within the kernel
  Line 1253 [write_port]: status_t status = write_port_etc(sSyslogPort, SYSLOG_MESSAGE,
  Line 78 [panic]: // separates panic() message from command list to execute
  Line 775 [panic]: execute_panic_commands()
  Line 873 [panic]: // No commands yet or we came here via a panic(). Always print a stack
  Line 885 [panic]: // Commands are registered already -- execute panic() commands. Do that
  Line 891 [panic]: execute_panic_commands();
  Line 1080 [panic]: cmd_execute_panic_commands(int argc, char** argv)
  Line 1082 [panic]: execute_panic_commands();
  Line 1712 [panic]: add_debugger_command_etc("panic_commands", &cmd_execute_panic_commands,
  Line 1713 [panic]: "Execute commands associated with the panic() that caused "
  Line 1716 [panic]: "Executes the commands associated with the panic() that caused "
  Line 2106 [panic]: panic(const char* format, ...)
  Line 1213 [TODO]: // TODO: A semaphore is rather unhandy here. It is released for

File: src/system/kernel/debug/debug_builtin_commands.cpp
  Line 302 [new]: // newline

File: src/system/kernel/debug/debug_commands.cpp
  Line 463 [malloc]: cmd = (debugger_command*)malloc(sizeof(debugger_command));
  Line 88 [new]: while (const char* newLine = strchr(string, '\n')) {
  Line 89 [new]: size_t length = newLine - string;
  Line 98 [new]: string = newLine + 1;
  Line 105 [new]: // buffer is full, but contains no newline -- execute anyway
  Line 128 [new]: while (char* newLine = strchr(line, '\n')) {
  Line 130 [new]: *newLine = '\0';
  Line 133 [new]: line = newLine + 1;
  Line 139 [new]: // buffer is full, but contains no newline -- execute anyway
  Line 375 [new]: new(&sPipeOutputFilters[i]) PipeDebugOutputFilter(pipe, i,
  Line 483 [new]: add_debugger_command_alias(const char* newName, const char* oldName,
  Line 493 [new]: // register new command
  Line 494 [new]: return add_debugger_command_etc(newName, command->func,
  Line 372 [TODO]: // TODO: If a pipe is invoked in a pipe, outputs will clash.

File: src/system/kernel/debug/debug_heap.cpp
  Line 272 [malloc]: debug_malloc(size_t size)
  Line 285 [malloc]: void* allocation = debug_malloc(allocationSize);
  Line 9 [new]: #include <new>

File: src/system/kernel/debug/debug_paranoia.cpp
  Line 237 [strcpy]: fDescription = alloc_tracing_buffer_strcpy(description, 64, false);
  Line 10 [new]: #include <new>
  Line 332 [new]: #	define T(x)	new(std::nothrow) ParanoiaTracing::x
  Line 438 [new]: set = new(slot) ParanoiaCheckSet(object, description);
  Line 550 [new]: check = new(slot) ParanoiaCheck(address, size);
  Line 417 [panic]: panic("create_paranoia_check_set(): NULL object");
  Line 426 [panic]: panic("create_paranoia_check_set(): object %p already has a check set",
  Line 434 [panic]: panic("create_paranoia_check_set(): out of free slots");
  Line 455 [panic]: panic("delete_paranoia_check_set(): object %p doesn't have a check set",
  Line 480 [panic]: panic("run_paranoia_checks(): object %p doesn't have a check set",
  Line 490 [panic]: panic("paranoia check failed for object %p (%s), address: %p, "
  Line 514 [panic]: panic("set_paranoia_check(): object %p doesn't have a check set",
  Line 523 [panic]: panic("set_paranoia_check(): object %p already has a check for "
  Line 529 [panic]: panic("set_paranoia_check(): changing check sizes not supported");
  Line 538 [panic]: panic("set_paranoia_check(): object %p doesn't have a check for "
  Line 546 [panic]: panic("set_paranoia_check(): out of free slots");
  Line 567 [panic]: panic("remove_paranoia_check(): object %p doesn't have a check set",
  Line 575 [panic]: panic("remove_paranoia_check(): no check for address %p "
  Line 581 [panic]: panic("remove_paranoia_check(): changing check sizes not "

File: src/system/kernel/debug/debug_parser.cpp
  Line 146 [malloc]: checked_malloc(size_t size)
  Line 148 [malloc]: void* address = debug_malloc(size);
  Line 750 [malloc]: debugger_command_pipe* pipe = (debugger_command_pipe*)checked_malloc(
  Line 806 [malloc]: char** argv = (char**)checked_malloc(kMaxArgumentCount * sizeof(char*));
  Line 956 [malloc]: char* buffer = (char*)checked_malloc(length);
  Line 640 [new]: // compute the new variable value
  Line 683 [new]: // compute the new value
  Line 418 [TODO]: case '|':	// TODO: Move when we support & and | in expressions.

File: src/system/kernel/debug/frame_buffer_console.cpp
  Line 502 [malloc]: sVesaModes = (vesa_mode*)malloc(args->vesa_modes_size);
  Line 509 [malloc]: edid1_info* info = (edid1_info*)malloc(sizeof(edid1_info));

File: src/system/kernel/debug/gdb.cpp
  Line 238 [TODO]: // TODO: Parse the address and resume there!
  Line 247 [TODO]: // TODO: Implement!
  Line 330 [TODO]: // TODO: Implement!

File: src/system/kernel/debug/guarded_heap.cpp
  Line 15 [malloc]: #include <malloc.h>
  Line 505 [malloc]: void* newBlock = malloc_etc(newSize, flags);
  Line 867 [malloc]: malloc(size_t size)
  Line 889 [malloc]: return malloc_etc(newSize, flags);
  Line 485 [new]: guarded_heap_realloc(guarded_heap& heap, void* address, size_t newSize, uint32 flags)
  Line 502 [new]: if (oldSize == newSize)
  Line 505 [new]: void* newBlock = malloc_etc(newSize, flags);
  Line 506 [new]: if (newBlock == NULL)
  Line 509 [new]: memcpy(newBlock, address, min_c(oldSize, newSize));
  Line 512 [new]: return newBlock;
  Line 730 [new]: new(&sGuardedHeapCache) GuardedHeapCache;
  Line 881 [new]: realloc_etc(void* address, size_t newSize, uint32 flags)
  Line 883 [new]: if (newSize == 0) {
  Line 889 [new]: return malloc_etc(newSize, flags);
  Line 891 [new]: return guarded_heap_realloc(sGuardedHeap, address, newSize, flags);
  Line 896 [new]: realloc(void* address, size_t newSize)
  Line 898 [new]: return realloc_etc(address, newSize, 0);
  Line 934 [new]: ObjectCache* cache = new ObjectCache;
  Line 148 [panic]: panic("guarded_heap: failed to allocate meta area");
  Line 167 [panic]: panic("guarded_heap_add_area: too early in the boot!");
  Line 209 [panic]: panic("guarded_heap: out of virtual memory");
  Line 340 [panic]: panic("out of memory");
  Line 406 [panic]: panic("tried to free %p, which is a %s chunk (last accessor: team %d, thread %d)",
  Line 409 [panic]: panic("tried to free %p, but can't find a heap chunk for it", address);
  Line 417 [panic]: panic("tried to free %p, but allocation base is really %p",
  Line 491 [panic]: panic("realloc(%p): no such allocation", address);
  Line 495 [panic]: panic("realloc(%p): chunk base is really %p", address,
  Line 519 [panic]: panic("guarded_heap: invalid access to %p @! guarded_heap_chunk %p",

File: src/system/kernel/debug/safemode_settings.cpp
  Line 259 [user_memcpy]: || user_memcpy(&bufferSize, _userBufferSize, sizeof(size_t)) != B_OK
  Line 271 [user_memcpy]: || user_memcpy(_userBufferSize, &bufferSize, sizeof(size_t))
  Line 81 [TODO]: // TODO: That's not correct. There should be another loop.

File: src/system/kernel/debug/system_profiler.cpp
  Line 79 [new]: Thread* newThread);
  Line 401 [new]: fWaitObjectBuffer = new(std::nothrow) WaitObject[fWaitObjectCount];
  Line 806 [new]: SystemProfiler::ThreadScheduled(Thread* oldThread, Thread* newThread)
  Line 825 [new]: event->thread = newThread->id;
  Line 1507 [new]: sRecordedParameters = new(std::nothrow) system_profiler_parameters;
  Line 1531 [new]: SystemProfiler* profiler = new(std::nothrow) SystemProfiler(B_SYSTEM_TEAM,
  Line 1542 [new]: // set the new profiler
  Line 1619 [new]: SystemProfiler* profiler = new(std::nothrow) SystemProfiler(team, areaInfo,
  Line 1629 [new]: // set the new profiler
  Line 1712 [new]: area_id newArea = transfer_area(sRecordedParameters->buffer_area, &address,
  Line 1714 [new]: if (newArea < 0)
  Line 1715 [new]: return newArea;
  Line 1717 [new]: status_t status = set_area_protection(newArea, B_READ_AREA);
  Line 1719 [new]: sRecordedParameters->buffer_area = newArea;
  Line 1725 [new]: delete_area(newArea);
  Line 1585 [user_memcpy]: || user_memcpy(&parameters, userParameters, sizeof(parameters))
  Line 1666 [user_memcpy]: user_memcpy(_droppedEvents, &droppedEvents, sizeof(droppedEvents));
  Line 1721 [user_memcpy]: status = user_memcpy(userParameters, sRecordedParameters,
  Line 912 [TODO]: // TODO: It is possible that we get remove notifications for teams that
  Line 998 [TODO]: // TODO: It is possible that we get remove notifications for threads that

File: src/system/kernel/debug/tracing.cpp
  Line 874 [strcpy]: fMessage = alloc_tracing_buffer_strcpy(message, 256, false);
  Line 907 [strcpy]: fMessage = alloc_tracing_buffer_strcpy(message, 256, true);
  Line 1628 [strcpy]: alloc_tracing_buffer_strcpy(const char* source, size_t maxSize, bool user)
  Line 147 [malloc]: char* buffer = (char*)debug_malloc(kBufferSize);
  Line 331 [new]: trace_entry* newFirst = NextEntry(fFirstEntry);
  Line 348 [new]: if (newFirst == NULL) {
  Line 354 [new]: fFirstEntry = newFirst;
  Line 445 [new]: // no previous tracing data found -- create new one
  Line 789 [new]: TraceEntry::operator new(size_t size, const std::nothrow_t&) throw()
  Line 1105 [new]: TraceFilter* filter = new(&fFilters[fFilterCount++])
  Line 1110 [new]: TraceFilter* filter = new(&fFilters[fFilterCount++])
  Line 1115 [new]: TraceFilter* filter = new(&fFilters[fFilterCount++])
  Line 1120 [new]: TraceFilter* filter = new(&fFilters[fFilterCount++])
  Line 1125 [new]: TraceFilter* filter = new(&fFilters[fFilterCount++]) NotTraceFilter;
  Line 1131 [new]: TraceFilter* filter = new(&fFilters[fFilterCount++]) AndTraceFilter;
  Line 1139 [new]: TraceFilter* filter = new(&fFilters[fFilterCount++]) OrTraceFilter;
  Line 1153 [new]: TraceFilter* filter = new(&fFilters[fFilterCount++])
  Line 1164 [new]: TraceFilter* filter = new(&fFilters[fFilterCount++])
  Line 1367 [new]: "before, or there were new entries written since the last "
  Line 1540 [new]: // don't print trailing new line
  Line 1789 [new]: new(nothrow) TracingLogStartEntry();
  Line 1854 [new]: new(nothrow) KernelTraceEntry(buffer);
  Line 1863 [new]: new(nothrow) UserTraceEntry(message);
  Line 1618 [user_memcpy]: if (user_memcpy(buffer, source, size) != B_OK)
  Line 1667 [panic]: // in the kernel stack trace would still cause a panic(), but this is
  Line 543 [TODO]: // TODO: ATM re-attaching the previous tracing buffer doesn't work very
  Line 681 [TODO]: // TODO: Actually check the entries! Do that when first accessing the
  Line 1003 [TODO]: // TODO: this is *very* slow
  Line 1014 [TODO]: // TODO: this is *very* slow
  Line 1028 [TODO]: // TODO: this is *very* slow
  Line 973 [dynamic_cast]: = dynamic_cast<const AbstractTraceEntry*>(_entry);
  Line 984 [dynamic_cast]: = dynamic_cast<const AbstractTraceEntry*>(_entry);
  Line 1745 [dynamic_cast]: AbstractTraceEntry* abstract = dynamic_cast<AbstractTraceEntry*>(entry);

File: src/system/kernel/debug/user_debugger.cpp
  Line 113 [new]: // handed over to a new debugger. In either case we don't send the
  Line 480 [new]: // set the new port ownership
  Line 507 [new]: // set the new port ownership
  Line 1017 [new]: message.new_team = teamID;
  Line 1067 [new]: /*!	Called by a new userland thread to update the debugging related flags of
  Line 1072 [new]: user_debug_update_new_thread_flags(Thread* thread)
  Line 1096 [new]: message.new_thread = threadID;
  Line 1138 [new]: port_id newDebuggerPort = team->debug_info.debugger_port;
  Line 1144 [new]: if (newDebuggerPort == debuggerPort
  Line 1870 [new]: void* newAddress = NULL;
  Line 1872 [new]: "debugger-cloned area", &newAddress, B_ANY_ADDRESS, B_READ_AREA,
  Line 1874 [new]: reply.clone_area.address = (void*)((addr_t)newAddress + addressOffset);
  Line 2701 [new]: // having sent the handed-over message to the new debugger.
  Line 2710 [new]: // set the new debugger
  Line 2754 [new]: // notify the new debugger
  Line 2759 [new]: dprintf("install_team_debugger(): Failed to send message to new "
  Line 2829 [new]: breakpointManager = new(std::nothrow) BreakpointManager;
  Line 73 [write_port]: kill_interruptable_write_port(port_id port, int32 code, const void *buffer,
  Line 76 [write_port]: return write_port_etc(port, code, buffer, bufferSize, B_KILL_CAN_INTERRUPT,
  Line 121 [write_port]: error = write_port_etc(port, code, buffer, bufferSize,
  Line 705 [write_port]: error = kill_interruptable_write_port(replyPort, event,
  Line 1039 [write_port]: write_port_etc(debuggerPort, B_DEBUGGER_MESSAGE_TEAM_DELETED, &message,
  Line 1152 [write_port]: write_port_etc(debuggerPort, B_DEBUGGER_MESSAGE_THREAD_DELETED,
  Line 1610 [write_port]: status_t error = kill_interruptable_write_port(threadDebugPort,
  Line 1969 [write_port]: result = write_port(threadDebugPort,
  Line 2009 [write_port]: write_port(threadDebugPort,
  Line 2035 [write_port]: result = write_port(threadDebugPort,
  Line 2570 [write_port]: status_t error = kill_interruptable_write_port(replyPort, command,
  Line 2755 [write_port]: error = write_port_etc(debuggerPort,
  Line 2777 [write_port]: kill_interruptable_write_port(nubPort, B_DEBUG_MESSAGE_HANDED_OVER,
  Line 2781 [write_port]: error = write_port_etc(oldDebuggerPort,
  Line 660 [read_port]: ssize_t commandMessageSize = read_port_etc(port, &command,
  Line 1740 [read_port]: ssize_t messageSize = read_port_etc(port, &command, &message,
  Line 50 [TODO]: // TODO: Since the introduction of team_debug_info::debugger_changed_condition
  Line 801 [TODO]: // TODO: Maybe better use ref-counting and a flag in the breakpoint manager.
  Line 2950 [TODO]: // TODO: Check, if the return value is really the old state.

File: src/system/kernel/device_manager/FileDevice.cpp
  Line 14 [new]: #include <new>
  Line 186 [new]: Cookie* cookie = new(std::nothrow) Cookie(fd);
  Line 258 [user_memcpy]: return user_memcpy(buffer, &result, sizeof(ResultType));
  Line 323 [user_memcpy]: if (user_memcpy(&iconData, buffer, sizeof(device_icon)) != B_OK) {
  Line 328 [user_memcpy]: if (user_memcpy(iconData.icon_data, kDeviceIcon,
  Line 335 [user_memcpy]: return user_memcpy(buffer, &iconData, sizeof(device_icon));
  Line 247 [ioctl]: set_ioctl_result(const ResultType& result, void* buffer, size_t length)
  Line 272 [ioctl]: return set_ioctl_result(
  Line 305 [ioctl]: return set_ioctl_result((pollFD.revents & pollFD.events) != 0,
  Line 361 [ioctl]: return set_ioctl_result(geometry, buffer, length);
  Line 365 [ioctl]: return set_ioctl_result((status_t)B_OK, buffer, length);
  Line 375 [ioctl]: return set_ioctl_result((uint8)0xf8, buffer, length);
  Line 164 [TODO]: // TODO: Support!
  Line 234 [TODO]: // TODO: The implementation is fine in principle, but do_fd_io() requires either
  Line 395 [TODO]: // TODO: Support (select_fd())!
  Line 403 [TODO]: // TODO: Support (deselect_fd())!

File: src/system/kernel/device_manager/IOCache.cpp
  Line 119 [new]: fPages = new(std::nothrow) vm_page*[fPagesPerLine];
  Line 120 [new]: fVecs = new(std::nothrow) generic_io_vec[fPagesPerLine];
  Line 149 [new]: // new media -- burn all cached data
  Line 58 [panic]: panic("Invalid cache line size (%" B_PRIuSIZE "). Must be a power of 2 "
  Line 112 [panic]: panic("IOCache::Init(): Where's our area (id: %" B_PRId32 ")?!", fArea);
  Line 199 [TODO]: // TODO:...
  Line 323 [TODO]: // TODO: If this is a read request and the missing pages range doesn't intersect
  Line 343 [TODO]: // TODO: When memory is low, we should consider cannibalizing ourselves or
  Line 675 [TODO]: // TODO: _MapPages() cannot fail, so the fallback is never needed. Test which

File: src/system/kernel/device_manager/IORequest.cpp
  Line 97 [malloc]: = (IOBuffer*)(malloc_etc(size, vip ? HEAP_PRIORITY_VIP : 0));
  Line 152 [malloc]: cookie = new(malloc_flags(fVIP ? HEAP_PRIORITY_VIP : 0))
  Line 770 [malloc]: ? new(malloc_flags(HEAP_PRIORITY_VIP)) IORequest
  Line 152 [new]: cookie = new(malloc_flags(fVIP ? HEAP_PRIORITY_VIP : 0))
  Line 770 [new]: ? new(malloc_flags(HEAP_PRIORITY_VIP)) IORequest
  Line 771 [new]: : new(std::nothrow) IORequest;
  Line 1345 [user_memcpy]: status = user_memcpy(bounceBuffer, (void*)(addr_t)external, size);
  Line 1347 [user_memcpy]: status = user_memcpy((void*)(addr_t)external, bounceBuffer, size);
  Line 238 [panic]: panic("memory already locked!");
  Line 270 [panic]: panic("memory not locked");
  Line 1233 [panic]: panic("IORequest::ClearData(): invalid range: (%" B_PRIdOFF
  Line 1289 [panic]: panic("IORequest::_CopyData(): invalid range: (%" B_PRIdOFF ", %lu)",
  Line 178 [TODO]: // TODO: This is a potential violation of the VIP requirement, since
  Line 198 [TODO]: // TODO: This is a potential violation of the VIP requirement, since
  Line 979 [dynamic_cast]: || dynamic_cast<IOOperation*>(fChildren.Head()) == NULL);
  Line 1180 [dynamic_cast]: return dynamic_cast<IORequest*>(fChildren.Head());
  Line 1189 [dynamic_cast]: return dynamic_cast<IORequest*>(fChildren.GetNext(previous));

File: src/system/kernel/device_manager/IORequest.h
  Line 12 [new]: #include <new>

File: src/system/kernel/device_manager/IOSchedulerRoster.cpp
  Line 213 [new]: new(&sDefaultInstance) IOSchedulerRoster;

File: src/system/kernel/device_manager/IOSchedulerSimple.cpp
  Line 121 [new]: fNewRequestCondition.Init(this, "I/O new request");
  Line 187 [new]: IOOperation* operation = new(std::nothrow) IOOperation;
  Line 194 [new]: fOperationArray = new(std::nothrow) IOOperation*[count];
  Line 201 [new]: fRequestOwners = new(std::nothrow) RequestOwnerHashTable;
  Line 535 [new]: // Wait for new requests owners. First check whether any finisher work
  Line 546 [new]: // Wait for new requests.
  Line 838 [new]: // not in table -- allocate a new one
  Line 839 [new]: owner = new(sRequestOwnerCache, CACHE_DONT_WAIT_FOR_MEMORY) RequestOwner;
  Line 274 [panic]: panic("IOSchedulerSimple: Out of request owners!\n");
  Line 681 [panic]: panic("no more requests for owner %p (thread %" B_PRId32 ")", owner, owner->thread);
  Line 215 [TODO]: // TODO: Use a device speed dependent bandwidths!
  Line 256 [TODO]: // TODO: it would be nice to be able to lock the memory later, but we can't
  Line 480 [TODO]: // TODO: If the device has block size restrictions, we might need to use
  Line 512 [TODO]: // TODO: Use a priority dependent quantum!
  Line 575 [TODO]: // TODO: _Scheduler() could directly add the operations to the array.
  Line 658 [TODO]: // TODO: We might actually grant the owner more bandwidth than
  Line 660 [TODO]: // TODO: We should make sure that after the first read operation

File: src/system/kernel/device_manager/devfs.cpp
  Line 261 [malloc]: vnode = (struct devfs_vnode*)malloc(sizeof(struct devfs_vnode));
  Line 445 [malloc]: struct devfs_partition* partition = (struct devfs_partition*)malloc(
  Line 901 [malloc]: fs = (struct devfs*)malloc(sizeof(struct devfs));
  Line 1110 [malloc]: cookie = (struct devfs_cookie*)malloc(sizeof(struct devfs_cookie));
  Line 1307 [malloc]: cookie = (devfs_dir_cookie*)malloc(sizeof(devfs_dir_cookie));
  Line 372 [new]: // the new vnode is the first entry in the list
  Line 637 [new]: // set up the new directory
  Line 651 [new]: new_node(struct devfs* fs, const char* path, struct devfs_vnode** _node,
  Line 710 [new]: // set up the new vnode
  Line 756 [new]: status = new_node(fs, path, &node, &dirNode);
  Line 915 [new]: fs->vnode_hash = new(std::nothrow) NodeTable();
  Line 1287 [new]: // set up the new directory
  Line 2051 [new]: FileDevice* device = new(std::nothrow) FileDevice;
  Line 2108 [new]: const char* newName)
  Line 2110 [new]: if (oldName == NULL || newName == NULL)
  Line 2123 [new]: // check if the new path already exists
  Line 2124 [new]: if (devfs_find_in_dir(device->parent, newName))
  Line 2127 [new]: char* name = strdup(newName);
  Line 2139 [new]: device->parent->id, newName, node->id);
  Line 1467 [user_memcpy]: return user_memcpy(buffer, &geometry, sizeof(device_geometry));
  Line 1536 [user_memcpy]: return user_memcpy(buffer, &partition->info,
  Line 1432 [ioctl]: devfs_ioctl(fs_volume* _volume, fs_vnode* _vnode, void* _cookie, uint32 op,
  Line 1438 [ioctl]: TRACE(("devfs_ioctl: vnode %p, cookie %p, op %" B_PRIu32
  Line 1564 [ioctl]: dprintf("devfs: unsupported legacy ioctl B_GET_NEXT_OPEN_DEVICE\n");
  Line 1567 [ioctl]: dprintf("devfs: unsupported legacy ioctl B_ADD_FIXED_DRIVER\n");
  Line 1570 [ioctl]: dprintf("devfs: unsupported legacy ioctl B_REMOVE_FIXED_DRIVER\n");
  Line 1955 [ioctl]: &devfs_ioctl,
  Line 742 [panic]: panic("publish_device() called before devfs mounted\n");
  Line 1090 [panic]: panic("devfs_removevnode: vnode %p asked to be removed is present in dir\n", vnode);
  Line 1551 [TODO]: // TODO: we might want to actually find the mountpoint
  Line 1656 [TODO]: // TODO: Obsolete hook!
  Line 1688 [TODO]: // TODO: use io_requests for this!
  Line 1747 [TODO]: // TODO: use io_requests for this!
  Line 1833 [TODO]: // TODO: this only works for partitions right now - if we should decide
  Line 2034 [dynamic_cast]: FileDevice* device = dynamic_cast<FileDevice*>(node->stream.u.dev.device);

File: src/system/kernel/device_manager/device_manager.cpp
  Line 1022 [malloc]: value.raw.data = malloc(attr.value.raw.length);
  Line 9 [new]: #include <new>
  Line 549 [new]: device_node* newNode = new(std::nothrow) device_node(moduleName, attrs);
  Line 550 [new]: if (newNode == NULL)
  Line 553 [new]: TRACE(("%p: register node \"%s\", parent %p\n", newNode, moduleName,
  Line 556 [new]: status_t status = newNode->InitCheck();
  Line 558 [new]: status = newNode->AcquireResources(ioResources);
  Line 560 [new]: status = newNode->Register(parent);
  Line 563 [new]: newNode->Release();
  Line 568 [new]: *_node = newNode;
  Line 693 [new]: Device* device = new(std::nothrow) Device(node, moduleName);
  Line 709 [new]: attr = new(std::nothrow) device_attr_private();
  Line 719 [new]: attr = new(std::nothrow) device_attr_private();
  Line 1249 [new]: = new(std::nothrow) device_attr_private(*attrs);
  Line 1257 [new]: device_attr_private* attr = new(std::nothrow) device_attr_private();
  Line 1324 [new]: io_resource_private* resource = new(std::nothrow) io_resource_private;
  Line 1561 [new]: KPath* path = new(std::nothrow) KPath;
  Line 1587 [new]: stack = new(std::nothrow) Stack<KPath*>();
  Line 1884 [new]: // (usually only one at all, but there might be a new driver
  Line 374 [user_memcpy]: return user_memcpy(buffer, &cookie, sizeof(device_node_cookie));
  Line 385 [user_memcpy]: if (user_memcpy(&cookie, buffer, sizeof(device_node_cookie)) < B_OK)
  Line 401 [user_memcpy]: return user_memcpy(buffer, &cookie, sizeof(device_node_cookie));
  Line 412 [user_memcpy]: if (user_memcpy(&cookie, buffer, sizeof(device_node_cookie)) < B_OK)
  Line 439 [user_memcpy]: return user_memcpy(buffer, &cookie, sizeof(device_node_cookie));
  Line 449 [user_memcpy]: if (user_memcpy(&attrInfo, buffer, sizeof(device_attr_info)) < B_OK)
  Line 509 [user_memcpy]: user_memcpy(attr.value.raw.data, attr_info->attr.value.raw.data,
  Line 515 [user_memcpy]: return user_memcpy(buffer, &attrInfo, sizeof(device_attr_info));
  Line 352 [TODO]: // TODO: implement module directory traversal!
  Line 1130 [TODO]: // TODO: maybe the device should be unlinked in devfs, too
  Line 1601 [TODO]: // TODO: maybe make this extendible via settings file?
  Line 1614 [TODO]: // TODO: check for ahci interface
  Line 1850 [TODO]: // TODO: we may want to be a bit more specific in the future
  Line 1895 [TODO]: // TODO: if this fails, we could try the second best driver,
  Line 1997 [TODO]: // TODO: maybe make this extendible via settings file?
  Line 746 [dynamic_cast]: Device* device = dynamic_cast<Device*>(baseDevice);

File: src/system/kernel/device_manager/dma_resources.cpp
  Line 35 [malloc]: DMABuffer* buffer = (DMABuffer*)malloc(
  Line 207 [malloc]: fScratchVecs = (generic_io_vec*)malloc(
  Line 279 [new]: DMABounceBuffer* buffer = new(std::nothrow) DMABounceBuffer;
  Line 270 [panic]: panic("get_memory_map() failed.");
  Line 728 [panic]: panic("don't do this to me!");
  Line 127 [TODO]: // TODO: add DMA attributes instead of reusing block_io's
  Line 221 [TODO]: // TODO: create bounce buffers in as few areas as feasible
  Line 350 [TODO]: TODO: is that what we want here?
  Line 451 [TODO]: // TODO: !partialOperation || totalLength >= fBlockSize
  Line 452 [TODO]: // TODO: Maybe enforce fBounceBufferSize >= 2 * fBlockSize.
  Line 509 [TODO]: // TODO: We should do that lazily when needed!
  Line 694 [TODO]: // TODO: sometimes we can replace the last vec with the bounce buffer

File: src/system/kernel/device_manager/id_generator.cpp
  Line 26 [new]: #include <new>
  Line 73 [new]: /*!	Create new generator.
  Line 81 [new]: id_generator* generator = new(std::nothrow) id_generator(name);
  Line 180 [new]: new(&sGenerators) GeneratorList;
  Line 192 [new]: // find generator, create new if not there

File: src/system/kernel/device_manager/io_resources.cpp
  Line 158 [new]: new(&sMemoryList) ResourceTypeList;
  Line 159 [new]: new(&sPortList) ResourceTypeList;
  Line 160 [new]: new(&sDMAChannelList) ResourceTypeList;
  Line 97 [TODO]: // TODO: we might want to ignore resources that belong to

File: src/system/kernel/device_manager/legacy_drivers.cpp
  Line 624 [malloc]: driver = (legacy_driver*)malloc(sizeof(legacy_driver));
  Line 1250 [malloc]: fDeviceModule = (device_module_info*)malloc(sizeof(device_module_info));
  Line 11 [new]: #include <new>
  Line 329 [new]: TRACE(("devfs: publishing new device \"%s\"\n", devicePaths[0]));
  Line 330 [new]: device = new(std::nothrow) LegacyDevice(driver, devicePaths[0], hooks);
  Line 386 [new]: #error Add checks here for new vs old api version!
  Line 505 [new]: driver_event* event = new (std::nothrow) driver_event(
  Line 608 [new]: //dprintf("new driver has priority %ld, old %ld\n", priority, driver->priority);
  Line 622 [new]: // we don't know this driver, create a new entry for it
  Line 648 [new]: new(&driver->devices) DeviceList;
  Line 723 [new]: // Add new drivers
  Line 999 [new]: KPath* nextPath = new(nothrow) KPath(path);
  Line 1032 [new]: KPath* path = new(nothrow) KPath(basePath);
  Line 1092 [new]: driver_event* driverEvent = new(std::nothrow) driver_event(
  Line 1122 [new]: directory_node_entry* entry = new(std::nothrow) directory_node_entry;
  Line 1131 [new]: new_driver_entry(const char* path, dev_t device, ino_t node)
  Line 1133 [new]: driver_entry* entry = new(std::nothrow) driver_entry;
  Line 1202 [new]: = new(std::nothrow) directory_node_entry;
  Line 1222 [new]: driver_entry* entry = new_driver_entry(path.Path(), stat.st_dev,
  Line 1353 [new]: // According to Be newsletter, vol II, issue 36,
  Line 1448 [new]: LegacyDevice* device = new(std::nothrow) LegacyDevice(NULL, path, hooks);
  Line 1491 [new]: new(&sDirectoryWatcher) DirectoryWatcher;
  Line 1520 [new]: sDriverHash = new(std::nothrow) DriverTable();
  Line 1526 [new]: new(&sDriverWatcher) DriverWatcher;
  Line 1527 [new]: new(&sDriverEvents) DriverEventList;
  Line 1034 [panic]: panic("out of memory");
  Line 523 [TODO]: // TODO: would it be better to initialize a static structure here
  Line 596 [TODO]: // TODO: do properly, but for now we just update the path if it
  Line 606 [TODO]: // TODO: check if this driver is a different one and has precedence
  Line 614 [TODO]: // TODO: test for changes here and/or via node monitoring and reload
  Line 1077 [TODO]: // TODO: adjust driver priority if necessary
  Line 1114 [TODO]: // TODO: create missing directories?
  Line 1343 [TODO]: // TODO: setup compatibility layer!

File: src/system/kernel/disk_device_manager/KDiskDevice.cpp
  Line 336 [ioctl]: if (ioctl(fFD, B_GET_MEDIA_STATUS, mediaStatus, sizeof(*mediaStatus)) != 0)
  Line 338 [ioctl]: // maybe the device driver doesn't implement this ioctl -- see, if getting
  Line 343 [ioctl]: // if the device is not removable, we can ignore the failed ioctl
  Line 358 [ioctl]: if (ioctl(fFD, B_GET_GEOMETRY, geometry, sizeof(*geometry)) != 0)
  Line 378 [ioctl]: if (ioctl(fFD, B_GET_DEVICE_NAME, name, sizeof(name)) == B_OK)
  Line 222 [TODO]: // TODO: allow a device to notify us about its media status!

File: src/system/kernel/disk_device_manager/KDiskDeviceManager.cpp
  Line 162 [new]: device_event* deviceEvent = new(std::nothrow) device_event;
  Line 218 [new]: // a new raw device was added/removed
  Line 260 [new]: fDevices(new(nothrow) DeviceMap),
  Line 261 [new]: fPartitions(new(nothrow) PartitionMap),
  Line 262 [new]: fDiskSystems(new(nothrow) DiskSystemMap),
  Line 263 [new]: fObsoletePartitions(new(nothrow) PartitionSet),
  Line 267 [new]: fDeviceWatcher(new(nothrow) DeviceWatcher()),
  Line 268 [new]: fNotifications(new(nothrow) DiskNotifications)
  Line 363 [new]: sDefaultManager = new(nothrow) KDiskDeviceManager;
  Line 688 [new]: KDiskDeviceManager::CreateDevice(const char* path, bool* newlyCreated)
  Line 698 [new]: if (newlyCreated)
  Line 699 [new]: *newlyCreated = false;
  Line 705 [new]: device = new(nothrow) KDiskDevice;
  Line 734 [new]: if (newlyCreated)
  Line 735 [new]: *newlyCreated = true;
  Line 762 [new]: KDiskDeviceManager::CreateFileDevice(const char* filePath, bool* newlyCreated)
  Line 778 [new]: if (newlyCreated)
  Line 779 [new]: *newlyCreated = false;
  Line 785 [new]: device = new(nothrow) KFileDiskDevice;
  Line 808 [new]: if (newlyCreated)
  Line 809 [new]: *newlyCreated = true;
  Line 1045 [new]: fDiskSystemWatcher = new(std::nothrow) DiskSystemWatcher(this);
  Line 1113 [new]: // rescan existing devices with the new disk systems
  Line 1141 [new]: KDiskSystem* diskSystem = new(nothrow) KPartitioningSystem(name);
  Line 1154 [new]: KDiskSystem* diskSystem = new(nothrow) KFileSystem(name);
  Line 1316 [new]: KDiskDevice* device = new(nothrow) KDiskDevice;
  Line 1347 [new]: // create a new job queue for the device
  Line 1348 [new]: KDiskDeviceJobQueue *jobQueue = new(nothrow) KDiskDeviceJobQueue;
  Line 1444 [new]: // new best disk system
  Line 198 [TODO]: // TODO: a real in-kernel DPC mechanism would be preferred...
  Line 285 [TODO]: // TODO: Watch the disk systems and the relevant directories.
  Line 443 [TODO]: // TODO: Optimize!
  Line 674 [TODO]: // TODO: This won't do. Locking the DDM while scanning the partition is not a
  Line 888 [TODO]: // TODO: If adding the partition to the obsolete list fails (due to lack
  Line 1340 [TODO]: // TODO: There's no reason why the manager needs to be locked anymore.
  Line 1344 [TODO]: // TODO: Reimplement asynchronous scanning, if we really need it.
  Line 1471 [TODO]: // TODO: Handle the error.
  Line 476 [dynamic_cast]: KFileDiskDevice* fileDevice = dynamic_cast<KFileDiskDevice*>(device);
  Line 842 [dynamic_cast]: if (!dynamic_cast<KFileDiskDevice*>(device) || id != device->ID())

File: src/system/kernel/disk_device_manager/KFileDiskDevice.cpp
  Line 66 [new]: // no device path: we shall create a new device entry
  Line 107 [TODO]: // TODO: Cleanup. The devfs will automatically remove the directory.

File: src/system/kernel/disk_device_manager/KPartition.cpp
  Line 265 [new]: char newNameBuffer[B_FILE_NAME_LENGTH];
  Line 266 [new]: status_t error = GetFileName(newNameBuffer, B_FILE_NAME_LENGTH);
  Line 272 [new]: if (strcmp(fPublishedName, newNameBuffer) == 0)
  Line 278 [new]: char* newName = strdup(newNameBuffer);
  Line 279 [new]: if (!newName) {
  Line 284 [new]: error = devfs_rename_partition(Device()->Path(), fPublishedName, newName);
  Line 287 [new]: free(newName);
  Line 295 [new]: fPublishedName = newName;
  Line 920 [new]: KPartition* child = new(std::nothrow) KPartition(id);
  Line 1042 [new]: // set and load new one
  Line 1134 [new]: fListeners = new(nothrow) ListenerSet;
  Line 1621 [TODO]: // TODO: handle this gracefully

File: src/system/kernel/disk_device_manager/KPartitioningSystem.cpp
  Line 274 [TODO]: // TODO: Change hook interface!
  Line 329 [TODO]: // TODO: Change hook interface!
  Line 357 [TODO]: // TODO: Change hook interface!

File: src/system/kernel/disk_device_manager/UserDataWriter.cpp
  Line 47 [new]: fRelocationEntries = new(std::nothrow) RelocationEntryList;

File: src/system/kernel/disk_device_manager/ddm_userland_interface.cpp
  Line 115 [malloc]: value = (char*)malloc(maxSize);
  Line 379 [malloc]: = static_cast<user_disk_device_data*>(malloc(neededSize));
  Line 734 [new]: partition_id childID, int32* childChangeCounter, off_t newOffset,
  Line 747 [new]: // check the new offset
  Line 748 [new]: if (newOffset == partition->Offset())
  Line 750 [new]: off_t proposedOffset = newOffset;
  Line 755 [new]: if (proposedOffset != newOffset)
  Line 757 [new]: // new offset is fine -- move the thing
  Line 758 [new]: off_t moveBy = newOffset - partition->Offset();
  Line 1147 [new]: // load the new disk system
  Line 1175 [new]: // higher priority than the new one. The old disk system will thus prevail.
  Line 1176 [new]: // Not setting the new disk system will at least prevent that the partition
  Line 71 [user_memcpy]: return user_memcpy(&value, userValue, sizeof(Type));
  Line 85 [user_memcpy]: return user_memcpy(userValue, &value, sizeof(Type));
  Line 397 [user_memcpy]: return user_memcpy(buffer, kernelBuffer, neededSize);
  Line 36 [TODO]: // TODO: Replace all instances, when it has been decided how to handle
  Line 457 [dynamic_cast]: = dynamic_cast<KFileDiskDevice*>(device);

File: src/system/kernel/disk_device_manager/disk_device_manager.cpp
  Line 333 [new]: // set the new interrupt properties only when not
  Line 202 [TODO]: // TODO: implemented

File: src/system/kernel/elf.cpp
  Line 272 [malloc]: = (struct elf_image_info *)malloc(sizeof(struct elf_image_info));
  Line 921 [malloc]: = (elf_version_info*)malloc(sizeof(elf_version_info) * (maxIndex + 1));
  Line 1191 [malloc]: elf_shdr *sectionHeaders = (elf_shdr *)malloc(size);
  Line 1218 [malloc]: symbolTable = (elf_sym *)malloc(size);
  Line 1245 [malloc]: stringTable = (char *)malloc(size = stringHeader->sh_size);
  Line 1329 [malloc]: image->debug_symbols = (elf_sym*)malloc(debugSymbolsSize);
  Line 1339 [malloc]: image->debug_string_table = (char*)malloc(
  Line 1966 [malloc]: elf_phdr *programHeaders = (elf_phdr *)malloc(
  Line 2259 [malloc]: elfHeader = (elf_ehdr *)malloc(sizeof(*elfHeader));
  Line 2289 [malloc]: programHeaders = (elf_phdr *)malloc(elfHeader->e_phnum
  Line 2603 [malloc]: elf_sym* symbolTable = (elf_sym*)malloc(0);
  Line 2604 [malloc]: char* stringTable = (char*)malloc(1);
  Line 647 [new]: // against a newer kernel.
  Line 1050 [new]: // before or the new symbol is not weak.
  Line 2862 [new]: sImagesHash = new(std::nothrow) ImageHash();
  Line 1576 [user_memcpy]: return user_memcpy(&data, address, sizeof(T)) == B_OK;
  Line 1854 [user_memcpy]: if (user_memcpy(&hashTabSize, &image->symhash[1], sizeof(uint32)) != B_OK)
  Line 1862 [user_memcpy]: if (user_memcpy(&i, &image->symhash[2 + hash], sizeof(uint32)) != B_OK)
  Line 1867 [user_memcpy]: if (user_memcpy(&symbol, &image->syms[i], sizeof(elf_sym)) != B_OK)
  Line 1888 [user_memcpy]: return user_memcpy(_value, (void*)address,
  Line 1896 [user_memcpy]: if (user_memcpy(&i, &image->symhash[2 + hashTabSize + i],
  Line 2745 [user_memcpy]: if (user_memcpy(&maxSymbolCount, _symbolCount, sizeof(maxSymbolCount))
  Line 2747 [user_memcpy]: || user_memcpy(&maxStringTableSize, _stringTableSize,
  Line 2809 [user_memcpy]: } else if (user_memcpy(symbolTable, symbols,
  Line 2821 [user_memcpy]: if (user_memcpy(stringTable, strings, stringsToCopy)
  Line 2835 [user_memcpy]: if (user_memcpy(_symbolCount, &symbolCount, sizeof(symbolCount)) != B_OK
  Line 2836 [user_memcpy]: || user_memcpy(_stringTableSize, &stringTableSize,
  Line 2838 [user_memcpy]: || (_imageDelta != NULL && user_memcpy(_imageDelta, &imageDelta,
  Line 2874 [panic]: panic("could not create kernel image.\n");
  Line 678 [TODO]: // TODO: Revise the default version case! That's how

File: src/system/kernel/events/Notifications.cpp
  Line 13 [new]: #include <new>
  Line 207 [new]: default_listener* listener = new(std::nothrow) default_listener;
  Line 403 [new]: = new(std::nothrow) UserMessagingListener(userListener);
  Line 448 [new]: default_listener* listener = new(std::nothrow) default_listener;
  Line 478 [new]: new(&sManager) NotificationManager;
  Line 616 [panic]: panic("Creating the notification manager failed: %s\n",
  Line 145 [dynamic_cast]: if (dynamic_cast<UserMessagingListener*>(listener) != NULL) {

File: src/system/kernel/events/event_queue.cpp
  Line 236 [new]: event = new(std::nothrow) select_event;
  Line 605 [new]: EventQueue* queue = new(std::nothrow) EventQueue(false);
  Line 620 [new]: int fd = new_fd(context, descriptor);
  Line 654 [user_memcpy]: if (user_memcpy(infos, userInfos, sizeof(event_wait_info) * numInfos) != B_OK)
  Line 670 [user_memcpy]: error = user_memcpy(&userInfos[i], &infos[i], sizeof(event_wait_info));
  Line 677 [user_memcpy]: user_memcpy(&userInfos[i].events, &error, sizeof(userInfos[i].events));
  Line 716 [user_memcpy]: status = user_memcpy(userInfos, infos, sizeof(event_wait_info) * numInfos);

File: src/system/kernel/events/wait_for_objects.cpp
  Line 10 [new]: #include <new>
  Line 339 [new]: #	define T(x)	new(std::nothrow) WaitForObjectsTracing::x
  Line 366 [new]: wait_for_objects_sync* sync = new(nothrow) wait_for_objects_sync;
  Line 371 [new]: sync->set = new(nothrow) select_info[numFDs];
  Line 483 [new]: // set new signal mask
  Line 597 [new]: // set new signal mask
  Line 788 [new]: entry = new (std::nothrow) select_sync_pool_entry;
  Line 811 [new]: pool = new (std::nothrow) select_sync_pool;
  Line 997 [user_memcpy]: if (user_memcpy(readSet, userReadSet, bytes) != B_OK)
  Line 1005 [user_memcpy]: if (user_memcpy(writeSet, userWriteSet, bytes) != B_OK)
  Line 1012 [user_memcpy]: if (user_memcpy(errorSet, userErrorSet, bytes) != B_OK)
  Line 1018 [user_memcpy]: && user_memcpy(&sigMask, userSigMask, sizeof(sigMask)) != B_OK) {
  Line 1029 [user_memcpy]: && user_memcpy(userReadSet, readSet, bytes) < B_OK)
  Line 1031 [user_memcpy]: && user_memcpy(userWriteSet, writeSet, bytes) < B_OK)
  Line 1033 [user_memcpy]: && user_memcpy(userErrorSet, errorSet, bytes) < B_OK))) {
  Line 1064 [user_memcpy]: if (user_memcpy(fds, userfds, bytes) < B_OK)
  Line 1071 [user_memcpy]: || user_memcpy(&sigMask, userSigMask, sizeof(sigMask)) < B_OK)) {
  Line 1079 [user_memcpy]: if (numFDs > 0 && user_memcpy(userfds, fds, bytes) != 0) {
  Line 1115 [user_memcpy]: if (user_memcpy(infos, userInfos, bytes) != B_OK)
  Line 1120 [user_memcpy]: if (result >= 0 && user_memcpy(userInfos, infos, bytes) != B_OK) {

File: src/system/kernel/fs/EntryCache.cpp
  Line 115 [malloc]: EntryCacheEntry* entry = (EntryCacheEntry*)malloc(sizeof(EntryCacheEntry) + nameLen);
  Line 9 [new]: #include <new>
  Line 39 [new]: entries = new(std::nothrow) EntryCacheEntry*[entries_size];
  Line 59 [new]: new(&fEntries) EntryTable;
  Line 98 [new]: fGenerations = new(std::nothrow) EntryCacheGeneration[fGenerationCount];
  Line 271 [new]: const int32 newGeneration = (fCurrentGeneration + 1) % fGenerationCount;
  Line 272 [new]: for (int32 i = 0; i < fGenerations[newGeneration].entries_size; i++) {
  Line 273 [new]: EntryCacheEntry* otherEntry = fGenerations[newGeneration].entries[i];
  Line 277 [new]: fGenerations[newGeneration].entries[i] = NULL;
  Line 284 [new]: // set the new generation and add the entry
  Line 285 [new]: fCurrentGeneration = newGeneration;
  Line 286 [new]: fGenerations[newGeneration].entries[0] = entry;
  Line 287 [new]: fGenerations[newGeneration].next_index = 1;
  Line 288 [new]: entry->generation = newGeneration;
  Line 91 [TODO]: // TODO: Choose generation size/count more scientifically?
  Line 92 [TODO]: // TODO: Add low_resource handler hook?

File: src/system/kernel/fs/KPath.cpp
  Line 254 [malloc]: buffer = (char*)malloc(fBufferSize);
  Line 436 [malloc]: fBuffer = (char*)malloc(fBufferSize);
  Line 286 [new]: KPath::ReplaceLeaf(const char* newLeaf)
  Line 301 [new]: if (newLeaf != NULL)
  Line 302 [new]: return Append(newLeaf);
  Line 227 [panic]: panic("KPath::UnlockBuffer(): Buffer not locked!");

File: src/system/kernel/fs/Vnode.cpp
  Line 25 [new]: new(&sBuckets[i]) Bucket;

File: src/system/kernel/fs/fd.cpp
  Line 1007 [malloc]: struct dirent* buffer = (struct dirent*)malloc(bufferSize);
  Line 74 [new]: /*! Allocates and initializes a new file_descriptor.
  Line 141 [new]: new_fd_etc(struct io_context* context, struct file_descriptor* descriptor,
  Line 172 [new]: new_fd(struct io_context* context, struct file_descriptor* descriptor)
  Line 174 [new]: return new_fd_etc(context, descriptor, 0);
  Line 378 [new]: status = new_fd(context, descriptor);
  Line 392 [new]: close(newfd);
  Line 393 [new]: fcntl(oldfd, F_DUPFD, newfd);
  Line 398 [new]: dup2_fd(int oldfd, int newfd, int flags, bool kernel)
  Line 403 [new]: TRACE(("dup2_fd: ofd = %d, nfd = %d\n", oldfd, newfd));
  Line 406 [new]: if (oldfd < 0 || newfd < 0)
  Line 418 [new]: || (uint32)newfd >= context->table_size
  Line 427 [new]: if (oldfd != newfd) {
  Line 429 [new]: TFD(Dup2FD(context, oldfd, newfd));
  Line 431 [new]: evicted = context->fds[newfd];
  Line 432 [new]: select_info* selectInfos = context->select_infos[newfd];
  Line 433 [new]: context->select_infos[newfd] = NULL;
  Line 436 [new]: context->fds[newfd] = context->fds[oldfd];
  Line 444 [new]: fd_set_close_on_exec(context, newfd, (flags & O_CLOEXEC) != 0);
  Line 445 [new]: fd_set_close_on_fork(context, newfd, (flags & O_CLOFORK) != 0);
  Line 455 [new]: return newfd;
  Line 462 [new]: \param kernel If \c true, the new FD will be created in the kernel team,
  Line 464 [new]: \return The newly created FD or an error code, if something went wrong.
  Line 483 [new]: // create a new FD in the target I/O context
  Line 484 [new]: int result = new_fd(get_current_io_context(kernel), descriptor);
  Line 839 [new]: off_t newPos;
  Line 841 [new]: newPos = descriptor->ops->fd_seek(descriptor.Get(), 0, SEEK_END);
  Line 845 [new]: newPos = pos + length;
  Line 847 [new]: descriptor->pos = newPos;
  Line 509 [user_memcpy]: || user_memcpy(&value, buffer, sizeof(int)) != B_OK) {
  Line 1032 [user_memcpy]: if (user_memcpy(userBuffer, buffer, sizeToCopy) != B_OK)
  Line 15 [ioctl]: #include <sys/ioctl.h>
  Line 495 [ioctl]: fd_ioctl(bool kernelFD, int fd, uint32 op, void* buffer, size_t length)
  Line 522 [ioctl]: if (descriptor->ops->fd_ioctl)
  Line 523 [ioctl]: status = descriptor->ops->fd_ioctl(descriptor.Get(), op, buffer, length);
  Line 905 [ioctl]: user_fd_kernel_ioctl(int fd, uint32 op, void* buffer, size_t length)
  Line 907 [ioctl]: TRACE(("user_fd_kernel_ioctl: fd %d\n", fd));
  Line 909 [ioctl]: return fd_ioctl(false, fd, op, buffer, length);
  Line 965 [ioctl]: _user_ioctl(int fd, uint32 op, void* buffer, size_t length)
  Line 967 [ioctl]: TRACE(("user_ioctl: fd %d\n", fd));
  Line 978 [ioctl]: return status = fd_ioctl(false, fd, op, buffer, length);
  Line 1204 [ioctl]: _kern_ioctl(int fd, uint32 op, void* buffer, size_t length)
  Line 1206 [ioctl]: TRACE(("kern_ioctl: fd %d\n", fd));
  Line 1210 [ioctl]: return fd_ioctl(true, fd, op, buffer, length);

File: src/system/kernel/fs/fifo.cpp
  Line 1082 [malloc]: file_cookie* cookie = (file_cookie*)malloc(sizeof(file_cookie));
  Line 18 [new]: #include <new>
  Line 1489 [new]: FIFOInode* fifo = new(std::nothrow) FIFOInode(vnode);
  Line 339 [user_memcpy]: if (user_memcpy(fBuffer + position, data, length) != B_OK)
  Line 349 [user_memcpy]: if (user_memcpy(fBuffer + position, data, upper) != B_OK
  Line 350 [user_memcpy]: || user_memcpy(fBuffer, (uint8*)data + upper, lower) != B_OK)
  Line 412 [user_memcpy]: if (user_memcpy(data, fBuffer + readHead, length) != B_OK)
  Line 422 [user_memcpy]: if (user_memcpy(data, fBuffer + readHead, upper) != B_OK
  Line 423 [user_memcpy]: || user_memcpy((uint8*)data + upper, fBuffer, lower) != B_OK)
  Line 1289 [user_memcpy]: || user_memcpy(buffer, &available, sizeof(available))
  Line 15 [ioctl]: #include <sys/ioctl.h>
  Line 1266 [ioctl]: fifo_ioctl(fs_volume* _volume, fs_vnode* _node, void* _cookie, uint32 op,
  Line 1272 [ioctl]: TRACE("fifo_ioctl: vnode %p, cookie %p, op %" B_PRId32 ", buf %p, len %ld\n",
  Line 1417 [ioctl]: &fifo_ioctl,
  Line 876 [TODO]: // TODO: This only works reliable if there is only one writer - we could
  Line 1224 [TODO]: // TODO: Just pass the changes to our modification time on to the super node.
  Line 1401 [TODO]: // TODO: This is suboptimal! We'd need to forward the

File: src/system/kernel/fs/node_monitor.cpp
  Line 364 [new]: // create new monitor
  Line 365 [new]: monitor = new(std::nothrow) node_monitor;
  Line 413 [new]: monitor_listener *listener = new(std::nothrow) monitor_listener;
  Line 876 [new]: message.AddInt32("new device", device);
  Line 1026 [new]: UserNodeListener* copiedListener = new(std::nothrow) UserNodeListener(
  Line 1131 [new]: new(&sNodeMonitorSender) UserMessagingMessageSender();
  Line 1132 [new]: new(&sNodeMonitorService) NodeMonitorService();
  Line 1216 [new]: \param toDirectory The entry's new parent directory ID.
  Line 1217 [new]: \param toName The entry's new name.
  Line 1319 [new]: \param toDirectory The new parent directory ID.
  Line 1321 [new]: \param toName The entry's new name.
  Line 1135 [panic]: panic("initializing node monitor failed\n");
  Line 1361 [TODO]: // TODO: We should verify that the port specified in the syscalls does actually

File: src/system/kernel/fs/rootfs.cpp
  Line 174 [malloc]: vnode = (rootfs_vnode*)malloc(sizeof(struct rootfs_vnode));
  Line 391 [malloc]: fs = (rootfs*)malloc(sizeof(struct rootfs));
  Line 726 [malloc]: cookie = (rootfs_dir_cookie*)malloc(sizeof(struct rootfs_dir_cookie));
  Line 271 [new]: // the new vnode is the first entry in the list
  Line 403 [new]: fs->vnode_list_hash = new(std::nothrow) VnodeTable();
  Line 590 [new]: int perms, void** _cookie, ino_t* _newID)
  Line 678 [new]: TRACE(("rootfs_create: creating new vnode\n"));
  Line 924 [new]: TRACE(("rootfs_create: creating new symlink\n"));
  Line 1039 [new]: // Add it back to the dir with the new name.
  Line 853 [ioctl]: rootfs_ioctl(fs_volume* _volume, fs_vnode* _v, void* _cookie, uint32 op,
  Line 856 [ioctl]: TRACE(("rootfs_ioctl: vnode %p, cookie %p, op %d, buf %p, length %d\n",
  Line 1249 [ioctl]: &rootfs_ioctl,
  Line 575 [panic]: panic("rootfs_remove_vnode: vnode %p asked to be removed is present in "
  Line 979 [TODO]: // TODO: This should be solved differently. Either root should still be

File: src/system/kernel/fs/socket.cpp
  Line 203 [malloc]: iovec* vecs = (iovec*)malloc(sizeof(iovec) * message.msg_iovlen);
  Line 1058 [malloc]: message.msg_control = ancillary = malloc(message.msg_controllen);
  Line 1155 [malloc]: message.msg_control = malloc(message.msg_controllen);
  Line 426 [new]: int fd = new_fd(context, descriptor);
  Line 547 [new]: // we need a reference for the new FD
  Line 118 [user_memcpy]: || user_memcpy(address, userAddress, addressLength) != B_OK) {
  Line 152 [user_memcpy]: && user_memcpy(&addressLength, _addressLength, sizeof(socklen_t))
  Line 170 [user_memcpy]: if (user_memcpy(userAddressLength, &addressLength,
  Line 173 [user_memcpy]: && (!IS_USER_ADDRESS(userAddress) || user_memcpy(userAddress, address,
  Line 192 [user_memcpy]: || user_memcpy(&message, userMessage, sizeof(msghdr)) != B_OK) {
  Line 1076 [user_memcpy]: if ((userAddress != NULL && user_memcpy(userAddress, address,
  Line 1078 [user_memcpy]: || (userAncillary != NULL && user_memcpy(userAncillary, ancillary,
  Line 1080 [user_memcpy]: || user_memcpy(userMessage, &message, sizeof(msghdr)) != B_OK) {
  Line 1140 [user_memcpy]: && user_memcpy(address, userAddress, message.msg_namelen) != B_OK) {
  Line 1160 [user_memcpy]: if (user_memcpy(message.msg_control, userAncillary,
  Line 1184 [user_memcpy]: if (user_memcpy(&length, _length, sizeof(socklen_t)) != B_OK)
  Line 1199 [user_memcpy]: if (user_memcpy(userValue, value, length) != B_OK)
  Line 1217 [user_memcpy]: || user_memcpy(value, userValue, length) != B_OK) {
  Line 1313 [user_memcpy]: if (user_memcpy(userSocketVector, socketVector,
  Line 1333 [user_memcpy]: || user_memcpy(&cookie, _cookie, sizeof(cookie)) != B_OK) {
  Line 1344 [user_memcpy]: if (user_memcpy(_cookie, &cookie, sizeof(cookie)) != B_OK
  Line 1345 [user_memcpy]: || user_memcpy(_stat, &stat, sizeof(net_stat)) != B_OK) {
  Line 281 [ioctl]: socket_ioctl(struct file_descriptor *descriptor, ulong op, void *buffer,
  Line 284 [ioctl]: return sStackInterface->ioctl(FD_SOCKET(descriptor), op, buffer, length);
  Line 295 [ioctl]: return sStackInterface->ioctl(FD_SOCKET(descriptor), op, NULL, 0);
  Line 365 [ioctl]: &socket_ioctl,

File: src/system/kernel/fs/vfs.cpp
  Line 808 [malloc]: char* name = (char*)malloc(end + 1 - fsName);
  Line 837 [malloc]: char* result = (char*)malloc(length);
  Line 3227 [malloc]: void* buffer = debug_malloc(B_PATH_NAME_LENGTH);
  Line 5051 [malloc]: io_context* context = (io_context*)malloc(sizeof(io_context));
  Line 5177 [malloc]: file_descriptor** newFDs = (file_descriptor**)malloc(
  Line 5179 [malloc]: select_info** newSelectInfos = (select_info**)malloc(
  Line 5181 [malloc]: uint8* newCloseOnExecTable = (uint8*)malloc(newCloseOnExitBitmapSize);
  Line 5182 [malloc]: uint8* newCloseOnForkTable = (uint8*)malloc(newCloseOnExitBitmapSize);
  Line 7736 [malloc]: volume = (fs_volume*)malloc(sizeof(fs_volume));
  Line 9114 [malloc]: args = (char*)malloc(argsLength + 1);
  Line 708 [new]: #	define TPIO(x) new(std::nothrow) VFSPagesIOTracing::x;
  Line 911 [new]: /*!	Creates a new vnode with the given mount and node ID.
  Line 912 [new]: If the node already exists, it is returned instead and no new node is
  Line 919 [new]: \param _vnode Will be set to the new vnode on success.
  Line 921 [new]: been newly created, \c false when it already existed. Will not be
  Line 928 [new]: create_new_vnode_and_lock(dev_t mountID, ino_t vnodeID, struct vnode*& _vnode,
  Line 931 [new]: FUNCTION(("create_new_vnode_and_lock()\n"));
  Line 1021 [new]: // a new cache attached!
  Line 1220 [new]: // we need to create a new vnode and read it in
  Line 1222 [new]: // unlock -- create_new_vnode_and_lock() write-locks on success
  Line 1224 [new]: status_t status = create_new_vnode_and_lock(mountID, vnodeID, vnode,
  Line 1562 [new]: locking = new(std::nothrow) advisory_locking;
  Line 1576 [new]: // set our newly created locking object
  Line 1678 [new]: LockList newLocks;
  Line 1680 [new]: struct advisory_lock* lock = new(std::nothrow) advisory_lock;
  Line 1682 [new]: while ((lock = newLocks.RemoveHead()) != NULL)
  Line 1687 [new]: newLocks.Add(lock);
  Line 1719 [new]: struct advisory_lock* secondLock = newLocks.RemoveHead();
  Line 1745 [new]: // free unused new locks
  Line 1747 [new]: while ((lock = newLocks.RemoveHead()) != NULL)
  Line 1857 [new]: // install new lock
  Line 1859 [new]: struct advisory_lock* lock = new(std::nothrow) advisory_lock;
  Line 1956 [new]: // If we've replaced the node, grab a reference for the new one.
  Line 2280 [new]: // If the new node is a symbolic link, resolve it (if we've been told to)
  Line 2895 [new]: get_new_fd(struct fd_ops* ops, struct fs_mount* mount, struct vnode* vnode,
  Line 2901 [new]: // If the vnode is locked, we don't allow creating a new file/directory
  Line 2937 [new]: fd = new_fd(context, descriptor);
  Line 3717 [new]: resize_monitor_table(struct io_context* context, const int newSize)
  Line 3719 [new]: if (newSize <= 0 || newSize > MAX_NODE_MONITORS)
  Line 3724 [new]: if ((size_t)newSize < context->num_monitors)
  Line 3727 [new]: context->max_monitors = newSize;
  Line 3736 [new]: new_vnode(fs_volume* volume, ino_t vnodeID, void* privateNode,
  Line 3739 [new]: FUNCTION(("new_vnode(volume = %p (%" B_PRId32 "), vnodeID = %" B_PRId64
  Line 3750 [new]: status_t status = create_new_vnode_and_lock(volume->id, vnodeID, vnode,
  Line 3756 [new]: // create_new_vnode_and_lock() has locked for us
  Line 3803 [new]: // create_new_vnode_and_lock() will re-lock for us on success
  Line 3804 [new]: status_t status = create_new_vnode_and_lock(volume->id, vnodeID, vnode,
  Line 4373 [new]: Calls fs_open() on the given vnode and returns a new
  Line 4618 [new]: The caller gets a reference to the newly created node (which is passed
  Line 4636 [new]: pointer to the newly created node.
  Line 5045 [new]: /*! Sets up a new io_control structure, and inherits the properties
  Line 5049 [new]: vfs_new_io_context(const io_context* parentContext, bool purgeCloseOnExec)
  Line 5149 [new]: vfs_resize_fd_table(struct io_context* context, uint32 newSize)
  Line 5151 [new]: if (newSize == 0 || newSize > MAX_FD_TABLE_SIZE)
  Line 5154 [new]: TIOC(ResizeIOContext(context, newSize));
  Line 5160 [new]: int newCloseOnExitBitmapSize = (newSize + 7) / 8;
  Line 5163 [new]: if (newSize < oldSize) {
  Line 5164 [new]: for (uint32 i = oldSize; i-- > newSize;) {
  Line 5176 [new]: // allocate new tables (separately to reduce the chances of needing a raw allocation)
  Line 5177 [new]: file_descriptor** newFDs = (file_descriptor**)malloc(
  Line 5178 [new]: sizeof(struct file_descriptor*) * newSize);
  Line 5179 [new]: select_info** newSelectInfos = (select_info**)malloc(
  Line 5180 [new]: + sizeof(select_info**) * newSize);
  Line 5181 [new]: uint8* newCloseOnExecTable = (uint8*)malloc(newCloseOnExitBitmapSize);
  Line 5182 [new]: uint8* newCloseOnForkTable = (uint8*)malloc(newCloseOnExitBitmapSize);
  Line 5183 [new]: if (newFDs == NULL || newSelectInfos == NULL || newCloseOnExecTable == NULL
  Line 5184 [new]: || newCloseOnForkTable == NULL) {
  Line 5185 [new]: free(newFDs);
  Line 5186 [new]: free(newSelectInfos);
  Line 5187 [new]: free(newCloseOnExecTable);
  Line 5188 [new]: free(newCloseOnForkTable);
  Line 5192 [new]: context->fds = newFDs;
  Line 5193 [new]: context->select_infos = newSelectInfos;
  Line 5194 [new]: context->fds_close_on_exec = newCloseOnExecTable;
  Line 5195 [new]: context->fds_close_on_fork = newCloseOnForkTable;
  Line 5196 [new]: context->table_size = newSize;
  Line 5200 [new]: uint32 toCopy = min_c(oldSize, newSize);
  Line 5205 [new]: min_c(oldCloseOnExitBitmapSize, newCloseOnExitBitmapSize));
  Line 5207 [new]: min_c(oldCloseOnExitBitmapSize, newCloseOnExitBitmapSize));
  Line 5211 [new]: if (newSize > oldSize) {
  Line 5212 [new]: memset(context->fds + oldSize, 0, sizeof(void*) * (newSize - oldSize));
  Line 5214 [new]: sizeof(void*) * (newSize - oldSize));
  Line 5216 [new]: newCloseOnExitBitmapSize - oldCloseOnExitBitmapSize);
  Line 5218 [new]: newCloseOnExitBitmapSize - oldCloseOnExitBitmapSize);
  Line 5414 [new]: sVnodeTable = new(std::nothrow) VnodeTable();
  Line 5418 [new]: sMountsTable = new(std::nothrow) MountTable();
  Line 5504 [new]: Calls fs_open() on the given vnode and returns a new
  Line 5519 [new]: int fd = get_new_fd(&sFileOps, NULL, vnode, cookie, openMode, kernel);
  Line 5529 [new]: Creates a new regular file and returns a new file descriptor for it.
  Line 5542 [new]: ino_t newID;
  Line 5614 [new]: &cookie, &newID);
  Line 5625 [new]: vnode.SetTo(lookup_vnode(directory->device, newID));
  Line 5634 [new]: int fd = get_new_fd(&sFileOps, NULL, vnode.Get(), cookie, openMode, kernel);
  Line 5653 [new]: /*! Calls fs open_dir() on the given vnode and returns a new
  Line 5668 [new]: status = get_new_fd(&sDirectoryOps, NULL, vnode, cookie, O_CLOEXEC, kernel);
  Line 5679 [new]: /*! Calls fs open_attr_dir() on the given vnode and returns a new
  Line 5695 [new]: status = get_new_fd(&sAttributeDirectoryOps, NULL, vnode, cookie, O_CLOEXEC,
  Line 5714 [new]: // get directory to put the new file in
  Line 5733 [new]: // get directory to put the new file in
  Line 5764 [new]: int newFD = open_vnode(vnode.Get(), openMode, kernel);
  Line 5765 [new]: if (newFD >= 0) {
  Line 5773 [new]: return newFD;
  Line 5794 [new]: int newFD = open_vnode(vnode.Get(), openMode, kernel);
  Line 5795 [new]: if (newFD >= 0) {
  Line 5803 [new]: return newFD;
  Line 6165 [new]: int newFD = open_dir_vnode(vnode.Get(), kernel);
  Line 6166 [new]: if (newFD >= 0) {
  Line 6174 [new]: return newFD;
  Line 6193 [new]: int newFD = open_dir_vnode(vnode.Get(), kernel);
  Line 6194 [new]: if (newFD >= 0) {
  Line 6202 [new]: return newFD;
  Line 6461 [new]: status = new_fd_etc(context, descriptor.Get(), (int)argument);
  Line 6806 [new]: common_rename(int fd, char* path, int newFD, char* newPath, bool kernel)
  Line 6810 [new]: FUNCTION(("common_rename(fd = %d, path = %s, newFD = %d, newPath = %s, "
  Line 6811 [new]: "kernel = %d)\n", fd, path, newFD, newPath, kernel));
  Line 6821 [new]: status = fd_and_path_to_dir_vnode(newFD, newPath, toVnode, toName, kernel);
  Line 7032 [new]: fd = get_new_fd(&sAttributeOps, NULL, vnode.Get(), cookie, openMode, kernel);
  Line 7075 [new]: fd = get_new_fd(&sAttributeOps, NULL, vnode.Get(), cookie, openMode, kernel);
  Line 7303 [new]: fd = get_new_fd(&sIndexDirectoryOps, mount, NULL, cookie, O_CLOEXEC, kernel);
  Line 7506 [new]: fd = get_new_fd(&sQueryOps, mount, NULL, cookie, O_CLOEXEC, kernel);
  Line 7603 [new]: // Helper to delete a newly created file device on failure.
  Line 7621 [new]: bool newlyCreatedFileDevice = false;
  Line 7636 [new]: normalizedDevice.Path(), &newlyCreatedFileDevice);
  Line 7639 [new]: if (newlyCreatedFileDevice)
  Line 7703 [new]: mount = new(std::nothrow) (struct ::fs_mount);
  Line 7886 [new]: mount->owns_file_device = newlyCreatedFileDevice;
  Line 8056 [new]: // prevent new vnodes from being created
  Line 8577 [new]: \return A FD referring to the newly opened node, or an error code,
  Line 8609 [new]: \return The FD of the newly opened directory or an error code, if
  Line 8629 [new]: \return A FD referring to the newly opened directory, or an error code,
  Line 8688 [new]: \a path must always be specified (it contains the name of the new directory
  Line 8696 [new]: \param perms The access permissions the new directory shall have.
  Line 8754 [new]: \a path must always be specified (it contains the name of the new symlink
  Line 8762 [new]: \param mode The access permissions the new symlink shall have.
  Line 8819 [new]: \a oldPath and \a newPath must always be specified (they contain at least
  Line 8828 [new]: \param newFD The FD of the new location. May be < 0.
  Line 8829 [new]: \param newPath The absolute or relative path of the new location. Must not
  Line 8835 [new]: _kern_rename(int oldFD, const char* oldPath, int newFD, const char* newPath)
  Line 8838 [new]: KPath newPathBuffer(newPath);
  Line 8839 [new]: if (oldPathBuffer.InitCheck() != B_OK || newPathBuffer.InitCheck() != B_OK)
  Line 8843 [new]: newFD, newPathBuffer.LockBuffer(), true);
  Line 9649 [new]: size_t newBufferSize = bufferSize;
  Line 9651 [new]: &newBufferSize, false);
  Line 9655 [new]: if (user_memcpy(userBufferSize, &newBufferSize, sizeof(size_t)) != B_OK)
  Line 9661 [new]: bufferSize = min_c(newBufferSize, bufferSize);
  Line 9744 [new]: _user_rename(int oldFD, const char* userOldPath, int newFD,
  Line 9748 [new]: KPath newPathBuffer;
  Line 9749 [new]: if (oldPathBuffer.InitCheck() != B_OK || newPathBuffer.InitCheck() != B_OK)
  Line 9753 [new]: char* newPath = newPathBuffer.LockBuffer();
  Line 9760 [new]: status = user_copy_name(newPath, userNewPath, B_PATH_NAME_LENGTH);
  Line 9764 [new]: return common_rename(oldFD, oldPath, newFD, newPath, false);
  Line 10333 [new]: // set the new root
  Line 6395 [user_memcpy]: else if (user_memcpy(&flock, (struct flock*)argument,
  Line 6498 [user_memcpy]: status = user_memcpy((struct flock*)argument,
  Line 6511 [user_memcpy]: status = user_memcpy((struct flock*)argument,
  Line 9170 [user_memcpy]: if (user_memcpy(userInfo, &info, sizeof(struct fs_info)) != B_OK)
  Line 9186 [user_memcpy]: || user_memcpy(&info, userInfo, sizeof(struct fs_info)) != B_OK)
  Line 9200 [user_memcpy]: || user_memcpy(&cookie, _userCookie, sizeof(int32)) != B_OK)
  Line 9207 [user_memcpy]: if (user_memcpy(_userCookie, &cookie, sizeof(int32)) != B_OK)
  Line 9237 [user_memcpy]: || user_memcpy(&cookie, userCookie, sizeof(uint32)) != B_OK)
  Line 9244 [user_memcpy]: if (user_memcpy(userCookie, &cookie, sizeof(uint32)) != B_OK
  Line 9245 [user_memcpy]: || user_memcpy(userInfo, &info, infoSize) != B_OK)
  Line 9632 [user_memcpy]: || user_memcpy(&bufferSize, userBufferSize, sizeof(size_t)) != B_OK)
  Line 9655 [user_memcpy]: if (user_memcpy(userBufferSize, &newBufferSize, sizeof(size_t)) != B_OK)
  Line 9662 [user_memcpy]: if (user_memcpy(userBuffer, buffer, bufferSize) != B_OK)
  Line 9854 [user_memcpy]: || user_memcpy(userFDs, fds, sizeof(fds)) != B_OK) {
  Line 9933 [user_memcpy]: return user_memcpy(userStat, &stat, statSize);
  Line 9947 [user_memcpy]: || user_memcpy(&stat, userStat, statSize) < B_OK)
  Line 10105 [user_memcpy]: if (user_memcpy(userAttrInfo, &info, sizeof(struct attr_info)) != B_OK)
  Line 10228 [user_memcpy]: if (user_memcpy(userStat, &stat, sizeof(stat)) != B_OK)
  Line 21 [ioctl]: #include <sys/ioctl.h>
  Line 414 [ioctl]: static status_t common_ioctl(struct file_descriptor* descriptor, ulong op,
  Line 448 [ioctl]: common_ioctl,
  Line 464 [ioctl]: common_ioctl,
  Line 480 [ioctl]: common_ioctl,
  Line 498 [ioctl]: common_ioctl,
  Line 514 [ioctl]: NULL,		// ioctl()
  Line 531 [ioctl]: NULL,		// ioctl()
  Line 548 [ioctl]: NULL,		// ioctl()
  Line 5983 [ioctl]: if (HAS_FS_CALL(vnode, ioctl)) {
  Line 5984 [ioctl]: status = FS_CALL(vnode, ioctl, descriptor->cookie,
  Line 6000 [ioctl]: if (HAS_FS_CALL(vnode, ioctl)) {
  Line 6002 [ioctl]: status = FS_CALL(vnode, ioctl, descriptor->cookie,
  Line 6360 [ioctl]: common_ioctl(struct file_descriptor* descriptor, ulong op, void* buffer,
  Line 6365 [ioctl]: if (HAS_FS_CALL(vnode, ioctl))
  Line 6366 [ioctl]: return FS_CALL(vnode, ioctl, descriptor->cookie, op, buffer, length);
  Line 8246 [ioctl]: ioctl(mount->partition->Device()->FD(), B_FLUSH_DRIVE_CACHE);
  Line 92 [panic]: : (panic("FS_CALL: vnode %p op " #op " is NULL", vnode), 0))
  Line 96 [panic]: : (panic("FS_CALL_NO_PARAMS: vnode %p op " #op " is NULL", vnode), 0))
  Line 100 [panic]: : (panic("FS_MOUNT_CALL: mount %p op " #op " is NULL", mount), 0))
  Line 104 [panic]: : (panic("FS_MOUNT_CALL_NO_PARAMS: mount %p op " #op " is NULL", mount), 0))
  Line 1073 [panic]: panic("dec_vnode_ref_count: called on busy vnode %p\n", vnode);
  Line 1242 [panic]: KDEBUG_ONLY(panic("filesystem get_vnode returned 0 with unset fields"));
  Line 2167 [panic]: panic("lookup_dir_entry(): could not lookup vnode (mountid 0x%" B_PRIx32
  Line 3643 [panic]: panic("sparse write attempt: vnode %p", vnode);
  Line 3768 [panic]: panic("vnode %" B_PRIdDEV ":%" B_PRIdINO " already exists (node = %p, "
  Line 3902 [panic]: panic("get_vnode(): Failed to get super node for vnode %p, "
  Line 3924 [panic]: KDEBUG_ONLY(panic("acquire_vnode(%p, %" B_PRIdINO "): not found!", volume, vnodeID));
  Line 3931 [panic]: panic("acquire_vnode(%p, %" B_PRIdINO "): node wasn't used!", volume, vnodeID);
  Line 3948 [panic]: KDEBUG_ONLY(panic("put_vnode(%p, %" B_PRIdINO "): not found!", volume, vnodeID));
  Line 4687 [panic]: panic("vfs_create_special_node(): lookup of node failed");
  Line 5416 [panic]: panic("vfs_init: error creating vnode hash table\n");
  Line 5421 [panic]: panic("vfs_init: error creating mounts hash table\n");
  Line 5426 [panic]: panic("vfs_init: error creating path name object_cache\n");
  Line 5432 [panic]: panic("vfs_init: error creating vnode object_cache\n");
  Line 5437 [panic]: panic("vfs_init: error creating file descriptor object_cache\n");
  Line 5629 [panic]: panic("vfs: fs_create() returned success but there is no vnode, "
  Line 7825 [panic]: panic("fs_mount: mount() succeeded but ops is NULL!");
  Line 7847 [panic]: panic("fs_mount: file system does not own its root node!\n");
  Line 7957 [panic]: panic("fs_unmount: find_mount() failed on root vnode @%p of mount\n",
  Line 1805 [TODO]: // TODO: deadlock detection is complex and currently deferred.
  Line 1826 [TODO]: // TODO: locks from the same team might be joinable!
  Line 1979 [TODO]: TODO: there is currently no means to stop a blocking read/write!
  Line 3542 [TODO]: // TODO: we could also write directly
  Line 4839 [TODO]: // TODO: actually the vnode needs to be busy already here, or
  Line 6858 [TODO]: // TODO: remove this once all file systems properly set them!
  Line 7475 [TODO]: /*!	TODO: the query FS API is still the pretty much the same as in R5.
  Line 7658 [TODO]: // TODO: Just mark the partition busy while mounting!
  Line 8046 [TODO]: // TODO: if there is some kind of bug that prevents the ref counts
  Line 8207 [TODO]: // TODO: we could track writes (and writable mapped vnodes)

File: src/system/kernel/fs/vfs_boot.cpp
  Line 343 [new]: bootMethod = new(nothrow) NetBootMethod(bootVolume, bootMethodType);
  Line 349 [new]: bootMethod = new(nothrow) DiskBootMethod(bootVolume,
  Line 444 [panic]: panic("error mounting rootfs!\n");
  Line 452 [panic]: panic("error mounting devfs\n");
  Line 478 [panic]: panic("get_boot_partitions failed!");
  Line 481 [panic]: panic("did not find any boot partitions! @! syslog | tail 15");
  Line 490 [panic]: panic("could not get boot device!\n");
  Line 514 [panic]: panic("could not mount boot device!\n");
  Line 545 [panic]: panic("Failed to mount system packagefs: %s",
  Line 209 [TODO]: // TODO: implement this! (and then enable this feature in the boot
  Line 250 [TODO]: // TODO: implement me!

File: src/system/kernel/fs/vfs_net_boot.cpp
  Line 159 [ioctl]: if (ioctl(fSocket, SIOCGIFINDEX, &request, sizeof(request)) < 0) {
  Line 170 [ioctl]: if (ioctl(fSocket, SIOCAIFADDR, &aliasRequest,
  Line 179 [ioctl]: if (ioctl(fSocket, SIOCGIFFLAGS, &request, sizeof(request)) < 0) {
  Line 189 [ioctl]: if (ioctl(fSocket, SIOCSIFFLAGS, &request, sizeof(request)) < 0) {
  Line 197 [ioctl]: if (ioctl(fLinkSocket, SIOCGIFADDR, &request, sizeof(request)) < 0) {
  Line 237 [ioctl]: if (ioctl(fSocket, SIOCSIFADDR, &request, sizeof(request)) < 0) {
  Line 245 [ioctl]: if (ioctl(fSocket, SIOCSIFNETMASK, &request, sizeof(request)) < 0) {
  Line 253 [ioctl]: if (ioctl(fSocket, SIOCSIFBRDADDR, &request, sizeof(request)) < 0) {
  Line 263 [ioctl]: if (ioctl(fSocket, SIOCSIFFLAGS, &request, sizeof(request)) < 0) {
  Line 276 [ioctl]: ioctl(fSocket, SIOCDELRT, &request, sizeof(request));
  Line 277 [ioctl]: if (ioctl(fSocket, SIOCADDRT, &request, sizeof(request)) < 0) {
  Line 325 [panic]: panic("no client MAC or IP address or net mask\n");
  Line 349 [TODO]: // TODO: "net root path" should be used for finding the boot device/FS,

File: src/system/kernel/fs/vfs_request_io.cpp
  Line 529 [malloc]: ? new(malloc_flags(HEAP_PRIORITY_VIP)) iterative_io_cookie
  Line 529 [new]: ? new(malloc_flags(HEAP_PRIORITY_VIP)) iterative_io_cookie
  Line 530 [new]: : new(std::nothrow) iterative_io_cookie;
  Line 189 [panic]: panic("do_iterative_fd_io_iterate(): write to sparse file "
  Line 259 [TODO]: // TODO: Cancel the subrequests that were scheduled successfully.

File: src/system/kernel/fs/vfs_tracing.h
  Line 53 [new]: out.Print("fd new:     descriptor: %p (%" B_PRId32 "), context: %p, "
  Line 128 [new]: Dup2FD(io_context* context, int oldFD, int newFD)
  Line 132 [new]: fEvictedDescriptor(context->fds[newFD]),
  Line 136 [new]: fNewFD(newFD)
  Line 187 [new]: #	define TFD(x)	new(std::nothrow) FileDescriptorTracing::x
  Line 242 [new]: out.Print("iocontext new:    context: %p, parent: %p", fContext,
  Line 269 [new]: ResizeIOContext(io_context* context, uint32 newTableSize)
  Line 273 [new]: fNewTableSize(newTableSize)
  Line 292 [new]: #	define TIOC(x)	new(std::nothrow) IOContextTracing::x

File: src/system/kernel/heap.cpp
  Line 1164 [malloc]: heap = (heap_allocator *)malloc(sizeof(heap_allocator)
  Line 1866 [malloc]: // new leak check info will be created with the malloc below
  Line 1871 [malloc]: *newAddress = malloc_etc(newSize, flags);
  Line 2354 [malloc]: malloc(size_t size)
  Line 2417 [malloc]: return malloc_etc(newSize, flags);
  Line 2462 [malloc]: newAddress = malloc(newSize);
  Line 2499 [malloc]: void *address = malloc(numElements * size);
  Line 236 [new]: Reallocate(addr_t oldAddress, addr_t newAddress, size_t newSize)
  Line 238 [new]: fNewAddress(newAddress),
  Line 239 [new]: fNewSize(newSize)
  Line 277 [new]: #	define T(x)	if (!gKernelStartup) new(std::nothrow) KernelHeapTracing::x;
  Line 668 [new]: // not found, add a new entry, if there are free slots
  Line 1545 [new]: // check if there is an aligned block in the free list or if a new
  Line 1779 [new]: heap_realloc(heap_allocator *heap, void *address, void **newAddress,
  Line 1780 [new]: size_t newSize, uint32 flags)
  Line 1808 [new]: TRACE(("realloc(address = %p, newSize = %lu)\n", address, newSize));
  Line 1847 [new]: newSize += sizeof(heap_leak_check_info);
  Line 1850 [new]: // does the new allocation simply fit in the old allocation?
  Line 1851 [new]: if (newSize > minSize && newSize <= maxSize) {
  Line 1856 [new]: info->size = newSize - sizeof(heap_leak_check_info);
  Line 1857 [new]: newSize -= sizeof(heap_leak_check_info);
  Line 1860 [new]: T(Reallocate((addr_t)address, (addr_t)address, newSize));
  Line 1861 [new]: *newAddress = address;
  Line 1866 [new]: // new leak check info will be created with the malloc below
  Line 1867 [new]: newSize -= sizeof(heap_leak_check_info);
  Line 1870 [new]: // if not, allocate a new chunk of memory
  Line 1871 [new]: *newAddress = malloc_etc(newSize, flags);
  Line 1872 [new]: T(Reallocate((addr_t)address, (addr_t)*newAddress, newSize));
  Line 1873 [new]: if (*newAddress == NULL) {
  Line 1879 [new]: memcpy(*newAddress, address, min_c(maxSize, newSize));
  Line 1910 [new]: // hopefully the heap grower will manage to create a new heap
  Line 1912 [new]: dprintf("heap: requesting new grow heap\n");
  Line 1945 [new]: heap_create_new_heap_area(heap_allocator *heap, const char *name, size_t size)
  Line 1973 [new]: // the grow heap is going to run full soon, try to allocate a new
  Line 1976 [new]: if (heap_create_new_heap_area(sGrowHeap, "additional grow heap",
  Line 1978 [new]: dprintf("heap_grower: failed to create new grow heap area\n");
  Line 1989 [new]: if (heap_create_new_heap_area(heap, "additional heap",
  Line 1991 [new]: dprintf("heap_grower: failed to create new heap area\n");
  Line 2409 [new]: realloc_etc(void *address, size_t newSize, uint32 flags)
  Line 2417 [new]: return malloc_etc(newSize, flags);
  Line 2419 [new]: if (newSize == 0) {
  Line 2424 [new]: void *newAddress = NULL;
  Line 2428 [new]: if (heap_realloc(heap, address, &newAddress, newSize, flags) == B_OK) {
  Line 2432 [new]: return newAddress;
  Line 2437 [new]: if (heap_realloc(sGrowHeap, address, &newAddress, newSize, flags) == B_OK)
  Line 2438 [new]: return newAddress;
  Line 2453 [new]: if (available >= newSize) {
  Line 2454 [new]: // there is enough room available for the newSize
  Line 2455 [new]: TRACE(("realloc(): new size %ld fits in old area %ld with %ld "
  Line 2456 [new]: "available\n", newSize, area, available));
  Line 2457 [new]: info->allocation_size = newSize;
  Line 2462 [new]: newAddress = malloc(newSize);
  Line 2463 [new]: if (newAddress == NULL) {
  Line 2464 [new]: dprintf("realloc(): failed to allocate new block of %ld bytes\n",
  Line 2465 [new]: newSize);
  Line 2469 [new]: memcpy(newAddress, address, min_c(newSize, info->allocation_size));
  Line 2471 [new]: TRACE(("realloc(): allocated new block %p for size %ld and deleted "
  Line 2472 [new]: "old area %ld\n", newAddress, newSize, area));
  Line 2473 [new]: return newAddress;
  Line 2478 [new]: newSize);
  Line 2484 [new]: realloc(void *address, size_t newSize)
  Line 2486 [new]: return realloc_etc(address, newSize, 0);
  Line 2523 [new]: DeferredFreeListEntry *entry = new(block) DeferredFreeListEntry;
  Line 867 [panic]: panic("free page is not part of the page table\n");
  Line 870 [panic]: panic("free page has invalid index\n");
  Line 873 [panic]: panic("free page index does not lead to target page\n");
  Line 876 [panic]: panic("free page entry has invalid prev link\n");
  Line 879 [panic]: panic("free page marked as in use\n");
  Line 889 [panic]: panic("free page count doesn't match free page list\n");
  Line 900 [panic]: panic("free pages and used pages do not add up (%lu + %lu != %lu)\n",
  Line 913 [panic]: panic("size ordering of area list broken\n");
  Line 916 [panic]: panic("area list entry has invalid prev link\n");
  Line 927 [panic]: panic("base ordering of all_areas list broken\n");
  Line 948 [panic]: panic("page area not present in area list\n");
  Line 955 [panic]: panic("used page is not part of the page table\n");
  Line 958 [panic]: panic("used page has invalid index\n");
  Line 961 [panic]: panic("used page index does not lead to target page\n");
  Line 964 [panic]: panic("used page entry has invalid prev link (%p vs %p bin "
  Line 969 [panic]: panic("used page marked as not in use\n");
  Line 972 [panic]: panic("used page with bin index %u in page list of bin %lu\n",
  Line 977 [panic]: panic("ordering of bin page list broken\n");
  Line 986 [panic]: panic("free list entry out of page range\n");
  Line 989 [panic]: panic("free list entry not on a element boundary\n");
  Line 997 [panic]: panic("empty index beyond slot count (%u with %lu slots)\n",
  Line 1003 [panic]: panic("more free slots than fit into the page\n");
  Line 1113 [panic]: panic("tried removing heap area that has still pages in use");
  Line 1118 [panic]: panic("tried removing the last non-full heap area");
  Line 1143 [panic]: panic("removing heap area that is not in all list");
  Line 1188 [panic]: panic("heap configuration invalid - max bin count reached\n");
  Line 1463 [panic]: panic("got an in use page %p from the free pages list\n", page);
  Line 1529 [panic]: panic("memalign() with an alignment which is not a power of 2\n");
  Line 1636 [panic]: panic("free(): page %p: invalid bin_index %d\n", page, page->bin_index);
  Line 1652 [panic]: panic("free(): address %p already exists in page free "
  Line 1669 [panic]: panic("free(): passed invalid pointer %p supposed to be in bin for "
  Line 1813 [panic]: panic("realloc(): page %p: invalid bin_index %d\n", page,
  Line 1936 [panic]: panic("heap: all heaps have run out of memory while growing\n");
  Line 2100 [panic]: panic("heap_init_post_area(): couldn't allocate dedicate grow heap "
  Line 2108 [panic]: panic("heap_init_post_area(): failed to create dedicated grow heap\n");
  Line 2128 [panic]: panic("heap_init_post_area(): couldn't allocate VIP heap area");
  Line 2135 [panic]: panic("heap_init_post_area(): failed to create VIP heap\n");
  Line 2150 [panic]: panic("heap_init_post_sem(): failed to create heap grow sem\n");
  Line 2156 [panic]: panic("heap_init_post_sem(): failed to create heap grown notify sem\n");
  Line 2174 [panic]: panic("heap_init_post_thread(): cannot create heap grow thread\n");
  Line 2223 [panic]: panic("heap_init_post_thread(): failed to init deferred deleter");
  Line 2239 [panic]: panic("memalign(): called with interrupts disabled\n");
  Line 2323 [panic]: panic("heap: kernel heap has run out of memory\n");
  Line 2364 [panic]: panic("free(): called with interrupts disabled\n");
  Line 2404 [panic]: panic("free(): free failed for address %p\n", address);
  Line 2412 [panic]: panic("realloc(): called with interrupts disabled\n");
  Line 2477 [panic]: panic("realloc(): failed to realloc address %p to size %lu\n", address,
  Line 1541 [TODO]: // TODO: The alignment is done by ensuring that the element size
  Line 2461 [TODO]: // have to allocate/copy/free - TODO maybe resize the area instead?

File: src/system/kernel/image.cpp
  Line 91 [malloc]: image = (struct image*)malloc(sizeof(struct image));
  Line 362 [new]: sImageTable = new(std::nothrow) ImageTable;
  Line 374 [new]: new(&sNotificationService) ImageNotificationService();
  Line 433 [user_memcpy]: || user_memcpy(&info, userInfo, size) < B_OK)
  Line 493 [user_memcpy]: if (user_memcpy(userInfo, &info, size) < B_OK)
  Line 512 [user_memcpy]: || user_memcpy(&cookie, _cookie, sizeof(int32)) < B_OK) {
  Line 518 [user_memcpy]: if (user_memcpy(userInfo, &info, size) < B_OK
  Line 519 [user_memcpy]: || user_memcpy(_cookie, &cookie, sizeof(int32)) < B_OK) {
  Line 364 [panic]: panic("image_init(): Failed to allocate image table!");
  Line 370 [panic]: panic("image_init(): Failed to init image table: %s", strerror(error));

File: src/system/kernel/interrupts.cpp
  Line 441 [malloc]: io = (struct io_handler *)malloc(sizeof(struct io_handler));
  Line 731 [new]: assign_io_interrupt_to_cpu(int32 vector, int32 newCPU)
  Line 737 [new]: if (newCPU == -1)
  Line 738 [new]: newCPU = assign_cpu();
  Line 740 [new]: if (newCPU == oldCPU)
  Line 751 [new]: newCPU = arch_int_assign_to_cpu(vector, newCPU);
  Line 752 [new]: sVectors[vector].assigned_cpu->cpu = newCPU;
  Line 753 [new]: cpu = &gCPU[newCPU];
  Line 621 [panic]: panic("reserved interrupt vector range %" B_PRId32 "-%" B_PRId32 " overlaps already "
  Line 701 [panic]: panic("invalid start vector %" B_PRId32 " or count %" B_PRId32 " supplied to "
  Line 712 [panic]: panic("io interrupt vector %" B_PRId32 " was not allocated\n",
  Line 719 [panic]: panic("freeing io interrupt vector %" B_PRId32 " that is still asigned to a "

File: src/system/kernel/kernel_daemon.cpp
  Line 9 [new]: #include <new>
  Line 89 [new]: struct ::daemon* daemon = new(std::nothrow) (struct ::daemon);
  Line 301 [new]: new(&sKernelDaemon) KernelDaemon;
  Line 305 [new]: new(&sResourceResizer) KernelDaemon;
  Line 303 [panic]: panic("kernel_daemon_init(): failed to init kernel daemon");
  Line 307 [panic]: panic("kernel_daemon_init(): failed to init resource resizer");

File: src/system/kernel/lib/Jamfile
  Line 135 [strcpy]: strcpy.c
  Line 131 [strcat]: strcat.c
  Line 67 [sprintf]: kernel_vsprintf.cpp
  Line 113 [ioctl]: ioctl.c

File: src/system/kernel/lib/kernel_vsprintf.cpp
  Line 481 [sprintf]: vsprintf(char *buffer, const char *format, va_list args)
  Line 502 [sprintf]: sprintf(char *buffer, const char *format, ...)

File: src/system/kernel/lib/stack_protector.cpp
  Line 22 [panic]: panic("stack smashing detected\n");

File: src/system/kernel/lib/strtod.c
  Line 392 [malloc]: rv = (Bigint *)malloc(sizeof(Bigint) + (x-1)*sizeof(Long));
  Line 2014 [malloc]: *resultp = (char *) malloc(i + 1);

File: src/system/kernel/locks/lock.cpp
  Line 97 [panic]: panic("recursive_lock_lock: called with interrupts disabled for lock "
  Line 123 [panic]: panic("recursive_lock_lock: called with interrupts disabled for lock "
  Line 147 [panic]: panic("recursive_lock %p unlocked by non-holder thread!\n", lock);
  Line 163 [panic]: panic("recursive_lock_switch_lock(): called with interrupts "
  Line 205 [panic]: panic("recursive_lock_switch_from_mutex(): called with interrupts "
  Line 235 [panic]: panic("recursive_lock_switch_from_read_lock(): called with interrupts "
  Line 426 [panic]: panic("rw_lock_destroy(): lock is in use and the caller "
  Line 481 [panic]: panic("too many read locks!");
  Line 497 [panic]: panic("_rw_lock_unset_read_locked(): lock %p not read-locked by current thread", lock);
  Line 508 [panic]: panic("_rw_lock_read_lock(): called with interrupts disabled for lock %p",
  Line 569 [panic]: panic("_rw_lock_read_lock_with_timeout(): called with interrupts "
  Line 700 [panic]: panic("rw_lock_read_unlock(): lock %p not read-locked", lock);
  Line 714 [panic]: panic("_rw_lock_write_lock(): called with interrupts disabled for lock %p",
  Line 762 [panic]: panic("rw_lock_write_unlock(): lock %p not write-locked by this thread",
  Line 902 [panic]: panic("mutex_destroy(): the lock (%p) is held by %" B_PRId32 ", not "
  Line 952 [panic]: panic("mutex_switch_lock(): called with interrupts disabled "
  Line 970 [panic]: panic("mutex_transfer_lock(): current thread is not the lock holder!");
  Line 981 [panic]: panic("mutex_switch_from_read_lock(): called with interrupts disabled "
  Line 999 [panic]: panic("_mutex_lock(): called with interrupts disabled for lock %p",
  Line 1021 [panic]: panic("_mutex_lock(): double lock of %p by thread %" B_PRId32, lock,
  Line 1024 [panic]: panic("_mutex_lock(): using uninitialized lock %p", lock);
  Line 1069 [panic]: panic("_mutex_unlock() failure: thread %" B_PRId32 " is trying to "
  Line 1109 [panic]: panic("_mutex_lock(): called with interrupts disabled for lock %p",
  Line 1123 [panic]: panic("_mutex_lock(): double lock of %p by thread %" B_PRId32, lock,
  Line 1126 [panic]: panic("_mutex_lock(): using uninitialized lock %p", lock);
  Line 1218 [panic]: panic("_mutex_trylock(): using uninitialized lock %p", lock);

File: src/system/kernel/locks/user_mutex.cpp
  Line 133 [new]: user_atomic_test_and_set(int32* value, int32 newValue, int32 testAgainst,
  Line 139 [new]: result = atomic_test_and_set(value, newValue, testAgainst);
  Line 145 [new]: result = atomic_test_and_set(value, newValue, testAgainst);
  Line 235 [new]: context = new(std::nothrow) user_mutex_context;
  Line 286 [new]: entry = new(std::nothrow) UserMutexEntry;
  Line 212 [panic]: panic("user_mutex_init(): Failed to init table!");

File: src/system/kernel/low_resource_manager.cpp
  Line 10 [new]: #include <new>
  Line 333 [new]: int32 newState = B_NO_LOW_RESOURCE;
  Line 337 [new]: newState = B_LOW_RESOURCE_CRITICAL;
  Line 339 [new]: newState = B_LOW_RESOURCE_WARNING;
  Line 341 [new]: newState = B_LOW_RESOURCE_NOTE;
  Line 343 [new]: if (sLowPagesState < newState)
  Line 344 [new]: sLowPagesState = newState;
  Line 350 [new]: newState = B_LOW_RESOURCE_CRITICAL;
  Line 352 [new]: newState = B_LOW_RESOURCE_WARNING;
  Line 354 [new]: newState = B_LOW_RESOURCE_NOTE;
  Line 356 [new]: if (sLowMemoryState < newState)
  Line 357 [new]: sLowMemoryState = newState;
  Line 363 [new]: newState = B_LOW_RESOURCE_CRITICAL;
  Line 365 [new]: newState = B_LOW_RESOURCE_WARNING;
  Line 367 [new]: newState = B_LOW_RESOURCE_NOTE;
  Line 369 [new]: if (sLowSemaphoresState < newState)
  Line 370 [new]: sLowSemaphoresState = newState;
  Line 375 [new]: newState = B_LOW_RESOURCE_CRITICAL;
  Line 377 [new]: newState = B_LOW_RESOURCE_WARNING;
  Line 379 [new]: newState = B_LOW_RESOURCE_NOTE;
  Line 381 [new]: if (sLowSpaceState < newState)
  Line 382 [new]: sLowSpaceState = newState;
  Line 416 [new]: new(&sLowResourceHandlers) HandlerList;
  Line 488 [new]: low_resource_handler *newHandler = new(std::nothrow) low_resource_handler;
  Line 489 [new]: if (newHandler == NULL)
  Line 492 [new]: newHandler->function = function;
  Line 493 [new]: newHandler->data = data;
  Line 494 [new]: newHandler->resources = resources;
  Line 495 [new]: newHandler->priority = priority;
  Line 509 [new]: sLowResourceHandlers.Add(newHandler, true);
  Line 511 [new]: sLowResourceHandlers.InsertBefore(last, newHandler);
  Line 517 [new]: sLowResourceHandlers.Add(newHandler, false);
  Line 220 [TODO]: // TODO: this should take fragmentation into account

File: src/system/kernel/messaging/KMessage.cpp
  Line 42 [malloc]: #	define MEMALIGN(alignment, size)	malloc(size)
  Line 45 [malloc]: #	include <malloc.h>
  Line 22 [new]: #	include <new>
  Line 1002 [new]: int32 newSize = offset + size;
  Line 1004 [new]: if (newSize > INT_MAX - (int32)kMessageBufferAlignment + 1)
  Line 1006 [new]: newSize = _Align(newSize);
  Line 1010 [new]: int32 newCapacity = _CapacityFor(newSize);
  Line 1011 [new]: void* newBuffer = MEMALIGN(kMessageBufferAlignment, newCapacity);
  Line 1012 [new]: if (!newBuffer)
  Line 1014 [new]: fBuffer = newBuffer;
  Line 1015 [new]: fBufferCapacity = newCapacity;
  Line 1019 [new]: if (newSize > fBufferCapacity) {
  Line 1026 [new]: ", needed: %" B_PRId32 "\n", fBufferCapacity, newSize);
  Line 1031 [new]: int32 newCapacity = _CapacityFor(newSize);
  Line 1032 [new]: void* newBuffer = realloc(fBuffer, newCapacity);
  Line 1033 [new]: if (!newBuffer)
  Line 1035 [new]: fBuffer = newBuffer;
  Line 1036 [new]: fBufferCapacity = newCapacity;
  Line 1039 [new]: _Header()->size = newSize;
  Line 1041 [new]: *alignedSize = newSize - offset;
  Line 521 [write_port]: return write_port(targetPort, 'KMSG', fBuffer, ContentSize());
  Line 523 [write_port]: return write_port_etc(targetPort, 'KMSG', fBuffer, ContentSize(),
  Line 632 [read_port]: ssize_t realSize = read_port_etc(fromPort, &what, buffer, messageInfo->size,
  Line 33 [panic]: #		define PANIC(str)	panic(str)
  Line 1025 [panic]: panic("KMessage: out of space: available: %" B_PRId32
  Line 26 [TODO]: // TODO: Add a field index using a hash map, so that lookup improves to O(1)

File: src/system/kernel/messaging/MessagingService.cpp
  Line 10 [new]: #include <new>
  Line 57 [new]: MessagingArea *area = new(nothrow) MessagingArea;
  Line 480 [new]: // not enough space in the last area: create a new area or reuse a
  Line 490 [new]: "left in current area. Allocated new one: %p\n", area));
  Line 497 [new]: // add the new area
  Line 557 [new]: sMessagingService = new(buffer) MessagingService;

File: src/system/kernel/module.cpp
  Line 400 [malloc]: moduleImage = (module_image*)malloc(sizeof(module_image));
  Line 530 [malloc]: if ((module = (struct module*)malloc(sizeof(struct module))) == NULL)
  Line 1101 [malloc]: moduleImage = (module_image*)malloc(sizeof(module_image));
  Line 1988 [malloc]: module_iterator* iterator = (module_iterator*)malloc(
  Line 2040 [malloc]: char* path = (char*)malloc(length + iterator->prefix_length + 2);
  Line 525 [new]: FATAL(("Duplicate module name (%s) detected... ignoring new one\n",
  Line 585 [new]: // name matches if it was a new entry
  Line 848 [new]: // allocate new space on the stack
  Line 976 [new]: // the prefix still reaches into the new path part
  Line 1274 [new]: module_listener* moduleListener = new(std::nothrow) module_listener;
  Line 1353 [new]: struct hash_entry* entry = new(std::nothrow) hash_entry;
  Line 1635 [new]: // we might need to watch new files now
  Line 1670 [new]: module_notification* notification = new(std::nothrow) module_notification;
  Line 1800 [new]: sModulesHash = new(std::nothrow) ModuleTable();
  Line 1805 [new]: sModuleImagesHash = new(std::nothrow) ImageTable();
  Line 1824 [new]: new(&sModuleNotificationService) ModuleNotificationService();
  Line 1940 [new]: // set the new path
  Line 1955 [new]: // re-insert the images that have got a new path
  Line 2164 [user_memcpy]: if (user_memcpy(&offset, _cookie, sizeof(uint32)) != B_OK)
  Line 2168 [user_memcpy]: if (user_memcpy(&bufferSize, _bufferSize, sizeof(size_t)) != B_OK)
  Line 2185 [user_memcpy]: if (user_memcpy(_bufferSize, &bufferSize, sizeof(size_t)) != B_OK)
  Line 2189 [user_memcpy]: if (user_memcpy(_cookie, &offset, sizeof(uint32)) != B_OK)
  Line 628 [panic]: panic("search_module called during kernel startup! name: \"%s\"", name);
  Line 787 [panic]: panic("Trying to unload module %s which is initializing\n",
  Line 792 [panic]: panic("Trying to unload module %s which is un-initializing\n",
  Line 2280 [panic]: panic("module %s has no references.\n", path);
  Line 2286 [panic]: panic("ref count of B_KEEP_LOADED module %s dropped to 0!",
  Line 86 [TODO]: * TODO: Could use only the inode number for hashing. Would probably be
  Line 950 [TODO]: // TODO: remember which directories were already scanned, and don't search
  Line 989 [TODO]: // TODO: this is a bit unclean, as we actually only want to prevent
  Line 1042 [TODO]: // TODO: we might want to create a module here and cache it in the
  Line 2033 [TODO]: // TODO: it would currently be nicer to use the commented
  Line 2141 [TODO]: TODO: check if the function in BeOS really does that (could also mean:

File: src/system/kernel/platform/atari_m68k/platform.cpp
  Line 7 [new]: #include <new>
  Line 310 [new]: fMFP[1] = new(sMFP1Buffer) M68KAtari::MFP(MFP1_BASE, MFP1_VECTOR_BASE);
  Line 314 [new]: fRTC = new(sRTCBuffer) M68KAtari::RTC(TT_RTC_BASE,TT_RTC_VECTOR);
  Line 337 [new]: fMFP[0] = new(sMFP0Buffer) M68KAtari::MFP(MFP0_BASE, MFP0_VECTOR_BASE);
  Line 703 [new]: return new(sM68KPlatformBuffer) M68KAtari;
  Line 316 [panic]: panic("TT RTC required!");
  Line 340 [panic]: panic("You MUST have an ST MFP! Wait, is that *really* an Atari ???");
  Line 566 [panic]: //panic("WRITEME");
  Line 666 [panic]: panic("Bombs!");
  Line 667 [panic]: panic("WRITEME");

File: src/system/kernel/port.cpp
  Line 257 [strcpy]: fName = alloc_tracing_buffer_strcpy(port->lock.name, B_OS_NAME_LENGTH,
  Line 736 [malloc]: port_message* message = (port_message*)malloc(size);
  Line 409 [new]: OwnerChange(Port* port, team_id newOwner, status_t status)
  Line 413 [new]: fNewOwner(newOwner),
  Line 434 [new]: #	define T(x) new(std::nothrow) PortTracing::x;
  Line 721 [new]: BReference<Port> newPortRef = get_locked_port(portID);
  Line 723 [new]: if (newPortRef.Get() != &port || is_port_closed(&port)) {
  Line 936 [new]: new(&sPorts) PortHashTable;
  Line 942 [new]: new(&sPortsByName) PortNameHashTable;
  Line 967 [new]: new(&sNotificationService) PortNotificationService();
  Line 997 [new]: Port* newPort = new(std::nothrow) Port(team_get_current_team_id(),
  Line 999 [new]: if (newPort == NULL)
  Line 1001 [new]: port.SetTo(newPort, true);
  Line 1391 [new]: BReference<Port> newPortRef = get_locked_port(id);
  Line 1392 [new]: if (newPortRef == NULL) {
  Line 1396 [new]: locker.SetTo(newPortRef->lock, true);
  Line 1398 [new]: if (newPortRef != portRef
  Line 1494 [new]: BReference<Port> newPortRef = get_locked_port(id);
  Line 1495 [new]: if (newPortRef == NULL) {
  Line 1499 [new]: locker.SetTo(newPortRef->lock, true);
  Line 1501 [new]: if (newPortRef != portRef
  Line 1628 [new]: BReference<Port> newPortRef = get_locked_port(id);
  Line 1629 [new]: if (newPortRef == NULL) {
  Line 1633 [new]: locker.SetTo(newPortRef->lock, true);
  Line 1635 [new]: if (newPortRef != portRef || is_port_closed(portRef)) {
  Line 1715 [new]: set_port_owner(port_id id, team_id newTeamID)
  Line 1717 [new]: TRACE(("set_port_owner(id = %ld, team = %ld)\n", id, newTeamID));
  Line 1722 [new]: // get the new team
  Line 1723 [new]: Team* team = Team::Get(newTeamID);
  Line 1749 [new]: MutexLocker newTeamPortsListLocker;
  Line 1751 [new]: newTeamPortsListLocker.SetTo(sTeamListLock[secondLockIndex],
  Line 784 [user_memcpy]: status_t status = user_memcpy(buffer, message->buffer, size);
  Line 1672 [user_memcpy]: status_t status = user_memcpy(message->buffer + offset,
  Line 1842 [user_memcpy]: && user_memcpy(userInfo, &info, sizeof(struct port_info)) < B_OK)
  Line 1860 [user_memcpy]: || user_memcpy(&cookie, userCookie, sizeof(int32)) < B_OK)
  Line 1866 [user_memcpy]: if (user_memcpy(userCookie, &cookie, sizeof(int32)) < B_OK
  Line 1867 [user_memcpy]: || (status == B_OK && user_memcpy(userInfo, &info,
  Line 1920 [user_memcpy]: && user_memcpy(userCode, &messageCode, sizeof(int32)) < B_OK)
  Line 1991 [user_memcpy]: || user_memcpy(userInfo, &info, sizeof(info)) != B_OK)) {
  Line 1554 [write_port]: write_port(port_id id, int32 msgCode, const void* buffer, size_t bufferSize)
  Line 1563 [write_port]: write_port_etc(port_id id, int32 msgCode, const void* buffer,
  Line 1603 [write_port]: TRACE(("write_port_etc: invalid port_id %ld\n", id));
  Line 1609 [write_port]: TRACE(("write_port_etc: port %ld closed\n", id));
  Line 1928 [write_port]: _user_write_port_etc(port_id port, int32 messageCode, const void *userBuffer,
  Line 804 [read_port]: // read_port() will see the B_BAD_PORT_ID return value, and act accordingly
  Line 1447 [read_port]: read_port(port_id port, int32* msgCode, void* buffer, size_t bufferSize)
  Line 1449 [read_port]: return read_port_etc(port, msgCode, buffer, bufferSize, 0, 0);
  Line 1454 [read_port]: read_port_etc(port_id id, int32* _code, void* buffer, size_t bufferSize,
  Line 1476 [read_port]: TRACE(("read_port_etc(): closed port %ld\n", id));
  Line 1902 [read_port]: _user_read_port_etc(port_id port, int32 *userCode, void *userBuffer,
  Line 1916 [read_port]: bytesRead = read_port_etc(port, &messageCode, userBuffer, bufferSize,
  Line 841 [panic]: panic("Invalid port state!\n");
  Line 938 [panic]: panic("Failed to init port hash table!");
  Line 944 [panic]: panic("Failed to init port by name hash table!");
  Line 984 [panic]: panic("ports used too early!\n");
  Line 1063 [panic]: panic("Port state was modified during creation!\n");
  Line 1238 [panic]: panic("ports used too early!\n");
  Line 1409 [panic]: panic("port %" B_PRId32 ": no messages found\n", portRef->id);
  Line 1517 [panic]: panic("port %" B_PRId32 ": no messages found\n", portRef->id);
  Line 692 [TODO]: // TODO: add per team limit
  Line 700 [TODO]: // TODO: we don't want to wait - but does that also mean we
  Line 713 [TODO]: // TODO: right here the condition could be notified and we'd

File: src/system/kernel/posix/realtime_sem.cpp
  Line 10 [new]: #include <new>
  Line 226 [new]: sem = new(std::nothrow) NamedSem;
  Line 319 [new]: TeamSemInfo* clone = new(std::nothrow) TeamSemInfo(sem, fUserSemaphore);
  Line 404 [new]: // create new context
  Line 405 [new]: realtime_sem_context* context = new(std::nothrow) realtime_sem_context;
  Line 454 [new]: // not open yet -- create a new team sem
  Line 464 [new]: teamSem = new(std::nothrow) TeamSemInfo(sem, userSem);
  Line 599 [new]: // no context yet -- create a new one
  Line 600 [new]: context = new(std::nothrow) realtime_sem_context;
  Line 648 [new]: new(&sSemTable) GlobalSemTable;
  Line 714 [user_memcpy]: if (user_memcpy(&userSem->u.named_sem_id, &id, sizeof(int32_t)) != B_OK
  Line 715 [user_memcpy]: || user_memcpy(_usedUserSem, &usedUserSem, sizeof(sem_t*)) != B_OK) {
  Line 745 [user_memcpy]: && user_memcpy(_deleteUserSem, &deleteUserSem, sizeof(sem_t*))
  Line 787 [user_memcpy]: if (user_memcpy(_value, &count, sizeof(int)) != B_OK)
  Line 650 [panic]: panic("realtime_sem_init() failed to init global sem table");

File: src/system/kernel/posix/xsi_message_queue.cpp
  Line 46 [malloc]: message = (char *)malloc(sizeof(char) * _length);
  Line 11 [new]: #include <new>
  Line 635 [new]: ipcKey = new(std::nothrow) Ipc(key);
  Line 637 [new]: TRACE(("xsi_msgget: failed to create new Ipc object "
  Line 664 [new]: // Create a new message queue for this key
  Line 671 [new]: messageQueue = new(std::nothrow) XsiMessageQueue(flags);
  Line 673 [new]: TRACE_ERROR(("xsi_msgget: failed to allocate new xsi "
  Line 824 [new]: = new(std::nothrow) queued_message(messagePointer, messageSize);
  Line 826 [new]: TRACE_ERROR(("xsi_msgsnd: failed to allocate new message\n"));
  Line 831 [new]: TRACE_ERROR(("xsi_msgsnd: failed to create new message to queue: %s\n",
  Line 50 [user_memcpy]: if (user_memcpy(&type, _message, sizeof(long)) != B_OK
  Line 51 [user_memcpy]: || user_memcpy(message, (void *)((char *)_message + sizeof(long)),
  Line 71 [user_memcpy]: if (user_memcpy(_message, &type, sizeof(long)) != B_OK
  Line 72 [user_memcpy]: || user_memcpy((void *)((char *)_message + sizeof(long)), message,
  Line 543 [user_memcpy]: if (user_memcpy(buffer, &msg, sizeof(struct msqid_ds)) < B_OK) {
  Line 544 [user_memcpy]: TRACE_ERROR(("xsi_msgctl: user_memcpy failed\n"));
  Line 558 [user_memcpy]: if (user_memcpy(&msg, buffer, sizeof(struct msqid_ds)) < B_OK) {
  Line 559 [user_memcpy]: TRACE_ERROR(("xsi_msgctl: user_memcpy failed\n"));
  Line 490 [panic]: panic("xsi_msg_init() failed to initialize ipc hash table\n");
  Line 493 [panic]: panic("xsi_msg_init() failed to initialize message queue hash table\n");
  Line 182 [TODO]: // TODO: fix this
  Line 236 [TODO]: // TODO: this can cause starvation for any

File: src/system/kernel/posix/xsi_semaphore.cpp
  Line 389 [malloc]: = (int16 *)malloc(sizeof(int16) * fNumberOfSemaphores);
  Line 11 [new]: #include <new>
  Line 221 [new]: fSemaphores = new(std::nothrow) XsiSemaphore[numberOfSemaphores];
  Line 356 [new]: // for creating a new sem_undo structure.
  Line 369 [new]: int newValue = current->undo_values[semaphoreNumber] + value;
  Line 370 [new]: if (newValue > SHRT_MAX || newValue < SHRT_MIN) {
  Line 371 [new]: TRACE_ERROR(("XsiSemaphoreSet::RecordUndo: newValue %d "
  Line 372 [new]: "out of range\n", newValue));
  Line 375 [new]: current->undo_values[semaphoreNumber] = newValue;
  Line 393 [new]: = new(std::nothrow) sem_undo(this, team, undoValues);
  Line 405 [new]: context = new(std::nothrow) xsi_sem_context;
  Line 424 [new]: TRACE(("XsiSemaphoreSet::RecordUndo: new record added. Team = %d, "
  Line 748 [new]: ipcKey = new(std::nothrow) Ipc(key);
  Line 750 [new]: TRACE_ERROR(("xsi_semget: failed to create new Ipc object "
  Line 756 [new]: // Create a new semaphore set for this key
  Line 771 [new]: semaphoreSet = new(std::nothrow) XsiSemaphoreSet(numberOfSemaphores, flags);
  Line 773 [new]: TRACE_ERROR(("xsi_semget: failed to allocate a new xsi "
  Line 793 [new]: TRACE(("semget: new set = %d created, sequence = %ld\n",
  Line 810 [user_memcpy]: || user_memcpy(&args, _args, sizeof(union semun)) != B_OK)
  Line 915 [user_memcpy]: if (user_memcpy(args.array + i, &value,
  Line 917 [user_memcpy]: TRACE_ERROR(("xsi_semctl: user_memcpy failed\n"));
  Line 936 [user_memcpy]: if (user_memcpy(&value, args.array + i,
  Line 938 [user_memcpy]: TRACE_ERROR(("xsi_semctl: user_memcpy failed\n"));
  Line 963 [user_memcpy]: if (user_memcpy(args.buf, &sem, sizeof(struct semid_ds))
  Line 965 [user_memcpy]: TRACE_ERROR(("xsi_semctl: user_memcpy failed\n"));
  Line 980 [user_memcpy]: if (user_memcpy(&sem, args.buf, sizeof(struct semid_ds))
  Line 982 [user_memcpy]: TRACE_ERROR(("xsi_semctl: user_memcpy failed\n"));
  Line 1068 [user_memcpy]: if (user_memcpy(operations, ops,
  Line 1070 [user_memcpy]: TRACE_ERROR(("xsi_semop: user_memcpy failed\n"));
  Line 638 [panic]: panic("xsi_sem_init() failed to initialize ipc hash table\n");
  Line 641 [panic]: panic("xsi_sem_init() failed to initialize semaphore hash table\n");
  Line 310 [TODO]: // TODO: fix this

File: src/system/kernel/real_time_clock.cpp
  Line 275 [new]: TRACE(("old system_time_offset %lld old %lld new %lld gmt %d\n",
  Line 306 [new]: TRACE(("new system_time_offset %lld\n",
  Line 324 [user_memcpy]: || user_memcpy(_timezoneOffset, &offset, sizeof(offset)) < B_OK))
  Line 375 [user_memcpy]: || user_memcpy(_userIsGMT, &isGMT, sizeof(bool)) != B_OK))

File: src/system/kernel/scheduler/low_latency.cpp
  Line 51 [new]: // wake new package
  Line 54 [new]: // wake new core
  Line 168 [new]: int32 newCPU = other->CPUHeap()->PeekRoot()->ID();
  Line 178 [new]: assign_io_interrupt_to_cpu(chosen->irq, newCPU);
  Line 106 [panic]: panic("other->CPUMask().IsEmpty()\n");

File: src/system/kernel/scheduler/power_saving.cpp
  Line 207 [new]: int32 newCPU = smallTaskCore->CPUHeap()->PeekRoot()->ID();
  Line 209 [new]: if (newCPU != cpu->cpu_num)
  Line 210 [new]: assign_io_interrupt_to_cpu(irq->irq, newCPU);
  Line 252 [new]: int32 newCPU = other->CPUHeap()->PeekRoot()->ID();
  Line 260 [new]: assign_io_interrupt_to_cpu(chosen->irq, newCPU);

File: src/system/kernel/scheduler/scheduler.cpp
  Line 78 [new]: static void enqueue(Thread* thread, bool newOne);
  Line 96 [new]: enqueue(Thread* thread, bool newOne)
  Line 114 [new]: && (!newOne || !threadData->HasCacheExpired())) {
  Line 156 [new]: TRACE("enqueueing new thread %" B_PRId32 " with static priority %" B_PRId32 "\n", thread->id,
  Line 210 [new]: // a new position.
  Line 277 [new]: scheduler_new_thread_entry(Thread* thread)
  Line 505 [new]: thread->scheduler_data = new(std::nothrow) ThreadData(thread);
  Line 651 [new]: sCPUToCore = new(std::nothrow) int32[cpuCount];
  Line 656 [new]: sCPUToPackage = new(std::nothrow) int32[cpuCount];
  Line 701 [new]: gCPUEntries = new(std::nothrow) CPUEntry[cpuCount];
  Line 706 [new]: gCoreEntries = new(std::nothrow) CoreEntry[coreCount];
  Line 711 [new]: gPackageEntries = new(std::nothrow) PackageEntry[packageCount];
  Line 716 [new]: new(&gCoreLoadHeap) CoreLoadHeap(coreCount);
  Line 717 [new]: new(&gCoreHighLoadHeap) CoreLoadHeap(coreCount);
  Line 719 [new]: new(&gIdlePackageList) IdlePackageList;
  Line 494 [panic]: panic("scheduler_reschedule_no_op() called in non-ready thread");
  Line 579 [panic]: panic("scheduler_set_cpu_enabled: called with interrupts enabled");
  Line 754 [panic]: panic("scheduler_init: failed to initialize scheduler\n");

File: src/system/kernel/scheduler/scheduler_cpu.cpp
  Line 551 [new]: int32 newKey;
  Line 555 [new]: newKey = intervalSkipped ? fCurrentLoad : GetLoad();
  Line 564 [new]: newKey = GetLoad();
  Line 569 [new]: ASSERT(newKey >= 0);
  Line 571 [new]: if (oldKey == newKey)
  Line 574 [new]: if (newKey > kHighLoad) {
  Line 580 [new]: gCoreHighLoadHeap.Insert(this, newKey);
  Line 584 [new]: gCoreHighLoadHeap.ModifyKey(this, newKey);
  Line 585 [new]: } else if (newKey < kMediumLoad) {
  Line 591 [new]: gCoreLoadHeap.Insert(this, newKey);
  Line 595 [new]: gCoreLoadHeap.ModifyKey(this, newKey);
  Line 598 [new]: gCoreHighLoadHeap.ModifyKey(this, newKey);
  Line 600 [new]: gCoreLoadHeap.ModifyKey(this, newKey);
  Line 810 [new]: new(&sDebugCPUHeap) CPUPriorityHeap(smp_get_num_cpus());
  Line 811 [new]: new(&sDebugCoreHeap) CoreLoadHeap(smp_get_num_cpus());

File: src/system/kernel/scheduler/scheduler_load.cpp
  Line 58 [user_memcpy]: if (user_memcpy(userInfo, &sAverageRunnable, sizeof(struct loadavg)) < B_OK)

File: src/system/kernel/scheduler/scheduler_profiler.cpp
  Line 30 [new]: fFunctionData(new(std::nothrow) FunctionData[kMaxFunctionEntries]),
  Line 43 [new]: = new(std::nothrow) FunctionEntry[kMaxFunctionStackEntries];
  Line 189 [new]: sProfiler = new(std::nothrow) Profiler;
  Line 191 [panic]: panic("Scheduler::Profiling::Profiler: could not initialize profiler");

File: src/system/kernel/scheduler/scheduler_tracing.cpp
  Line 161 [dynamic_cast]: if (dynamic_cast<SchedulerTraceEntry*>(_entry) == NULL)
  Line 164 [dynamic_cast]: if (ScheduleThread* entry = dynamic_cast<ScheduleThread*>(_entry)) {
  Line 232 [dynamic_cast]: = dynamic_cast<EnqueueThread*>(_entry)) {
  Line 247 [dynamic_cast]: } else if (RemoveThread* entry = dynamic_cast<RemoveThread*>(_entry)) {

File: src/system/kernel/scheduler/scheduler_tracing.h
  Line 45 [strcpy]: fName = alloc_tracing_buffer_strcpy(thread->name, B_OS_NAME_LENGTH,
  Line 91 [strcpy]: fName = alloc_tracing_buffer_strcpy(thread->name, B_OS_NAME_LENGTH,
  Line 128 [new]: #	define T(x) new(std::nothrow) SchedulerTracing::x;

File: src/system/kernel/scheduler/scheduling_analysis.cpp
  Line 309 [new]: thread = new(memory) Thread(id);
  Line 330 [new]: WaitObject* waitObject = new(memory) WaitObject(type, object);
  Line 355 [new]: // This is a new object at the same address. Replace the old one.
  Line 406 [new]: threadWaitObject = new(memory) ThreadWaitObject(thread->id,
  Line 860 [user_memcpy]: error = user_memcpy(analysis, manager.Analysis(),
  Line 111 [dynamic_cast]: const ThreadKey* key = dynamic_cast<const ThreadKey*>(_key);
  Line 153 [dynamic_cast]: const WaitObjectKey* key = dynamic_cast<const WaitObjectKey*>(_key);
  Line 199 [dynamic_cast]: = dynamic_cast<const ThreadWaitObjectKey*>(_key);
  Line 286 [dynamic_cast]: return dynamic_cast<Thread*>(Lookup(ThreadKey(id)));
  Line 291 [dynamic_cast]: return dynamic_cast<WaitObject*>(Lookup(WaitObjectKey(type, object)));
  Line 297 [dynamic_cast]: return dynamic_cast<ThreadWaitObject*>(
  Line 428 [dynamic_cast]: WaitObject* waitObject = dynamic_cast<WaitObject*>(object);
  Line 454 [dynamic_cast]: Thread* thread = dynamic_cast<Thread*>(object);
  Line 458 [dynamic_cast]: = dynamic_cast<WaitObject*>(object)) {
  Line 577 [dynamic_cast]: = dynamic_cast<SchedulerTraceEntry*>(_entry);
  Line 588 [dynamic_cast]: if (ScheduleThread* entry = dynamic_cast<ScheduleThread*>(_entry)) {
  Line 625 [dynamic_cast]: = dynamic_cast<WaitObjectTraceEntry*>(_entry)) {
  Line 636 [dynamic_cast]: = dynamic_cast<SchedulerTraceEntry*>(_entry);
  Line 642 [dynamic_cast]: if (ScheduleThread* entry = dynamic_cast<ScheduleThread*>(_entry)) {
  Line 745 [dynamic_cast]: = dynamic_cast<EnqueueThread*>(_entry)) {
  Line 767 [dynamic_cast]: } else if (RemoveThread* entry = dynamic_cast<RemoveThread*>(_entry)) {
  Line 802 [dynamic_cast]: = dynamic_cast<WaitObjectTraceEntry*>(_entry)) {

File: src/system/kernel/sem.cpp
  Line 488 [malloc]: char* tempName = (char*)malloc(nameLength);
  Line 510 [new]: new(&sem->queue) ThreadQueue;
  Line 1068 [new]: int32 newIndex = *_cookie;
  Line 1074 [new]: while (sem != NULL && index < newIndex) {
  Line 1087 [new]: newIndex = index + 1;
  Line 1090 [new]: newIndex++;
  Line 1096 [new]: *_cookie = newIndex;
  Line 1102 [new]: set_sem_owner(sem_id id, team_id newTeamID)
  Line 1108 [new]: if (newTeamID < 0)
  Line 1113 [new]: // get the new team
  Line 1114 [new]: Team* newTeam = Team::Get(newTeamID);
  Line 1115 [new]: if (newTeam == NULL)
  Line 1117 [new]: BReference<Team> newTeamReference(newTeam, true);
  Line 1128 [new]: list_add_item(&newTeam->sem_list, &sSems[slot].u.used.team_link);
  Line 1130 [new]: sSems[slot].u.used.owner = newTeam->id;
  Line 1252 [user_memcpy]: if (status == B_OK && user_memcpy(userCount, &count, sizeof(int32)) < B_OK)
  Line 1269 [user_memcpy]: if (status == B_OK && user_memcpy(userInfo, &info, size) < B_OK)
  Line 1286 [user_memcpy]: || user_memcpy(&cookie, userCookie, sizeof(int32)) < B_OK)
  Line 1292 [user_memcpy]: if (user_memcpy(userInfo, &info, size) < B_OK
  Line 1293 [user_memcpy]: || user_memcpy(userCookie, &cookie, sizeof(int32)) < B_OK)
  Line 382 [panic]: panic("sem %" B_PRId32 " has no owner", id);
  Line 428 [panic]: panic("unable to allocate semaphore table!\n");
  Line 736 [panic]: panic("switch_sem_etc: called with interrupts disabled for sem "
  Line 893 [panic]: panic("release_sem_etc(): called with interrupts disabled and "
  Line 756 [TODO]: // TODO: the B_CHECK_PERMISSION flag should be made private, as it
  Line 1066 [TODO]: // TODO: find a way to iterate the list that is more reliable

File: src/system/kernel/shutdown.cpp
  Line 21 [TODO]: // TODO: Once we are sure we can shutdown the system on all hardware

File: src/system/kernel/signal.cpp
  Line 303 [new]: Signal* signalToQueue = new(std::nothrow) Signal(signal);
  Line 745 [new]: #	define T(x)	new(std::nothrow) SignalTracing::x
  Line 2017 [new]: // set new sigaction structure
  Line 2164 [new]: // Set the new block mask and block until interrupted. We might be here
  Line 2401 [new]: _user_set_signal_stack(const stack_t* newUserStack, stack_t* oldUserStack)
  Line 2404 [new]: struct stack_t newStack, oldStack;
  Line 2407 [new]: if ((newUserStack != NULL && (!IS_USER_ADDRESS(newUserStack)
  Line 2408 [new]: || user_memcpy(&newStack, newUserStack, sizeof(stack_t)) < B_OK))
  Line 2426 [new]: if (newUserStack != NULL) {
  Line 2428 [new]: if ((newStack.ss_flags & ~SS_DISABLE) != 0)
  Line 2431 [new]: if ((newStack.ss_flags & SS_DISABLE) == 0) {
  Line 2433 [new]: if (newStack.ss_size < MINSIGSTKSZ)
  Line 2437 [new]: if (!IS_USER_ADDRESS(newStack.ss_sp))
  Line 2440 [new]: thread->signal_stack_base = (addr_t)newStack.ss_sp;
  Line 2441 [new]: thread->signal_stack_size = newStack.ss_size;
  Line 2250 [user_memcpy]: || user_memcpy(&userValue, userUserValue, sizeof(userValue))
  Line 2286 [user_memcpy]: || user_memcpy(&set, userSet, sizeof(sigset_t)) < B_OK))
  Line 2288 [user_memcpy]: || user_memcpy(&oldSet, userOldSet, sizeof(sigset_t)) < B_OK)))
  Line 2296 [user_memcpy]: && user_memcpy(userOldSet, &oldSet, sizeof(sigset_t)) < B_OK)
  Line 2311 [user_memcpy]: || user_memcpy(&act, userAction, sizeof(struct sigaction)) < B_OK))
  Line 2313 [user_memcpy]: || user_memcpy(&oact, userOldAction, sizeof(struct sigaction))
  Line 2322 [user_memcpy]: && user_memcpy(userOldAction, &oact, sizeof(struct sigaction)) < B_OK)
  Line 2336 [user_memcpy]: || user_memcpy(&set, userSet, sizeof(sigset_t)) != B_OK) {
  Line 2353 [user_memcpy]: status = user_memcpy(userInfo, &info, sizeof(info));
  Line 2372 [user_memcpy]: || user_memcpy(&mask, userMask, sizeof(sigset_t)) < B_OK) {
  Line 2393 [user_memcpy]: && user_memcpy(userSet, &set, sizeof(sigset_t)) < B_OK)
  Line 2408 [user_memcpy]: || user_memcpy(&newStack, newUserStack, sizeof(stack_t)) < B_OK))
  Line 2410 [user_memcpy]: || user_memcpy(&oldStack, oldUserStack, sizeof(stack_t)) < B_OK)))
  Line 2449 [user_memcpy]: && user_memcpy(oldUserStack, &oldStack, sizeof(stack_t)) < B_OK)
  Line 2487 [user_memcpy]: || user_memcpy(&signalFrameData, userSignalFrameData,
  Line 1043 [TODO]: // TODO: apply zombie cleaning on SIGCHLD
  Line 1700 [TODO]: // TODO: Is that correct or should we only target the main thread?

File: src/system/kernel/slab/HashedObjectCache.cpp
  Line 66 [new]: HashedObjectCache* cache = new(buffer) HashedObjectCache();
  Line 164 [panic]: panic("hash object cache %p: unknown object %p", this, object);

File: src/system/kernel/slab/MemoryManager.cpp
  Line 417 [new]: //#	define T(x)	new(std::nothrow) SlabMemoryManagerCacheTracing::x
  Line 418 [new]: #	define T(x)	new(std::nothrow) MemoryManager::Tracing::x
  Line 457 [new]: new(&sFreeCompleteMetaChunks) MetaChunkList;
  Line 458 [new]: new(&sFreeShortMetaChunks) MetaChunkList;
  Line 459 [new]: new(&sPartialMetaChunksSmall) MetaChunkList;
  Line 460 [new]: new(&sPartialMetaChunksMedium) MetaChunkList;
  Line 462 [new]: new(&sAreaTable) AreaTable;
  Line 1019 [new]: // We need to allocate a new area. Wait, if someone else is trying to do
  Line 736 [panic]: panic("cannot proceed without locking kernel space!");
  Line 763 [panic]: panic("freeing unknown block %p", pages);
  Line 997 [panic]: panic("MemoryManager::_AllocateChunks(): Unsupported chunk size: %"
  Line 1695 [panic]: panic("out of memory");
  Line 1735 [panic]: panic("invalid meta chunk %p!", metaChunk);
  Line 1748 [panic]: panic("meta chunk %p has invalid chunk size: %" B_PRIuSIZE,
  Line 1754 [panic]: panic("meta chunk %p has invalid total size: %" B_PRIuSIZE,
  Line 1764 [panic]: panic("meta chunk %p has invalid base address: %" B_PRIxADDR, metaChunk,
  Line 1770 [panic]: panic("meta chunk %p has invalid chunk count: %u", metaChunk,
  Line 1776 [panic]: panic("meta chunk %p has invalid unused chunk count: %u", metaChunk,
  Line 1782 [panic]: panic("meta chunk %p has invalid first free chunk: %u", metaChunk,
  Line 1788 [panic]: panic("meta chunk %p has invalid last free chunk: %u", metaChunk,
  Line 1799 [panic]: panic("meta chunk %p has invalid element in free list, chunk: %p",
  Line 1805 [panic]: panic("meta chunk %p has cyclic free list", metaChunk);
  Line 1811 [panic]: panic("meta chunk %p has mismatching free/used chunk counts: total: "
  Line 1825 [panic]: panic("meta chunk %p has used chunks that appear free: total: "
  Line 1835 [panic]: panic("meta chunk %p has used chunk in free range, chunk: %p (%"
  Line 557 [TODO]: // TODO: Support CACHE_UNLOCKED_PAGES!

File: src/system/kernel/slab/MemoryManager.h
  Line 31 [TODO]: // TODO: These sizes have been chosen with 4 KB pages in mind.

File: src/system/kernel/slab/ObjectCache.cpp
  Line 181 [panic]: panic("cache: destroying a slab which isn't empty.");
  Line 202 [panic]: panic("object_cache: free'd object %p has no slab", object);
  Line 213 [panic]: panic("object_cache: tried to free invalid object pointer %p", object);
  Line 264 [panic]: panic("object_cache: to be freed object %p: slab not part of cache!",
  Line 273 [panic]: panic("object_cache: double free of %p (slab %p, cache %p)",

File: src/system/kernel/slab/ObjectDepot.cpp
  Line 331 [new]: // the magazine depot doesn't provide us with a new empty magazine
  Line 355 [new]: // allocate a new empty magazine

File: src/system/kernel/slab/Slab.cpp
  Line 132 [strcpy]: fName = alloc_tracing_buffer_strcpy(name, 64, false);
  Line 13 [new]: #include <new>
  Line 240 [new]: #	define T(x)	new(std::nothrow) SlabObjectCacheTracing::x
  Line 542 [new]: // not found, add a new entry, if there are free slots
  Line 978 [new]: // add new slabs until there are as many free ones as requested
  Line 980 [new]: slab* newSlab = cache->CreateSlab(flags);
  Line 981 [new]: if (newSlab == NULL) {
  Line 988 [new]: cache->total_objects += newSlab->size;
  Line 990 [new]: cache->empty.Add(newSlab);
  Line 1052 [new]: size_t newCapacity = cache->depot.magazine_capacity / 2;
  Line 1053 [new]: if (newCapacity < 2)
  Line 1054 [new]: newCapacity = 2;
  Line 1055 [new]: cache->depot.magazine_capacity = newCapacity;
  Line 1396 [new]: new (&sObjectCaches) ObjectCacheList();
  Line 1464 [new]: new(&sMaintenanceQueue) MaintenanceQueue;
  Line 895 [panic]: panic("cache destroy: still has full slabs");
  Line 898 [panic]: panic("cache destroy: still has partial slabs");
  Line 1345 [panic]: panic("object_cache: object %p is already freed", object);
  Line 1470 [panic]: panic("slab_init_post_thread(): failed to spawn object cache resizer "
  Line 1338 [TODO]: // TODO: allow forcing the check even if we don't find deadbeef

File: src/system/kernel/slab/SmallObjectCache.cpp
  Line 39 [new]: SmallObjectCache* cache = new(buffer) SmallObjectCache();
  Line 82 [new]: slab* newSlab = slab_in_pages(pages, slab_size);
  Line 84 [new]: if (AllocateTrackingInfos(newSlab, byteCount, flags) != B_OK) {
  Line 89 [new]: slab* slab = InitSlab(newSlab, pages, byteCount, flags);
  Line 92 [new]: FreeTrackingInfos(newSlab, flags);

File: src/system/kernel/slab/allocator.cpp
  Line 18 [malloc]: #include <malloc.h>
  Line 255 [malloc]: malloc(size_t size)
  Line 269 [new]: realloc_etc(void* address, size_t newSize, uint32 flags)
  Line 271 [new]: if (newSize == 0) {
  Line 277 [new]: return block_alloc(newSize, 0, flags);
  Line 286 [new]: if (oldSize == newSize)
  Line 289 [new]: void* newBlock = block_alloc(newSize, 0, flags);
  Line 290 [new]: if (newBlock == NULL)
  Line 293 [new]: memcpy(newBlock, address, std::min(oldSize, newSize));
  Line 297 [new]: return newBlock;
  Line 302 [new]: realloc(void* address, size_t newSize)
  Line 304 [new]: return realloc_etc(address, newSize, 0);
  Line 198 [panic]: panic("allocator: failed to init block cache");
  Line 282 [panic]: panic("block_realloc(): allocation %p not known", address);
  Line 314 [panic]: panic("block allocator not enabled!");

File: src/system/kernel/slab/slab_private.h
  Line 33 [malloc]: return malloc_etc(size, flags);

File: src/system/kernel/smp.cpp
  Line 1407 [malloc]: = (struct smp_msg*)malloc(sizeof(struct smp_msg));
  Line 987 [user_memcpy]: || user_memcpy(buffer, &info, sizeof(info)) != B_OK) {
  Line 66 [panic]: // panic(), assuming a deadlock.
  Line 207 [panic]: panic("spinlock %p was held for %" B_PRIdBIGTIME " usecs (%d allowed)\n",
  Line 304 [panic]: panic("try_acquire_spinlock: attempt to acquire lock %p with "
  Line 333 [panic]: panic("acquire_spinlock: attempt to acquire lock %p with interrupts "
  Line 348 [panic]: panic("acquire_spinlock(): Failed to acquire spinlock %p "
  Line 352 [panic]: panic("acquire_spinlock(): Failed to acquire spinlock %p "
  Line 380 [panic]: panic("acquire_spinlock: attempt to acquire lock %p twice on "
  Line 396 [panic]: panic("acquire_spinlock_nocheck: attempt to acquire lock %p with "
  Line 410 [panic]: panic("acquire_spinlock_nocheck(): Failed to acquire "
  Line 414 [panic]: panic("acquire_spinlock_nocheck(): Failed to acquire "
  Line 442 [panic]: panic("acquire_spinlock_nocheck: attempt to acquire lock %p twice "
  Line 459 [panic]: panic("acquire_spinlock_cpu: attempt to acquire lock %p with "
  Line 473 [panic]: panic("acquire_spinlock_cpu(): Failed to acquire spinlock "
  Line 477 [panic]: panic("acquire_spinlock_cpu(): Failed to acquire spinlock "
  Line 505 [panic]: panic("acquire_spinlock_cpu(): attempt to acquire lock %p twice on "
  Line 525 [panic]: panic("release_spinlock: attempt to release lock %p with "
  Line 531 [panic]: panic("release_spinlock: lock %p was already released\n", lock);
  Line 538 [panic]: panic("release_spinlock: attempt to release lock %p with "
  Line 542 [panic]: panic("release_spinlock: lock %p was already released\n", lock);
  Line 553 [panic]: panic("try_acquire_write_spinlock: attempt to acquire lock %p with "
  Line 558 [panic]: panic("try_acquire_write_spinlock(): attempt to acquire lock %p twice "
  Line 572 [panic]: panic("acquire_write_spinlock: attempt to acquire lock %p with "
  Line 585 [panic]: panic("acquire_write_spinlock(): Failed to acquire spinlock %p "
  Line 603 [panic]: panic("release_write_spinlock: lock %p was already released (value: "
  Line 617 [panic]: panic("try_acquire_read_spinlock: attempt to acquire lock %p with "
  Line 622 [panic]: panic("try_acquire_read_spinlock(): attempt to acquire lock %p twice "
  Line 637 [panic]: panic("acquire_read_spinlock: attempt to acquire lock %p with "
  Line 650 [panic]: panic("acquire_read_spinlock(): Failed to acquire spinlock %p "
  Line 668 [panic]: panic("release_read_spinlock: lock %p was already released (value:"
  Line 894 [panic]: panic("last == NULL or msg != msg1");
  Line 1129 [panic]: panic("smp_send_multicast_ici(): 0 CPU mask");
  Line 1409 [panic]: panic("error creating smp mailboxes\n");
  Line 1478 [panic]: panic("call_single_cpu is not yet available");
  Line 981 [TODO]: // TODO: This isn't very useful at the moment...

File: src/system/kernel/syscalls.cpp
  Line 364 [strcpy]: = alloc_tracing_buffer_strcpy(
  Line 221 [new]: new(&sGenericSyscalls) GenericSyscallList;
  Line 260 [new]: generic_syscall* syscall = new(std::nothrow) generic_syscall;
  Line 474 [new]: new(std::nothrow) SyscallTracing::PreSyscall(syscallNumber, parameters);
  Line 488 [new]: new(std::nothrow) SyscallTracing::PostSyscall(syscallNumber,
  Line 613 [new]: new(&sFilter) SyscallWrapperTraceFilter;
  Line 144 [user_memcpy]: if (user_memcpy(&requestedVersion, buffer, sizeof(uint32)) != B_OK)
  Line 150 [user_memcpy]: return user_memcpy(buffer, &syscall->version, sizeof(uint32));
  Line 445 [panic]: panic("syscall return value 64 bit although it should be 32 "
  Line 285 [TODO]: // TODO: we should only remove the syscall with the matching version
  Line 516 [dynamic_cast]: if (const PreSyscall* entry = dynamic_cast<const PreSyscall*>(_entry)) {
  Line 525 [dynamic_cast]: = dynamic_cast<const PostSyscall*>(_entry)) {
  Line 531 [dynamic_cast]: = dynamic_cast<const AbstractTraceEntry*>(_entry)) {

File: src/system/kernel/system_info.cpp
  Line 127 [new]: // just add the new flags
  Line 132 [new]: // create a new listener
  Line 133 [new]: listener = new(std::nothrow) Listener;
  Line 142 [new]: // if there's no list yet, create a new list
  Line 144 [new]: listenerList = new(std::nothrow) ListenerList;
  Line 560 [new]: new (&sSystemNotificationService) SystemNotificationService;
  Line 630 [new]: = new(std::nothrow) cpu_topology_node_info[count];
  Line 539 [user_memcpy]: if (user_memcpy(info, localInfo, sizeof(cpu_info) * localIdx) != B_OK)
  Line 584 [user_memcpy]: if (user_memcpy(userInfo, &info, sizeof(system_info)) < B_OK)
  Line 617 [user_memcpy]: return user_memcpy(topologyInfoCount, &count, sizeof(uint32));
  Line 622 [user_memcpy]: status_t error = user_memcpy(&userCount, topologyInfoCount, sizeof(uint32));
  Line 640 [user_memcpy]: error = user_memcpy(topologyInfos, topology,
  Line 644 [user_memcpy]: return user_memcpy(topologyInfoCount, &count, sizeof(uint32));
  Line 564 [panic]: panic("system_info_init(): Failed to init system notification service");

File: src/system/kernel/team.cpp
  Line 241 [strcpy]: fPath = alloc_tracing_buffer_strcpy(path, B_PATH_NAME_LENGTH,
  Line 1444 [malloc]: char** flatArgs = (char**)malloc(_ALIGN(flatArgsSize));
  Line 1503 [malloc]: struct team_arg* teamArg = (struct team_arg*)malloc(sizeof(team_arg));
  Line 2167 [malloc]: forkArgs = (arch_fork_arg*)malloc(sizeof(arch_fork_arg));
  Line 3537 [malloc]: team_watcher* watcher = (team_watcher*)malloc(sizeof(team_watcher));
  Line 3649 [malloc]: = (free_user_thread*)malloc(sizeof(free_user_thread));
  Line 3820 [malloc]: char** flatArgs = (char**)malloc(size);
  Line 225 [new]: out.Print("team forked, new thread %" B_PRId32, fForkedThread);
  Line 308 [new]: SetJobControlState(team_id team, job_control_state newState, Signal* signal)
  Line 311 [new]: fNewState(newState),
  Line 320 [new]: "new state: %s, signal: %d",
  Line 396 [new]: #	define T(x) new(std::nothrow) TeamTracing::x;
  Line 454 [new]: job_control_entry = new(nothrow) ::job_control_entry;
  Line 505 [new]: fQueuedSignalsCounter = new(std::nothrow) BKernel::QueuedSignalsCounter(
  Line 553 [new]: Team* team = new(std::nothrow) Team(id, kernel);
  Line 1685 [new]: return thread_enter_userspace_new_team(thread, (addr_t)entry,
  Line 1786 [new]: // create a new io_context for this team
  Line 1788 [new]: team->io_context = vfs_new_io_context(parentIOContext, true);
  Line 1845 [new]: // Create a kernel thread, but under the context of the new team
  Line 1846 [new]: // The new thread will take over ownership of teamArgs.
  Line 1867 [new]: // wait for the loader of the new team to finish its work
  Line 1965 [new]: /*!	Almost shuts down the current team and loads a new image into it.
  Line 2130 [new]: // create a new team
  Line 2173 [new]: // create a new io_context for this team
  Line 2174 [new]: team->io_context = vfs_new_io_context(parentTeam->io_context, false);
  Line 2206 [new]: // don't clone the user area; just create a new one
  Line 2881 [new]: new(&sTeamHash) TeamTable;
  Line 2885 [new]: new(&sGroupHash) ProcessGroupHashTable;
  Line 2891 [new]: ProcessSession* session = new(std::nothrow) ProcessSession(1);
  Line 2896 [new]: ProcessGroup* group = new(std::nothrow) ProcessGroup(1);
  Line 2922 [new]: sKernelTeam->io_context = vfs_new_io_context(NULL, false);
  Line 2948 [new]: new(&sNotificationService) TeamNotificationService();
  Line 3188 [new]: // we need to send SIGHUP + SIGCONT to all newly-orphaned process
  Line 3260 [new]: // Mark the team as shutting down. That will prevent new threads from being
  Line 3435 [new]: \a newState The new state to be set.
  Line 3436 [new]: \a signal The signal the new state was caused by. Can \c NULL, if none. Then
  Line 3438 [new]: entry before releasing the parent team's lock, unless the new state is
  Line 3444 [new]: team_set_job_control_state(Team* team, job_control_state newState,
  Line 3453 [new]: if (entry->state == newState || entry->state == JOB_CONTROL_STATE_DEAD)
  Line 3456 [new]: T(SetJobControlState(team->id, newState, signal));
  Line 3474 [new]: entry->state = newState;
  Line 3481 [new]: // add to new list
  Line 4126 [new]: // * Create a new process group with the target process' ID and the target
  Line 4142 [new]: // We loop when running into the following race condition: We create a new
  Line 4149 [new]: // allowed to create a new one, do that.
  Line 4151 [new]: bool newGroup = false;
  Line 4156 [new]: group = new(std::nothrow) ProcessGroup(groupID);
  Line 4160 [new]: newGroup = true;
  Line 4180 [new]: // lock the new process group and the team's current process group
  Line 4201 [new]: if (newGroup || group->id > oldGroup->id) {
  Line 4229 [new]: // we now have references and locks of both new and old process group
  Line 4253 [new]: // If we created a new process group, publish it now.
  Line 4254 [new]: if (newGroup) {
  Line 4287 [new]: // create a new process group and session
  Line 4288 [new]: ProcessGroup* group = new(std::nothrow) ProcessGroup(team->id);
  Line 4294 [new]: ProcessSession* session = new(std::nothrow) ProcessSession(group->id);
  Line 4310 [new]: // remove the team from the old and add it to the new process group
  Line 1448 [user_memcpy]: if (user_memcpy(flatArgs, userFlatArgs, flatArgsSize) != B_OK) {
  Line 1593 [user_memcpy]: || user_memcpy(&programArgs->arg_count, &argCount, sizeof(int32)) < B_OK
  Line 1594 [user_memcpy]: || user_memcpy(&programArgs->args, &userArgs, sizeof(char**)) < B_OK
  Line 1595 [user_memcpy]: || user_memcpy(&programArgs->env_count, &envCount, sizeof(int32)) < B_OK
  Line 1596 [user_memcpy]: || user_memcpy(&programArgs->env, &userEnv, sizeof(char**)) < B_OK
  Line 1597 [user_memcpy]: || user_memcpy(&programArgs->error_port, &teamArgs->error_port,
  Line 1599 [user_memcpy]: || user_memcpy(&programArgs->error_token, &teamArgs->error_token,
  Line 1601 [user_memcpy]: || user_memcpy(&programArgs->umask, &teamArgs->umask, sizeof(mode_t)) < B_OK
  Line 1602 [user_memcpy]: || user_memcpy(&programArgs->disable_user_addons,
  Line 1604 [user_memcpy]: || user_memcpy(userArgs, teamArgs->flat_args,
  Line 4087 [user_memcpy]: if (userInfo != NULL && user_memcpy(userInfo, &info, sizeof(info)) != B_OK)
  Line 4090 [user_memcpy]: if (usageInfo != NULL && user_memcpy(usageInfo, &usage_info,
  Line 4334 [user_memcpy]: if (user_memcpy(_userReturnCode, &returnCode, sizeof(returnCode))
  Line 4434 [user_memcpy]: if (user_memcpy(userInfo, &info, size) < B_OK)
  Line 4454 [user_memcpy]: || user_memcpy(&cookie, userCookie, sizeof(int32)) < B_OK)
  Line 4461 [user_memcpy]: if (user_memcpy(userCookie, &cookie, sizeof(int32)) < B_OK
  Line 4462 [user_memcpy]: || user_memcpy(userInfo, &info, size) < B_OK)
  Line 4488 [user_memcpy]: || user_memcpy(userInfo, &info, size) != B_OK) {
  Line 4582 [user_memcpy]: if (user_memcpy(_sizeNeeded, &sizeNeeded, sizeof(sizeNeeded)) != B_OK)
  Line 4588 [user_memcpy]: if (user_memcpy(buffer, info.Buffer(), sizeNeeded) != B_OK)
  Line 2231 [panic]: panic("user data area not found, parent area is %" B_PRId32,
  Line 2442 [panic]: panic("job_control_entry::~job_control_entry(): unknown group "
  Line 2883 [panic]: panic("Failed to init team hash table!");
  Line 2887 [panic]: panic("Failed to init process group hash table!");
  Line 2893 [panic]: panic("Could not create initial session.\n");
  Line 2898 [panic]: panic("Could not create initial process group.\n");
  Line 2906 [panic]: panic("could not create kernel team!\n");
  Line 2924 [panic]: panic("could not create io_context for kernel team!\n");
  Line 1568 [TODO]: // TODO: ENV_SIZE is a) limited, and b) not used after libroot copied it to
  Line 1570 [TODO]: // TODO: we could reserve the whole USER_STACK_REGION upfront...
  Line 1994 [TODO]: // TODO: make the current thread the team's main thread?
  Line 2027 [TODO]: // TODO: remove team resources if there are any left
  Line 2131 [TODO]: // TODO: this is very similar to load_image_internal() - maybe we can do
  Line 2200 [TODO]: // TODO: should be able to handle stack areas differently (ie. don't have
  Line 2643 [TODO]: // TODO: Fill in si_errno?
  Line 2702 [TODO]: // TODO: Set more informations for team_info
  Line 4578 [TODO]: // TODO: Support the other flags!

File: src/system/kernel/thread.cpp
  Line 18 [malloc]: #include <malloc.h>
  Line 1351 [malloc]: data = malloc(bufferSize);
  Line 2160 [malloc]: = (thread_death_entry*)malloc(sizeof(thread_death_entry));
  Line 258 [new]: \param threadID The ID to be assigned to the new thread. If
  Line 367 [new]: Thread* thread = new Thread(name, -1, NULL);
  Line 450 [new]: Thread::operator new(size_t size)
  Line 457 [new]: Thread::operator new(size_t, void* pointer)
  Line 737 [new]: dprintf("Failed to init TLS for new userland thread \"%s\" (%" B_PRId32
  Line 743 [new]: user_debug_update_new_thread_flags(thread);
  Line 793 [new]: thread_enter_userspace_new_team(Thread* thread, addr_t entryFunction,
  Line 816 [new]: // The thread is new and has been scheduled the first time.
  Line 818 [new]: scheduler_new_thread_entry(thread);
  Line 975 [new]: /*!	Creates a new thread.
  Line 981 [new]: \return The ID of the newly created thread (>= 0) or an error code on
  Line 999 [new]: // a new thread object with the given attributes.
  Line 1098 [new]: // If the new thread belongs to the same team as the current thread, it
  Line 1114 [new]: // stop the new thread, if desired
  Line 1155 [new]: // Debug the new thread, if the parent thread required that (see above),
  Line 2825 [new]: new(&sThreadHash) ThreadHashTable();
  Line 2849 [new]: thread = new(&sIdleThreads[i]) Thread(name,
  Line 2879 [new]: new(&sNotificationService) ThreadNotificationService();
  Line 2884 [new]: new(&sUndertakerEntries) DoublyLinkedList<UndertakerEntry>();
  Line 2956 [new]: "  <priority>  - The thread's new priority (0 - 120)\n"
  Line 3643 [new]: _user_set_thread_priority(thread_id thread, int32 newPriority)
  Line 3645 [new]: return thread_set_thread_priority(thread, newPriority, false);
  Line 664 [user_memcpy]: || user_memcpy((thread_creation_attributes*)this, userAttributes,
  Line 764 [user_memcpy]: if (user_memcpy((void*)thread->user_local_storage, tls, sizeof(tls)) != B_OK)
  Line 1355 [user_memcpy]: if (user_memcpy(data, buffer, bufferSize) != B_OK) {
  Line 1408 [user_memcpy]: status = user_memcpy(buffer, thread->msg.buffer, size);
  Line 3133 [user_memcpy]: if (user_memcpy(&waitStatus, &thread->user_thread->wait_status,
  Line 3138 [user_memcpy]: if (user_memcpy(&thread->user_thread->wait_status, &status,
  Line 3732 [user_memcpy]: || user_memcpy(userRemainingTime, &remainingTime,
  Line 3771 [user_memcpy]: && user_memcpy(userInfo, &info, sizeof(thread_info)) < B_OK)
  Line 3787 [user_memcpy]: || user_memcpy(&cookie, userCookie, sizeof(int32)) < B_OK)
  Line 3794 [user_memcpy]: if (user_memcpy(userCookie, &cookie, sizeof(int32)) < B_OK
  Line 3795 [user_memcpy]: || user_memcpy(userInfo, &info, sizeof(thread_info)) < B_OK)
  Line 3832 [user_memcpy]: && user_memcpy(userReturnCode, &returnCode, sizeof(status_t)) < B_OK) {
  Line 3875 [user_memcpy]: if (user_memcpy(_userSender, &sender, sizeof(thread_id)) < B_OK)
  Line 3893 [user_memcpy]: if (user_memcpy(&waitStatus, &thread->user_thread->wait_status,
  Line 3919 [user_memcpy]: if (user_memcpy(&oldStatus, &thread->user_thread->wait_status,
  Line 3924 [user_memcpy]: if (user_memcpy(&thread->user_thread->wait_status, &status,
  Line 3963 [user_memcpy]: if (user_memcpy(threads, userThreads, count * sizeof(thread_id)) != B_OK)
  Line 3993 [user_memcpy]: ret = user_memcpy(urlp, &rl, sizeof(struct rlimit));
  Line 4013 [user_memcpy]: || user_memcpy(&resourceLimit, userResourceLimit,
  Line 4050 [user_memcpy]: if (user_memcpy(userMask, &mask, min_c(sizeof(mask), size)) < B_OK)
  Line 4066 [user_memcpy]: if (user_memcpy(&mask, userMask, min_c(sizeof(CPUSet), size)) < B_OK)
  Line 179 [panic]: // panic("out of cached stacks!");
  Line 1503 [panic]: panic("common_snooze_etc(): called with interrupts disabled, timeout "
  Line 2108 [panic]: panic("thread_exit() called with interrupts disabled!\n");
  Line 2431 [panic]: panic("never can get here\n");
  Line 2682 [panic]: panic("could acquire exit_sem for thread %" B_PRId32 "\n", id);
  Line 2827 [panic]: panic("thread_init(): failed to init thread hash table!");
  Line 2834 [panic]: panic("thread_init(): failed to allocate thread object cache!");
  Line 2837 [panic]: panic("arch_thread_init() failed!\n");
  Line 2852 [panic]: panic("error creating idle thread struct\n");
  Line 2866 [panic]: panic("error finding idle kstack area\n");
  Line 2890 [panic]: panic("Failed to create undertaker thread!");
  Line 1719 [TODO]: // TODO: This is a non-trivial syscall doing some locking, so this is
  Line 3975 [TODO]: // TODO: the following two functions don't belong here

File: src/system/kernel/timer.cpp
  Line 283 [new]: // If the new schedule time is a full interval or more in the past,
  Line 214 [panic]: panic("arch_init_timer() failed");
  Line 418 [FIXME]: // FIXME: Theoretically we should be able to skip this if (previous == NULL).

File: src/system/kernel/usergroup.cpp
  Line 225 [malloc]: newGroups = (BKernel::GroupsArray*)malloc(sizeof(BKernel::GroupsArray)
  Line 13 [new]: #include <new>
  Line 223 [new]: BKernel::GroupsArray* newGroups = NULL;
  Line 225 [new]: newGroups = (BKernel::GroupsArray*)malloc(sizeof(BKernel::GroupsArray)
  Line 227 [new]: if (newGroups == NULL)
  Line 229 [new]: new(newGroups) BKernel::GroupsArray;
  Line 232 [new]: memcpy(newGroups->groups, groupList, sizeof(gid_t) * groupCount);
  Line 235 [new]: || user_memcpy(newGroups->groups, groupList, sizeof(gid_t) * groupCount) != B_OK) {
  Line 236 [new]: free(newGroups);
  Line 240 [new]: newGroups->count = groupCount;
  Line 248 [new]: team->supplementary_groups.SetTo(newGroups, true);
  Line 207 [user_memcpy]: || user_memcpy(groupList, groups,
  Line 235 [user_memcpy]: || user_memcpy(newGroups->groups, groupList, sizeof(gid_t) * groupCount) != B_OK) {
  Line 415 [user_memcpy]: || user_memcpy(rgid, &team->real_gid, sizeof(uid_t)) != B_OK) {
  Line 421 [user_memcpy]: || user_memcpy(egid, &team->effective_gid, sizeof(uid_t)) != B_OK) {
  Line 427 [user_memcpy]: || user_memcpy(ssgid, &team->saved_set_gid, sizeof(uid_t)) != B_OK) {
  Line 441 [user_memcpy]: || user_memcpy(ruid, &team->real_uid, sizeof(uid_t)) != B_OK) {
  Line 447 [user_memcpy]: || user_memcpy(euid, &team->effective_uid, sizeof(uid_t)) != B_OK) {
  Line 453 [user_memcpy]: || user_memcpy(ssuid, &team->saved_set_uid, sizeof(uid_t)) != B_OK) {

File: src/system/kernel/util/AVLTreeBase.cpp
  Line 15 [panic]: #	define CHECK_FAILED(message...)	panic(message)

File: src/system/kernel/util/Bitmap.cpp
  Line 83 [TODO]: // TODO: optimize
  Line 92 [TODO]: // TODO: optimize
  Line 101 [TODO]: // TODO: optimize
  Line 114 [TODO]: // TODO: optimize

File: src/system/kernel/util/RadixBitmap.cpp
  Line 171 [malloc]: radix_bitmap *bmp = (radix_bitmap *)malloc(sizeof(radix_bitmap));
  Line 185 [malloc]: bmp->root = (radix_node *)malloc(bmp->root_size * sizeof(radix_node));
  Line 77 [panic]: *	BLIST_BMAP_RADIX blocks per call.  It will panic with 'allocation too
  Line 91 [panic]: *  3. allocate more than 32 slots won't lead to kernel panic

File: src/system/kernel/util/kernel_cpp.cpp
  Line 93 [malloc]: return malloc(size);
  Line 100 [malloc]: return malloc(size);
  Line 107 [malloc]: return malloc(size);
  Line 114 [malloc]: return malloc(size);
  Line 121 [malloc]: return malloc(size);
  Line 128 [malloc]: return malloc(size);
  Line 88 [new]: operator new(size_t size) _THROW(std::bad_alloc)
  Line 91 [new]: // keep the prototype as specified in <new>, or else GCC 3
  Line 98 [new]: operator new[](size_t size)
  Line 105 [new]: operator new(size_t size, const std::nothrow_t &) _NOEXCEPT
  Line 112 [new]: operator new[](size_t size, const std::nothrow_t &) _NOEXCEPT
  Line 119 [new]: operator new(size_t size, const mynothrow_t &) _NOEXCEPT
  Line 126 [new]: operator new[](size_t size, const mynothrow_t &) _NOEXCEPT
  Line 24 [panic]: #	define panic printf
  Line 59 [panic]: panic("pure virtual function call\n");
  Line 67 [panic]: panic("pure virtual function call\n");
  Line 234 [panic]: panic("_Unwind_DeleteException");
  Line 241 [panic]: panic("_Unwind_Find_FDE");
  Line 249 [panic]: panic("_Unwind_GetDataRelBase");
  Line 256 [panic]: panic("_Unwind_GetGR");
  Line 263 [panic]: panic("_Unwind_GetIP");
  Line 270 [panic]: panic("_Unwind_GetIPInfo");
  Line 277 [panic]: panic("_Unwind_GetLanguageSpecificData");
  Line 284 [panic]: panic("_Unwind_GetRegionStart");
  Line 291 [panic]: panic("_Unwind_GetTextRelBase");
  Line 298 [panic]: panic("_Unwind_RaiseException");
  Line 305 [panic]: panic("_Unwind_Resume");
  Line 312 [panic]: panic("_Unwind_Resume_or_Rethrow");
  Line 319 [panic]: panic("_Unwind_SetGR");
  Line 326 [panic]: panic("_Unwind_SetIP");
  Line 333 [panic]: panic("__deregister_frame_info");
  Line 340 [panic]: panic("__register_frame_info");
  Line 347 [panic]: panic("__aeabi_unwind_cpp_pr0");
  Line 353 [panic]: panic("__aeabi_unwind_cpp_pr1");
  Line 359 [panic]: panic("__aeabi_unwind_cpp_pr2");
  Line 365 [panic]: panic("_Unwind_Complete");
  Line 371 [panic]: panic("_Unwind_VRS_Set");
  Line 377 [panic]: panic("_Unwind_VRS_Get");
  Line 383 [panic]: panic("__gnu_unwind_frame");
  Line 393 [panic]: panic("abort() called!");
  Line 416 [panic]: panic("exit() called with status code = %d!", status);
  Line 179 [TODO]: // TODO: Introduce a vdprintf()...
  Line 213 [TODO]: // TODO: Introduce a vdprintf()...

File: src/system/kernel/util/queue.cpp
  Line 10 [malloc]: #include <malloc.h>
  Line 116 [malloc]: q->table = (void**)malloc(size * sizeof(void *));

File: src/system/kernel/util/ring_buffer.cpp
  Line 27 [malloc]: *	They also don't use malloc() or any kind of locking after initialization.
  Line 181 [malloc]: ring_buffer* buffer = (ring_buffer*)malloc(sizeof(ring_buffer) + size);
  Line 19 [user_memcpy]: #define user_memcpy(x...) (memcpy(x), B_OK)
  Line 55 [user_memcpy]: if (user_memcpy(data, buffer->buffer + buffer->first, length) < B_OK)
  Line 65 [user_memcpy]: if (user_memcpy(data, buffer->buffer + buffer->first, upper) < B_OK
  Line 66 [user_memcpy]: || user_memcpy(data + upper, buffer->buffer, lower) < B_OK)
  Line 101 [user_memcpy]: if (user_memcpy(buffer->buffer + position, data, length) < B_OK)
  Line 111 [user_memcpy]: if (user_memcpy(buffer->buffer + position, data, upper) < B_OK
  Line 112 [user_memcpy]: || user_memcpy(buffer->buffer, data + upper, lower) < B_OK)
  Line 144 [user_memcpy]: if (user_memcpy(data, buffer->buffer + offset, length) < B_OK)
  Line 154 [user_memcpy]: if (user_memcpy(data, buffer->buffer + offset, upper) < B_OK
  Line 155 [user_memcpy]: || user_memcpy((uint8*)data + upper, buffer->buffer, lower) < B_OK)
  Line 395 [write_port]: status = write_port_etc(port, code, buffer->buffer + buffer->first, length,

File: src/system/kernel/vm/VMAddressSpace.cpp
  Line 15 [new]: #include <new>
  Line 124 [new]: new(&sAddressSpaceTable) AddressSpaceTable;
  Line 190 [new]: ? (VMAddressSpace*)new(std::nothrow) VMKernelAddressSpace(teamID, base,
  Line 192 [new]: : (VMAddressSpace*)new(std::nothrow) VMUserAddressSpace(teamID, base,
  Line 127 [panic]: panic("vm_init: error creating aspace hash table\n");
  Line 133 [panic]: panic("vm_init: error creating kernel address space!\n");

File: src/system/kernel/vm/VMAddressSpaceLocking.cpp
  Line 505 [new]: originalItems = new(nothrow) lock_item[fCount];

File: src/system/kernel/vm/VMAnonymousCache.cpp
  Line 417 [malloc]: allocation = malloc(size);
  Line 1016 [malloc]: ? new(malloc_flags(HEAP_PRIORITY_VIP)) WriteCallback(this, _callback)
  Line 228 [new]: #	define T(x) new(std::nothrow) SwapTracing::x;
  Line 446 [new]: void SetTo(page_num_t pageIndex, swap_addr_t slotIndex, bool newSlot)
  Line 450 [new]: fNewSlot = newSlot;
  Line 539 [new]: fNoSwapPages = new(std::nothrow) Bitmap(0);
  Line 595 [new]: // not an option as 1. unlocking the cache means that new
  Line 629 [new]: VMAnonymousCache::Resize(off_t newSize, int priority)
  Line 632 [new]: if (fNoSwapPages->Resize(PAGE_ALIGN(newSize) >> PAGE_SHIFT) != B_OK)
  Line 638 [new]: status_t status = VMCache::Resize(newSize, priority);
  Line 642 [new]: _FreeSwapPageRange(newSize + B_PAGE_SIZE - 1,
  Line 650 [new]: VMAnonymousCache::Rebase(off_t newBase, int priority)
  Line 653 [new]: const ssize_t sizeDifference = (newBase >> PAGE_SHIFT) - (virtual_base >> PAGE_SHIFT);
  Line 659 [new]: status_t status = VMCache::Rebase(newBase, priority);
  Line 663 [new]: _FreeSwapPageRange(oldVirtualBase, newBase);
  Line 686 [new]: off_t newOffset)
  Line 695 [new]: off_t pageIndex = newOffset >> PAGE_SHIFT;
  Line 780 [new]: status_t status = VMCache::Adopt(source, offset, size, newOffset);
  Line 784 [new]: uint32 newPages = page_count - initialPageCount;
  Line 785 [new]: off_t pagesCommitment = newPages * B_PAGE_SIZE;
  Line 999 [new]: bool newSlot = slotIndex == SWAP_SLOT_NONE;
  Line 1002 [new]: if (newSlot) {
  Line 1016 [new]: ? new(malloc_flags(HEAP_PRIORITY_VIP)) WriteCallback(this, _callback)
  Line 1017 [new]: : new(std::nothrow) WriteCallback(this, _callback);
  Line 1019 [new]: if (newSlot) {
  Line 1032 [new]: callback->SetTo(pageIndex, slotIndex, newSlot);
  Line 1573 [new]: swap_file* swap = new(std::nothrow) swap_file;
  Line 291 [panic]: panic("swap_slot_alloc(): no swap file in the system\n");
  Line 319 [panic]: panic("swap_slot_alloc: swap space exhausted!\n");
  Line 349 [panic]: panic("find_swap_file(): can't find swap file for slot %" B_PRIu32 "\n",
  Line 690 [panic]: panic("VMAnonymousCache::Adopt(): adopt from incompatible cache %p "
  Line 933 [panic]: panic("VMAnonymousCache::Write(): can't allocate swap space\n");
  Line 1126 [panic]: panic("VMAnonymousCache::Merge(): merge with incompatible cache "
  Line 1675 [panic]: panic("swap_init(): can't create object cache for swap blocks\n");
  Line 1680 [panic]: panic("swap_init(): object_cache_set_minimum_reserve() failed: %s",
  Line 1691 [panic]: panic("swap_init(): Failed to register swap hash resizer: %s",
  Line 868 [TODO]: // TODO: Assumes that only one page is read.
  Line 936 [TODO]: // TODO: Assumes that only one page is written.
  Line 991 [TODO]: // TODO: Currently this method is only used for single pages. Either make
  Line 1029 [TODO]: // TODO: If the page already had swap space assigned, we don't need an own
  Line 1478 [TODO]: // TODO: This can be removed if we get BFS uuid's
  Line 1649 [TODO]: // TODO: mark this swap file deleting, and remove it after releasing
  Line 1732 [TODO]: // TODO: Some kind of BFS uuid would be great here :)
  Line 688 [dynamic_cast]: VMAnonymousCache* source = dynamic_cast<VMAnonymousCache*>(_source);
  Line 1124 [dynamic_cast]: VMAnonymousCache* source = dynamic_cast<VMAnonymousCache*>(_source);
  Line 1894 [dynamic_cast]: VMAnonymousCache* cache = dynamic_cast<VMAnonymousCache*>(page->Cache());

File: src/system/kernel/vm/VMAnonymousCache.h
  Line 45 [new]: virtual	status_t			Resize(off_t newSize, int priority);
  Line 46 [new]: virtual	status_t			Rebase(off_t newBase, int priority);
  Line 48 [new]: off_t size, off_t newOffset);
  Line 19 [TODO]: // TODO: Should be wider, but RadixBitmap supports only a 32 bit type ATM!

File: src/system/kernel/vm/VMAnonymousNoSwapCache.cpp
  Line 63 [new]: off_t newOffset)
  Line 66 [new]: status_t status = VMCache::Adopt(from, offset, size, newOffset);
  Line 70 [new]: uint32 newPages = page_count - initialPageCount;
  Line 71 [new]: off_t pagesCommitment = newPages * B_PAGE_SIZE;
  Line 148 [panic]: panic("anonymous_store: read called. Invalid!\n");
  Line 213 [panic]: panic("VMAnonymousNoSwapCache::Merge(): merge with incompatible "
  Line 211 [dynamic_cast]: = dynamic_cast<VMAnonymousNoSwapCache*>(_source);

File: src/system/kernel/vm/VMAnonymousNoSwapCache.h
  Line 26 [new]: off_t newOffset);

File: src/system/kernel/vm/VMArea.cpp
  Line 13 [new]: #include <new>
  Line 38 [new]: new (&mappings) VMAreaMappings;
  Line 208 [new]: new(&sTree) VMAreasTree;
  Line 135 [panic]: panic("VMArea::Unwire(%#" B_PRIxADDR ", %#" B_PRIxADDR ", %d): no such "
  Line 230 [TODO]: // TODO: Iterating through the whole table can be very slow and the whole

File: src/system/kernel/vm/VMCache.cpp
  Line 341 [new]: fCacheRef = new(gCacheRefObjectCache, allocationFlags) VMCacheRef(this);
  Line 773 [new]: // If we don't have enough committed space to cover through to the new end
  Line 853 [new]: VMCache::Resize(off_t newSize, int priority)
  Line 855 [new]: TRACE(("VMCache::Resize(cache %p, newSize %" B_PRIdOFF ") old size %"
  Line 856 [new]: B_PRIdOFF "\n", this, newSize, this->virtual_end));
  Line 857 [new]: T(Resize(this, newSize));
  Line 863 [new]: if (newSize > (off_t)((uint64)((page_num_t)-1) << PAGE_SHIFT))
  Line 865 [new]: page_num_t newPageCount = (page_num_t)((newSize + B_PAGE_SIZE - 1)
  Line 868 [new]: if (newPageCount < oldPageCount) {
  Line 869 [new]: // Remove all pages in the cache outside of the new virtual size.
  Line 870 [new]: while (_FreePageRange(pages.GetIterator(newPageCount, true, true)))
  Line 873 [new]: if (newSize < virtual_end && newPageCount > 0) {
  Line 875 [new]: uint32 partialBytes = newSize % B_PAGE_SIZE;
  Line 877 [new]: vm_page* page = LookupPage(newSize - partialBytes);
  Line 886 [new]: status_t status = Commit(PAGE_ALIGN(newSize - virtual_base), priority);
  Line 891 [new]: virtual_end = newSize;
  Line 905 [new]: VMCache::Rebase(off_t newBase, int priority)
  Line 907 [new]: TRACE(("VMCache::Rebase(cache %p, newBase %lld) old base %lld\n",
  Line 908 [new]: this, newBase, this->virtual_base));
  Line 909 [new]: T(Rebase(this, newBase));
  Line 913 [new]: page_num_t basePage = (page_num_t)(newBase >> PAGE_SHIFT);
  Line 915 [new]: if (newBase > virtual_base) {
  Line 916 [new]: // Remove all pages in the cache outside of the new virtual base.
  Line 922 [new]: status_t status = Commit(PAGE_ALIGN(virtual_end - newBase), priority);
  Line 927 [new]: virtual_base = newBase;
  Line 936 [new]: VMCache::Adopt(VMCache* source, off_t offset, off_t size, off_t newOffset)
  Line 940 [new]: off_t offsetChange = newOffset - offset;
  Line 1245 [new]: // The remaining consumer has got a new source.
  Line 1247 [new]: VMCache* newSource = source;
  Line 1249 [new]: newSource->Lock();
  Line 1251 [new]: newSource->consumers.Remove(this);
  Line 1252 [new]: newSource->consumers.Add(consumer);
  Line 1253 [new]: consumer->source = newSource;
  Line 1256 [new]: newSource->Unlock();
  Line 217 [panic]: panic("vm_cache_init(): Failed to create object caches!");
  Line 366 [panic]: panic("cache %p to be deleted still has areas", this);
  Line 368 [panic]: panic("cache %p to be deleted still has consumers", this);
  Line 376 [panic]: panic("remove page %p from cache %p: page still has mappings!\n"
  Line 467 [panic]: panic("page %p not in cache %p\n", page, this);
  Line 485 [panic]: panic("insert page %p into cache %p: page cache is set to %p\n",
  Line 496 [panic]: panic("VMCache::InsertPage(): there's already page %p with cache "
  Line 520 [panic]: panic("remove page %p from cache %p: page cache is set to %p\n", page,
  Line 823 [panic]: // Note: This prevents a panic here, but if the page remains wired
  Line 824 [panic]: // when the cache is destroyed, VMCache::Delete() will still panic.
  Line 818 [TODO]: // TODO: Find a real solution! If the page is wired
  Line 93 [dynamic_cast]: if (InsertArea* insertAreaEntry = dynamic_cast<InsertArea*>(entry)) {
  Line 114 [dynamic_cast]: if (Create* createEntry = dynamic_cast<Create*>(entry)) {
  Line 117 [dynamic_cast]: } else if (AddConsumer* addEntry = dynamic_cast<AddConsumer*>(entry)) {

File: src/system/kernel/vm/VMCacheFactory.cpp
  Line 41 [new]: = new(gAnonymousCacheObjectCache, allocationFlags) VMAnonymousCache;
  Line 60 [new]: = new(gAnonymousNoSwapCacheObjectCache, allocationFlags)
  Line 87 [new]: = new(gVnodeCacheObjectCache, allocationFlags) VMVnodeCache;
  Line 112 [new]: = new(gDeviceCacheObjectCache, allocationFlags) VMDeviceCache;
  Line 138 [new]: = new(gNullCacheObjectCache, allocationFlags) VMNullCache;

File: src/system/kernel/vm/VMDeviceCache.cpp
  Line 27 [panic]: panic("device_store: read called. Invalid!\n");

File: src/system/kernel/vm/VMKernelAddressSpace.cpp
  Line 102 [new]: fFreeLists = new(std::nothrow) RangeFreeList[fFreeListCount];
  Line 106 [new]: Range* range = new(fRangesObjectCache, 0) Range(fBase, size,
  Line 244 [new]: VMKernelAddressSpace::CanResizeArea(VMArea* area, size_t newSize)
  Line 248 [new]: if (newSize <= range->size)
  Line 262 [new]: return newSize - range->size <= nextRange->size;
  Line 267 [new]: VMKernelAddressSpace::ResizeArea(VMArea* _area, size_t newSize,
  Line 271 [new]: newSize);
  Line 276 [new]: if (newSize == range->size)
  Line 281 [new]: if (newSize < range->size) {
  Line 285 [new]: nextRange->size += range->size - newSize;
  Line 286 [new]: nextRange->base = range->base + newSize;
  Line 289 [new]: // no free range following -- we need to allocate a new one and
  Line 291 [new]: nextRange = new(fRangesObjectCache, allocationFlags) Range(
  Line 292 [new]: range->base + newSize, range->size - newSize,
  Line 306 [new]: size_t sizeDiff = newSize - range->size;
  Line 319 [new]: nextRange->base = range->base + newSize;
  Line 325 [new]: range->size = newSize;
  Line 326 [new]: area->SetSize(newSize);
  Line 335 [new]: VMKernelAddressSpace::ShrinkAreaHead(VMArea* _area, size_t newSize,
  Line 339 [new]: newSize);
  Line 344 [new]: if (newSize == range->size)
  Line 347 [new]: if (newSize > range->size)
  Line 352 [new]: size_t sizeDiff = range->size - newSize;
  Line 359 [new]: range->size = newSize;
  Line 361 [new]: // no free range before -- we need to allocate a new one and
  Line 363 [new]: previousRange = new(fRangesObjectCache, allocationFlags) Range(
  Line 368 [new]: range->size = newSize;
  Line 382 [new]: VMKernelAddressSpace::ShrinkAreaTail(VMArea* area, size_t newSize,
  Line 385 [new]: return ResizeArea(area, newSize, allocationFlags);
  Line 656 [new]: Range* leftOverRange = new(fRangesObjectCache, allocationFlags)
  Line 666 [new]: Range* leftOverRange = new(fRangesObjectCache, allocationFlags) Range(
  Line 676 [new]: Range* leftOverRange1 = new(fRangesObjectCache, allocationFlags) Range(
  Line 680 [new]: Range* leftOverRange2 = new(fRangesObjectCache, allocationFlags) Range(
  Line 82 [panic]: panic("deleting the kernel aspace!\n");
  Line 893 [panic]: panic("VMKernelAddressSpace::_CheckStructures(): list/tree range "
  Line 900 [panic]: panic("VMKernelAddressSpace::_CheckStructures(): range base %#"
  Line 905 [panic]: panic("VMKernelAddressSpace::_CheckStructures(): empty range %p",
  Line 910 [panic]: panic("VMKernelAddressSpace::_CheckStructures(): range %p (%#"
  Line 916 [panic]: panic("VMKernelAddressSpace::_CheckStructures(): range too large: "
  Line 925 [panic]: panic("VMKernelAddressSpace::_CheckStructures(): adjoining "
  Line 939 [panic]: panic("VMKernelAddressSpace::_CheckStructures(): space not fully "
  Line 954 [panic]: panic("VMKernelAddressSpace::_CheckStructures(): non-free "
  Line 961 [panic]: panic("VMKernelAddressSpace::_CheckStructures(): unknown "
  Line 968 [panic]: panic("VMKernelAddressSpace::_CheckStructures(): "
  Line 260 [TODO]: // TODO: If there is free space after a reserved range (or vice versa), it
  Line 304 [TODO]: // TODO: If there is free space after a reserved range (or vice versa),
  Line 804 [TODO]: // TODO: Support allocating if the area range covers multiple

File: src/system/kernel/vm/VMKernelAddressSpace.h
  Line 42 [new]: virtual	bool				CanResizeArea(VMArea* area, size_t newSize);
  Line 43 [new]: virtual	status_t			ResizeArea(VMArea* area, size_t newSize,
  Line 45 [new]: virtual	status_t			ShrinkAreaHead(VMArea* area, size_t newSize,
  Line 47 [new]: virtual	status_t			ShrinkAreaTail(VMArea* area, size_t newSize,

File: src/system/kernel/vm/VMKernelArea.cpp
  Line 32 [new]: VMKernelArea* area = new(objectCache, allocationFlags) VMKernelArea(

File: src/system/kernel/vm/VMPageQueue.cpp
  Line 16 [new]: new(&fPages) PageList;

File: src/system/kernel/vm/VMPageQueue.h
  Line 74 [panic]: panic("%p->VMPageQueue::Append(page: %p): page thinks it is "
  Line 93 [panic]: panic("%p->VMPageQueue::Prepend(page: %p): page thinks it is "
  Line 112 [panic]: panic("%p->VMPageQueue::InsertAfter(page: %p): page thinks it is "
  Line 131 [panic]: panic("%p->VMPageQueue::Remove(page: %p): page thinks it "
  Line 154 [panic]: panic("%p->VMPageQueue::RemoveHead(): page %p thinks it is in "
  Line 171 [panic]: panic("%p->VMPageQueue::Requeue(): page %p thinks it is in "
  Line 196 [panic]: panic("%p->VMPageQueue::AppendUnlocked(): page %p thinks it is "

File: src/system/kernel/vm/VMTranslationMap.cpp
  Line 125 [panic]: panic("page %p has mapping for area %p (%#" B_PRIxADDR "), but "
  Line 130 [panic]: panic("unmapping page %p for area %p (%#" B_PRIxADDR ") failed: %x",

File: src/system/kernel/vm/VMUserAddressSpace.cpp
  Line 232 [new]: VMUserAddressSpace::CanResizeArea(VMArea* area, size_t newSize)
  Line 234 [new]: const addr_t newEnd = area->Base() + (newSize - 1);
  Line 235 [new]: if (newEnd < area->Base())
  Line 240 [new]: if (next->Base() > newEnd)
  Line 246 [new]: if ((next->Base() + (next->Size() - 1)) >= newEnd)
  Line 254 [new]: return fEndAddress >= newEnd;
  Line 259 [new]: VMUserAddressSpace::ResizeArea(VMArea* _area, size_t newSize,
  Line 265 [new]: const addr_t newEnd = area->Base() + (newSize - 1);
  Line 268 [new]: if (oldEnd < newEnd) {
  Line 270 [new]: if (next->Base() > newEnd)
  Line 273 [new]: if (next->id != RESERVED_AREA_ID && next->Base() < newEnd) {
  Line 280 [new]: addr_t offset = (area->Base() + newSize) - next->Base();
  Line 301 [new]: addr_t newNextBase = oldNextBase - (oldEnd - newEnd);
  Line 302 [new]: if (newNextBase < (addr_t)next->cache_offset)
  Line 303 [new]: newNextBase = next->cache_offset;
  Line 305 [new]: next->SetBase(newNextBase);
  Line 306 [new]: next->SetSize(next->Size() + (oldNextBase - newNextBase));
  Line 310 [new]: area->SetSize(newSize);
  Line 419 [new]: // We create a new area for the tail, starting at endAddress + 1.
  Line 421 [new]: VMUserArea* newArea = VMUserArea::CreateReserved(this,
  Line 423 [new]: if (newArea == NULL)
  Line 431 [new]: // Configure new area (tail)
  Line 432 [new]: newArea->SetBase(endAddress + 1);
  Line 433 [new]: newArea->SetSize(areaEnd - endAddress);
  Line 434 [new]: newArea->cache_offset = newArea->Base();
  Line 436 [new]: fAreas.Insert(newArea);
  Line 552 [new]: // range to the new area - and remove, resize or split the old
  Line 559 [new]: // the new area fully covers the reserved range
  Line 575 [new]: // we need a new reserved area to cover this space
  Line 576 [new]: VMUserArea* newReserved = VMUserArea::CreateReserved(this,
  Line 578 [new]: if (newReserved == NULL)
  Line 584 [new]: newReserved->SetBase(start + size);
  Line 585 [new]: newReserved->SetSize(
  Line 587 [new]: newReserved->cache_offset = reserved->cache_offset;
  Line 591 [new]: fAreas.Insert(newReserved);
  Line 681 [new]: // find a hole big enough for a new area
  Line 801 [new]: // The new area will be placed at the beginning of the
  Line 813 [new]: // The new area will be placed at the end of the
  Line 274 [panic]: panic("resize situation for area %p has changed although we "
  Line 627 [TODO]: // TODO: this could be further optimized.
  Line 765 [TODO]: // TODO: it would make sense to start with the biggest of them
  Line 775 [TODO]: // TODO: take free space after the reserved area into

File: src/system/kernel/vm/VMUserAddressSpace.h
  Line 37 [new]: virtual	bool				CanResizeArea(VMArea* area, size_t newSize);
  Line 38 [new]: virtual	status_t			ResizeArea(VMArea* area, size_t newSize,
  Line 40 [new]: virtual	status_t			ShrinkAreaHead(VMArea* area, size_t newSize,
  Line 42 [new]: virtual	status_t			ShrinkAreaTail(VMArea* area, size_t newSize,

File: src/system/kernel/vm/VMUserArea.cpp
  Line 30 [malloc]: VMUserArea* area = new(malloc_flags(allocationFlags)) VMUserArea(
  Line 49 [malloc]: VMUserArea* area = new(malloc_flags(allocationFlags)) VMUserArea(
  Line 30 [new]: VMUserArea* area = new(malloc_flags(allocationFlags)) VMUserArea(
  Line 49 [new]: VMUserArea* area = new(malloc_flags(allocationFlags)) VMUserArea(

File: src/system/kernel/vm/vm.cpp
  Line 527 [malloc]: area->page_protections = (uint8*)malloc_etc(bytes,
  Line 2937 [malloc]: targetPageProtections = (uint8*)malloc_etc(bytes,
  Line 5340 [malloc]: uint32 mallocFlags = isUser
  Line 5377 [malloc]: VMAreaWiredRange* range = new(malloc_flags(mallocFlags))
  Line 5452 [malloc]: free_etc(range, mallocFlags);
  Line 5499 [malloc]: uint32 mallocFlags = isUser
  Line 5552 [malloc]: free_etc(range, mallocFlags);
  Line 5595 [malloc]: free_etc(range, mallocFlags);
  Line 395 [new]: #	define TPF(x) new(std::nothrow) VMPageFaultTracing::x;
  Line 414 [new]: sPageMappingsObjectCaches = new object_cache*[count];
  Line 812 [new]: uint8* newProtections = realloc_area_page_protections(
  Line 815 [new]: if (newProtections == NULL) {
  Line 820 [new]: area->page_protections = newProtections;
  Line 843 [new]: const size_t newCommitmentPages = compute_area_page_commitment(area);
  Line 844 [new]: cache->Commit(newCommitmentPages * B_PAGE_SIZE, priority);
  Line 852 [new]: uint8* newProtections = NULL;
  Line 855 [new]: newProtections = realloc_area_page_protections(NULL, area->Size(),
  Line 858 [new]: if (newProtections == NULL)
  Line 866 [new]: free_etc(newProtections, allocationFlags);
  Line 876 [new]: memcpy(newProtections, area->page_protections, bytes);
  Line 878 [new]: area->page_protections = newProtections;
  Line 902 [new]: const size_t newCommitmentPages = compute_area_page_commitment(area);
  Line 903 [new]: cache->Commit(newCommitmentPages * B_PAGE_SIZE, priority);
  Line 911 [new]: // new area for the end section.
  Line 929 [new]: // Try to allocate the new memory before making some hard to reverse
  Line 952 [new]: // Create a new cache for the second area.
  Line 1064 [new]: // We need a cache reference for the new area.
  Line 1258 [new]: // if this is a private map, we need to create a new cache
  Line 1262 [new]: VMCache* newCache;
  Line 1265 [new]: status = VMCacheFactory::CreateAnonymousCache(newCache,
  Line 1272 [new]: newCache->Lock();
  Line 1273 [new]: newCache->temporary = 1;
  Line 1274 [new]: newCache->virtual_base = offset;
  Line 1275 [new]: newCache->virtual_end = offset + size;
  Line 1277 [new]: cache->AddConsumer(newCache);
  Line 1280 [new]: cache = newCache;
  Line 2031 [new]: // modify the pointer returned to be offset back into the new area
  Line 2535 [new]: VMArea* newArea;
  Line 2542 [new]: kernel, &newArea, address);
  Line 2548 [new]: // create a new cache, and has therefore already acquired a reference
  Line 2553 [new]: if (newArea->wiring == B_FULL_LOCK) {
  Line 2568 [new]: size_t reservePages = map->MaxPagesNeededToMap(newArea->Base(),
  Line 2569 [new]: newArea->Base() + (newArea->Size() - 1));
  Line 2577 [new]: for (addr_t offset = 0; offset < newArea->Size();
  Line 2579 [new]: map->Map(newArea->Base() + offset, physicalAddress + offset,
  Line 2580 [new]: protection, newArea->MemoryType(), &reservation);
  Line 2588 [new]: newArea->Base(), newArea->Base() + (newArea->Size() - 1));
  Line 2599 [new]: map_page(newArea, page,
  Line 2600 [new]: newArea->Base() + ((page->cache_offset << PAGE_SHIFT)
  Line 2601 [new]: - newArea->cache_offset),
  Line 2613 [new]: newArea->cache_type = sourceArea->cache_type;
  Line 2614 [new]: return newArea->id;
  Line 2706 [new]: /*!	Creates a new cache on top of given cache, moves all areas from
  Line 2707 [new]: the old cache to the new one, and changes the protection of all affected
  Line 2709 [new]: new cache and copies are added to the old cache in their place.
  Line 2716 [new]: \param lowerCache The cache on top of which a new cache shall be created.
  Line 2728 [new]: // deeper and we create a new cache inbetween.
  Line 2778 [new]: // allocate a new page and copy the wired one
  Line 2984 [new]: const size_t newPageCommitment = compute_area_page_commitment(target);
  Line 2985 [new]: target->cache->Commit(newPageCommitment * B_PAGE_SIZE, VM_PRIORITY_USER);
  Line 2990 [new]: // The new area uses the old area's cache, but map_backing_store()
  Line 3006 [new]: // we return the ID of the newly created area
  Line 3012 [new]: vm_set_area_protection(team_id team, area_id areaID, uint32 newProtection,
  Line 3015 [new]: fix_protection(&newProtection);
  Line 3018 [new]: ", protection = %#" B_PRIx32 ")\n", team, areaID, newProtection));
  Line 3020 [new]: if (!arch_vm_supports_protection(newProtection))
  Line 3024 [new]: = (newProtection & (B_WRITE_AREA | B_KERNEL_WRITE_AREA)) != 0;
  Line 3051 [new]: " (%s)\n", team, newProtection, areaID, area->name);
  Line 3056 [new]: && (newProtection & area->protection_max)
  Line 3057 [new]: != (newProtection & B_USER_PROTECTION)) {
  Line 3061 [new]: "%" B_PRId32 " (%s)\n", team, newProtection,
  Line 3073 [new]: if (area->protection == newProtection)
  Line 3102 [new]: // Assume the existing protections don't match the new ones.
  Line 3132 [new]: if (newProtection
  Line 3141 [new]: // There are consumers -- we have to insert a new cache. Fortunately
  Line 3146 [new]: // No consumers, so we don't need to insert a new one.
  Line 3180 [new]: map->ProtectPage(area, address, newProtection);
  Line 3184 [new]: map->ProtectArea(area, newProtection);
  Line 3189 [new]: area->protection = newProtection;
  Line 3710 [new]: // (Some of the logic here is similar to the new-range code at the end of the method.)
  Line 3727 [new]: // so we want to create a new range with it regardless.
  Line 3793 [new]: // Try starting a new range.
  Line 3890 [new]: // map in the new heap and initialize it
  Line 4052 [new]: bool isUser, addr_t* newIP)
  Line 4063 [new]: *newIP = 0;
  Line 4111 [new]: *newIP = reinterpret_cast<uintptr_t>(thread->fault_handler);
  Line 4321 [new]: // insert the new page into our cache
  Line 4331 [new]: FTRACE(("get new page, copy it, and put it into the topmost cache\n"));
  Line 4348 [new]: // insert the new page into our cache
  Line 4499 [new]: uint32 newProtection = protection;
  Line 4501 [new]: newProtection &= ~(B_WRITE_AREA | B_KERNEL_WRITE_AREA);
  Line 4519 [new]: context.map->ProtectPage(area, address, newProtection);
  Line 4558 [new]: // guaranteed to have that cached locked, our new page is a copy of
  Line 4562 [new]: // (was before the new page was inserted) no other page in any
  Line 4572 [new]: if (map_page(area, context.page, address, newProtection,
  Line 4886 [new]: vm_resize_area(area_id areaID, size_t newSize, bool kernel)
  Line 4888 [new]: // is newSize a multiple of B_PAGE_SIZE?
  Line 4889 [new]: if ((newSize & (B_PAGE_SIZE - 1)) != 0)
  Line 4929 [new]: if (newSize == oldSize)
  Line 4935 [new]: if (oldSize < newSize) {
  Line 4939 [new]: if (!current->address_space->CanResizeArea(current, newSize))
  Line 4957 [new]: current->Base() + newSize, oldSize - newSize, &locker,
  Line 4973 [new]: if (oldSize < newSize) {
  Line 4975 [new]: status = cache->Resize(cache->virtual_base + newSize, priority);
  Line 4982 [new]: status = current->address_space->ResizeArea(current, newSize,
  Line 4987 [new]: // We also need to unmap all pages beyond the new size, if the area has
  Line 4989 [new]: if (newSize < oldSize) {
  Line 4993 [new]: unmap_pages(current, current->Base() + newSize,
  Line 4994 [new]: oldSize - newSize);
  Line 5003 [new]: size_t bytes = area_page_protections_size(newSize);
  Line 5004 [new]: uint8* newProtections
  Line 5006 [new]: if (newProtections == NULL)
  Line 5009 [new]: area->page_protections = newProtections;
  Line 5011 [new]: if (oldSize < newSize) {
  Line 5028 [new]: if (status == B_OK && newSize < oldSize)
  Line 5029 [new]: status = cache->Resize(cache->virtual_base + newSize, priority);
  Line 5356 [new]: // We get a new address space reference here. The one we got above will
  Line 5377 [new]: VMAreaWiredRange* range = new(malloc_flags(mallocFlags))
  Line 5810 [new]: set_area_protection(area_id area, uint32 newProtection)
  Line 5813 [new]: newProtection, true);
  Line 5818 [new]: resize_area(area_id areaID, size_t newSize)
  Line 5820 [new]: return vm_resize_area(areaID, newSize, true);
  Line 5824 [new]: /*!	Transfers the specified area to a new team. The caller must be the owner
  Line 6058 [new]: _user_set_area_protection(area_id area, uint32 newProtection)
  Line 6060 [new]: if ((newProtection & ~(B_USER_PROTECTION | B_CLONEABLE_AREA)) != 0)
  Line 6064 [new]: newProtection, false);
  Line 6069 [new]: _user_resize_area(area_id area, size_t newSize)
  Line 6071 [new]: return vm_resize_area(area, newSize, false);
  Line 6091 [new]: area_id newArea = transfer_area(area, &address, addressSpec, target, false);
  Line 6092 [new]: if (newArea < B_OK)
  Line 6093 [new]: return newArea;
  Line 6098 [new]: return newArea;
  Line 6383 [new]: const bool newNeedsCommitment = (protection & commitProtection) != 0;
  Line 6397 [new]: if (newNeedsCommitment && !nowNeedsCommitment)
  Line 6399 [new]: else if (!newNeedsCommitment && nowNeedsCommitment)
  Line 6404 [new]: off_t newCommitment = topCache->committed_size + commitmentChange;
  Line 6406 [new]: if (newCommitment > topCacheSize) {
  Line 6410 [new]: KDEBUG_ONLY(dprintf("set_memory_protection(area %d): new commitment "
  Line 6412 [new]: newCommitment = (compute_area_page_commitment(area) * B_PAGE_SIZE)
  Line 6415 [new]: status_t status = topCache->Commit(newCommitment, VM_PRIORITY_USER);
  Line 6446 [new]: // the new protection.
  Line 5099 [user_memcpy]: user_memcpy(void* to, const void* from, size_t size)
  Line 5104 [user_memcpy]: if (arch_cpu_user_memcpy(to, from, size) < B_OK)
  Line 5950 [user_memcpy]: || user_memcpy(&address, userAddress, sizeof(address)) != B_OK)
  Line 5959 [user_memcpy]: if (user_memcpy(userAddress, &address, sizeof(address)) != B_OK) {
  Line 6017 [user_memcpy]: if (user_memcpy(userInfo, &info, sizeof(area_info)) < B_OK)
  Line 6031 [user_memcpy]: || user_memcpy(&cookie, userCookie, sizeof(ssize_t)) < B_OK)
  Line 6049 [user_memcpy]: if (user_memcpy(userCookie, &cookie, sizeof(ssize_t)) < B_OK
  Line 6050 [user_memcpy]: || user_memcpy(userInfo, &info, sizeof(area_info)) < B_OK)
  Line 6088 [user_memcpy]: || user_memcpy(&address, userAddress, sizeof(address)) < B_OK)
  Line 6095 [user_memcpy]: if (user_memcpy(userAddress, &address, sizeof(address)) < B_OK)
  Line 6121 [user_memcpy]: || user_memcpy(&address, userAddress, sizeof(address)) < B_OK)
  Line 6132 [user_memcpy]: if (user_memcpy(userAddress, &address, sizeof(address)) < B_OK) {
  Line 6160 [user_memcpy]: || user_memcpy(&address, userAddress, sizeof(address)) < B_OK)
  Line 6177 [user_memcpy]: && user_memcpy(userAddress, &address, sizeof(address)) < B_OK) {
  Line 6215 [user_memcpy]: || user_memcpy(&address, userAddress, sizeof(address)) < B_OK)
  Line 6235 [user_memcpy]: if (user_memcpy(userAddress, &address, sizeof(address)) < B_OK)
  Line 6615 [user_memcpy]: error = user_memcpy(_protected, &protection, sizeof(protection));
  Line 6619 [user_memcpy]: error = user_memcpy(_lock, &wiring, sizeof(wiring));
  Line 416 [panic]: panic("failed to allocate page mappings object_cache array");
  Line 426 [panic]: panic("failed to create page mappings object_cache");
  Line 1014 [panic]: panic("failed to restore cache range: %s",
  Line 1229 [panic]: panic("map_backing_store(): called with size=0 for area '%s'!",
  Line 1822 [panic]: panic("ALREADY_WIRED flag used outside kernel startup\n");
  Line 1833 [panic]: panic("looking up mapping failed for va 0x%lx\n",
  Line 1838 [panic]: panic("looking up page failed for pa %#" B_PRIxPHYSADDR
  Line 1873 [panic]: panic("couldn't lookup physical page just allocated\n");
  Line 1878 [panic]: panic("couldn't map physical page in page run\n");
  Line 1912 [panic]: panic("couldn't lookup physical page just allocated\n");
  Line 3610 [panic]: panic("could not reserve boot loader ranges\n");
  Line 3690 [panic]: panic("early physical page allocations no longer possible!");
  Line 3841 [panic]: panic("vm_allocate_early: could not allocate virtual address\n");
  Line 3849 [panic]: panic("error allocating early page!\n");
  Line 3857 [panic]: panic("error mapping early page!");
  Line 3888 [panic]: panic("vm_init: go buy some RAM please.");
  Line 3906 [panic]: panic("vm_init: error initializing areas map\n");
  Line 4080 [panic]: panic("vm_page_fault: non kernel thread accessing user memory "
  Line 4114 [panic]: panic("vm_page_fault: unhandled page fault in kernel space at "
  Line 4590 [panic]: panic("vm_soft_fault: failed to allocate mapping object for page %p",
  Line 4848 [panic]: panic("kernel areas cannot be both writable and executable!");
  Line 5038 [panic]: panic("vm_resize_area(): Failed and not being able to restore "
  Line 5576 [panic]: panic("unlock_memory_etc(): Failed to unwire page: address "
  Line 5677 [panic]: panic("get_memory_map() called on unmapped memory!");
  Line 6438 [panic]: panic("area %p looking up page failed for pa %#" B_PRIxPHYSADDR
  Line 6748 [panic]: panic("get_memory_map(): Address is greater 4 GB!");
  Line 1017 [TODO]: // TODO: Handle out of memory cases by freeing memory and
  Line 1633 [TODO]: // TODO: We don't really support this mode efficiently. Just fall
  Line 1694 [TODO]: // TODO: We don't reserve the memory for the pages for the page
  Line 1762 [TODO]: // TODO: This should be done via a method.
  Line 2041 [TODO]: TODO: This function was introduced to map physical page vecs to
  Line 2243 [TODO]: // TODO: for binary files, we want to make sure that they get the
  Line 2350 [TODO]: // TODO: this only works for file systems that use the file cache
  Line 2388 [TODO]: // TODO: this probably deserves a smarter solution, e.g. probably
  Line 2606 [TODO]: // TODO: B_FULL_LOCK means that all pages are locked. We are not
  Line 3122 [TODO]: // TODO: we may be able to join with our source cache, if
  Line 3675 [TODO]: // TODO: horrible brute-force method of determining if the page can be
  Line 4329 [TODO]: // TODO: If memory is low, it might be a good idea to steal the page
  Line 4879 [TODO]: // TODO: retrieve real values here!
  Line 5861 [TODO]: // TODO: The clonedArea is B_SHARED_AREA, which is not really desired.
  Line 6197 [TODO]: // TODO: create a BeOS style call for this!
  Line 6528 [TODO]: // TODO: This is probably not quite what is supposed to happen.
  Line 6565 [TODO]: // TODO: Implement!
  Line 6705 [TODO]: // TODO: B_SHARED_AREAs need to be handled a bit differently:
  Line 6709 [TODO]: // TODO: fork() should automatically unlock memory in the child.
  Line 956 [dynamic_cast]: dynamic_cast<VMAnonymousNoSwapCache*>(cache) == NULL, priority);
  Line 2735 [dynamic_cast]: dynamic_cast<VMAnonymousNoSwapCache*>(lowerCache) == NULL,
  Line 6667 [dynamic_cast]: if (dynamic_cast<VMAnonymousNoSwapCache*>(area->cache) != NULL) {
  Line 6669 [dynamic_cast]: } else if ((anonCache = dynamic_cast<VMAnonymousCache*>(area->cache)) != NULL) {

File: src/system/kernel/vm/vm_page.cpp
  Line 3218 [malloc]: = new(malloc_flags(allocationFlags)) PageWriteWrapper[maxPages + 1];
  Line 3220 [malloc]: = new(malloc_flags(allocationFlags)) PageWriteWrapper*[maxPages];
  Line 421 [new]: #	define TA(x)	new(std::nothrow) PageAllocationTracing::x
  Line 496 [new]: #	define TD(x)	new(std::nothrow) PageDaemonTracing::x
  Line 529 [new]: #	define TPW(x)	new(std::nothrow) PageWriterTracing::x
  Line 542 [new]: SetPageState(vm_page* page, uint8 newState)
  Line 546 [new]: fNewState(newState),
  Line 597 [new]: #	define TPS(x)	new(std::nothrow) PageStateTracing::x
  Line 1234 [new]: // not found, add a new entry, if there are free slots
  Line 1453 [new]: vm_page::InitState(uint8 newState)
  Line 1455 [new]: state = newState;
  Line 1460 [new]: vm_page::SetState(uint8 newState)
  Line 1462 [new]: TPS(SetPageState(this, newState));
  Line 1464 [new]: state = newState;
  Line 2270 [new]: fWrappers = new(std::nothrow) PageWriteWrapper[maxPages];
  Line 2271 [new]: fTransfers = new(std::nothrow) PageWriteTransfer[maxPages];
  Line 3218 [new]: = new(malloc_flags(allocationFlags)) PageWriteWrapper[maxPages + 1];
  Line 3220 [new]: = new(malloc_flags(allocationFlags)) PageWriteWrapper*[maxPages];
  Line 3410 [new]: new (&sPageReservationWaiters) PageReservationWaiterList;
  Line 3412 [new]: // map in the new free page table
  Line 3554 [new]: new (&sFreePageCondition) ConditionVariable;
  Line 1130 [panic]: panic("page %" B_PRIuPHYSADDR " at %p has invalid state!\n", i,
  Line 1578 [panic]: panic("free_page(): page %p already free", page);
  Line 1585 [panic]: panic("free_page(): page %p in invalid state %d",
  Line 1591 [panic]: panic("to be freed page %p has cache", page);
  Line 1593 [panic]: panic("to be freed page %p has mappings", page);
  Line 1650 [panic]: panic("set_page_state(): page %p is free/clear", page);
  Line 1657 [panic]: panic("set_page_state(): page %p in invalid state %d",
  Line 1681 [panic]: panic("set_page_state(): target state is free/clear");
  Line 1688 [panic]: panic("set_page_state(): invalid target state %d", pageState);
  Line 1811 [panic]: panic("mark_page_range_in_use: page %#" B_PRIxPHYSADDR
  Line 2038 [panic]: panic("page write wrapper going out of scope but isn't completed");
  Line 2050 [panic]: panic("setting page write wrapper to busy page");
  Line 2053 [panic]: panic("re-setting page write wrapper that isn't completed");
  Line 2085 [panic]: panic("completing page write wrapper that is not active");
  Line 2384 [panic]: panic("page writer: Failed to init PageWriterRun!");
  Line 2624 [panic]: panic("invalid marker %p state", &marker);
  Line 3697 [panic]: panic("Had reserved page, but there is none!");
  Line 3707 [panic]: panic("supposed to be free page %p has cache @! page %p; cache _cache", page, page);
  Line 4159 [panic]: panic("vm_page_requeue() called for free/clear page %p", page);
  Line 4165 [panic]: panic("vm_page_touch: vm_page %p in invalid state %d\n",
  Line 1477 [TODO]: // TODO: We don't get an actual snapshot here!
  Line 1520 [TODO]: // TODO: If this is a low priority thread, we might want to disable
  Line 1740 [TODO]: // TODO: If free + cached pages are low, we might directly want to free the
  Line 2010 [TODO]: generic_io_vec		fVecs[64]; // TODO: make dynamic/configurable
  Line 2109 [TODO]: // TODO: Unmapping should already happen when resizing the cache!
  Line 2391 [TODO]: // TODO: Maybe wait shorter when memory is low!
  Line 2431 [TODO]: // TODO: make this laptop friendly, too (ie. only start doing
  Line 2496 [TODO]: // TODO: We're possibly adding pages of different caches and
  Line 2576 [TODO]: // TODO: This should be done in the page daemon!
  Line 2593 [TODO]: // TODO: how to judge a page is highly active?
  Line 2772 [TODO]: // TODO: This would probably also be the place to reclaim swap space.
  Line 2987 [TODO]: // TODO: This would probably also be the place to reclaim swap space.
  Line 3868 [TODO]: // TODO: if the page turns out to have been freed already,
  Line 4208 [TODO]: // TODO: We should subtract the blocks that are in use ATM, since those
  Line 4243 [TODO]: // TODO: We don't consider pages used for page directories/tables yet.
